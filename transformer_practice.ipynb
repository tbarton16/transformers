{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbarton16/transformers/blob/main/transformer_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/tutorials/beginner/transformer_tutorial.html?fbclid=IwAR1D94cCvEqwV4nB4EZV49x5eb6K6ALD_W1EXNNQVOYAFGAU7avXCa9Xz9M\n",
        "! pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3D1YmQL9IUu",
        "outputId": "35434461-b632-4ac9-befa-5a81d5f4af2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 28.9 MB/s \n",
            "\u001b[?25hCollecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.2 MB/s eta 0:00:45tcmalloc: large alloc 1147494400 bytes == 0x65e14000 @  0x7f6bce862615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 887.4 MB 1.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 76.9 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 34 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 980 kB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchdata) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchdata) (57.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, urllib3, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.6.0 torch-1.13.1 torchdata-0.5.1 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfX5De5W231g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pdb\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchtext.datasets import WikiText2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "gIGVC2Wilaw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention(torch.nn.Module):\n",
        "  \"\"\"Neural Net architecture for single head of self-attention.\"\"\"\n",
        "  def __init__(self, batch_size, input_dim, dq, dv):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      input_size: int, input to this layer will have shape N x D\n",
        "      input_size, input_dim where 1 is the batch_size.\n",
        "      output_size: int, same as d_k in the paper.\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    # Define the layers, # todo verify intialization\n",
        "    # dq == dk,v dv can differ\n",
        "    self.WQ = torch.nn.Linear(input_dim, dq)  # (input_dim, output_dim) -> y N by outputsize = xW # score for word\n",
        "    self.WK = torch.nn.Linear(input_dim, dq) #\n",
        "    self.WV = torch.nn.Linear(input_dim, dv) # batch_size, dq WV\n",
        "    self.dq = dq\n",
        "    # Initialize the weights\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch_size, input_dim)\n",
        "    q, k, v = self.create_qkv(x)\n",
        "    sdpa = self.scaled_dot_product_attn(q, k, v)\n",
        "    return sdpa\n",
        "\n",
        "  def create_qkv(self, x):\n",
        "    q = self.WQ(x) # (batch_size, dq)\n",
        "    k = self.WK(x) # (batch_size, dq)\n",
        "    v = self.WV(x) # (batch_size, dv)\n",
        "    return q, k, v \n",
        "\n",
        "  def scaled_dot_product_attn(self, Q, K, V):\n",
        "    \"\"\"Given Q, K, V, perform the scaled-dot-product attention.\n",
        "\n",
        "    Args:\n",
        "      Q: float tensor, N x N where N is the number of tokens in the sentence.\n",
        "    \n",
        "    \"\"\"\n",
        "    x = Q @ (K.T) #(batch_size, dq) (dq, batch_size) = (sentence, sentence)\n",
        "    x_d = x / torch.sqrt(torch.tensor(self.dq))\n",
        "    x_s = torch.nn.functional.softmax(x_d, dim=0)\n",
        "    product = x_s @ V\n",
        "    return product"
      ],
      "metadata": {
        "id": "IkzauPfv29ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(10, 4)\n",
        "bart_tron = SingleHeadAttention(10, 4, 5, 3)\n",
        "print(bart_tron(data)) # __ call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtKt4dV3nYvj",
        "outputId": "907a1fc3-386e-4a8d-ca66-01848e9a9c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0477, -0.2410, -0.0955],\n",
            "        [ 0.0409, -0.2168, -0.0860],\n",
            "        [ 0.0501, -0.2384, -0.0931],\n",
            "        [ 0.0461, -0.2291, -0.0905],\n",
            "        [ 0.0495, -0.2389, -0.0936],\n",
            "        [ 0.0511, -0.2448, -0.0955],\n",
            "        [ 0.0482, -0.2373, -0.0931],\n",
            "        [ 0.0500, -0.2415, -0.0948],\n",
            "        [ 0.0433, -0.2179, -0.0864],\n",
            "        [ 0.0474, -0.2348, -0.0929]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the dataset"
      ],
      "metadata": {
        "id": "MVtHrX2B8dIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "XseYLNUeMLpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingModule(torch.nn.Module):\n",
        "  \"\"\" Word embedding, wordToken -> longer numbers \"\"\"\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_size):\n",
        "    \"\"\"Args: None\"\"\"\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.layer = torch.nn.Embedding(self.vocab_size, self.embedding_size) # \n",
        "\n",
        "  def forward(self, x): # [context_length]\n",
        "    return self.layer(x) # (bsz=1, context_length, embedding_size)\n",
        "\n",
        "class PositionalEmbedding(torch.nn.Module):\n",
        "  \"\"\" Encode position using either learned or  sin and cos \"\"\"\n",
        "\n",
        "  def __init__(self, context_len, embedding_size, use_learned_embedding=True):\n",
        "    \"\"\" embed stuff, should uptput something like context_len by embeddingh size\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.context_len = context_len\n",
        "    self.embedding_size = embedding_size\n",
        "    self.use_learned_embedding = use_learned_embedding\n",
        "\n",
        "    if self.use_learned_embedding:\n",
        "      # map (bsz=1, contextlen) -> (bsz=1, embedding_size)\n",
        "      self.layer = torch.nn.Embedding(self.context_len, self.embedding_size)\n",
        "    else: \n",
        "      self.layer = None\n",
        "      \n",
        "    self.to(device)\n",
        "  \n",
        "  def forward(self, x): #(bsz, context_len)\n",
        "    if self.use_learned_embedding:\n",
        "      idxs = torch.arange(x.shape[-1], device=device)\n",
        "      return self.layer(idxs)\n",
        "    else:\n",
        "      assert x.shape[-1] % 2 ==0\n",
        "      d = x.shape[-1]\n",
        "     # pdb.set_trace()\n",
        "      k = np.arange(1, d  / 2 + 1) # [1, 1, 2, 2, 3, 3] 1 d\n",
        "      k = np.expand_dims(k, axis=1)\n",
        "      #k_2 = np.concatenate([k, k], axis=1) # [1 2 3],[1 2 3] # d / 2, 2 -> (1, d)\n",
        "      #k_2 = k_2.reshape(-1)\n",
        "      w_k = 1 / (1000 **(2 * k / d))\n",
        "\n",
        "      cos_array = np.arange(0, d, 2) # even numbers\n",
        "      sin_array = np.arange(1, d, 2) # odd numbers\n",
        "\n",
        "      cos_array = np.cos(w_k * cos_array)\n",
        "      sin_array = np.sin(w_k * sin_array)\n",
        "      cos_array = cos_array[:, np.newaxis] # d/2, 1\n",
        "      sin_array = sin_array[:, np.newaxis] # d/2, 1\n",
        "\n",
        "      fin_array = np.concatenate([cos_array, sin_array], axis = 1) # d/2, 2\n",
        "      fin_array = fin_array.reshape(-1)  # d/2*2\n",
        "      return torch.from_numpy(fin_array)\n",
        "\n",
        "x = torch.randint(0, 10, (1, 10))\n",
        "e = PositionalEmbedding(10, 5, True)\n",
        "f = EmbeddingModule(10, 5)\n",
        "print(x)\n",
        "# print(e(x))\n",
        "# print(f(x))\n",
        "from matplotlib import pyplot\n",
        "with torch.no_grad():\n",
        "  pyplot.plot(e(x).cpu().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "BXVnpJCG9JP1",
        "outputId": "b853ab37-030d-4952-f93f-15df78fbd858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7, 1, 8, 3, 7, 1, 9, 5, 2, 6]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hU1daH3z2TSe+d9NB7CL23gEqzoYKKih2xl0+9Il6vvXdsWLEBYkNFkZpQFQgloUN6SCY9kz5tf39MqOnJzCTCeZ8nj2TOPnuvMcmafdZe67eElBIFBQUFhfMfVXsboKCgoKBgHxSHr6CgoHCBoDh8BQUFhQsExeErKCgoXCAoDl9BQUHhAsGhvQ1oDH9/fxkVFdXeZigoKCj8a9i1a1eBlDKgvmsd2uFHRUWxc+fO9jZDQUFB4V+DECK9oWtKSEdBQUHhAkFx+AoKCgoXCIrDV1BQULhAUBy+goKCwgVCmx2+ECJcCLFBCHFACLFfCHF/PWOEEOIdIcQxIcQ+IcTAtq6roKCgoNAyrJGlYwQellImCiE8gF1CiDVSygNnjJkCdKv9GgZ8UPtfBQUFBQU70eYdvpQyR0qZWPvvMuAgEHrOsMuAJdLCdsBbCNGprWsrKCgoKDQfq8bwhRBRQCzw9zmXQoHMM77Pou6Hwsk57hBC7BRC7MzPz7emeQoKCgodntR9Bexek4E0W1+63moOXwjhDvwAPCCl1LV2Hinlx1LKwVLKwQEB9RaLKSgoKJy3HN6WQ9LGLIRKWH1uqzh8IYQGi7P/Rkr5Yz1DsoHwM74Pq31NQUFBQeEMtGk6gqM9bTK3NbJ0BPApcFBK+UYDw1YCN9Zm6wwHSqWUOW1dW0FBQeF8ory4mvLiGoKivWwyvzWydEYBNwBJQog9ta89AUQASCk/BFYBU4FjQCVwsxXWVVBQUDiv0KZaouFBNtrht9nhSyk3A40Gm6Slce7dbV1LQUFB4XxGm6pD5SAICPewyfxKpa2CgoJCByE3tZSAcA/UGtu4ZsXhKygoKHQATCYz+ellBEXZJpwDisNXUFBQ6BAUZVdgNJgJ6qw4fAUFBYXzGm1qKQDBNsrQAcXhKygoKHQItKk6XDw0ePg522wNxeErKCgodAByU3UERXthKW2yDYrDV1BQUGhnqisMlGgrbZZ/fxLF4SsoKCi0M3lpti24Ooni8BUUFBTamdxUHQgIilQcvoKCgsJ5jTa1FN9Obji6WEPtpmEUh6+goKDQjkgp0abqbB7OAcXhKygoKLQrpXlV1FQabZp/fxLF4SsoKCi0I7m1BVfKDl9BQUHhPEebqkPjpMank5vN11IcvoKCgkI7ok3VERjlicoGLQ3PRXH4CgoKCu2EQW+iIKvcZi0Nz0Vx+AoKCgrtRH5GGdIs7RK/B+s1Mf9MCJEnhEhu4Pp4IUSpEGJP7ddT1lhXQUFB4d+MNuVkha3tM3TAOj1tAb4A3gOWNDJmk5RyupXWU1BQUPjXo00txdPfGVdPR7usZ5UdvpQyASiyxlwKCgoKFwraNJ1NO1ydiz1j+COEEHuFEH8IIfo0NEgIcYcQYqcQYmd+fr4dzVNQUFCwH+XF1ZQX19gtnAP2c/iJQKSUMgZ4F/i5oYFSyo+llIOllIMDAgLsZJ6CgoKCfdGm1sbvbdjS8Fzs4vCllDopZXntv1cBGiGEvz3WVlBQUOiIaFN1qBwEAWEedlvTLg5fCBEsatu4CCGG1q5baI+1FRQUFDoiuamlBIR7oNbYL7JulSwdIcR3wHjAXwiRBfwX0ABIKT8ErgLuEkIYgSpgtpRSWmNtBQUFhX8bJpOZ/PQyeo8Jseu6VnH4Usprm7j+Hpa0TQUFBYULnqLsCowGs90Krk6iVNoqKCgo2BltrUKmPSSRz0Rx+AoKCgp2JjdVh4uHBg8/Z7uuqzh8BQUFBTtj6XDlRW0ui91QHL6CgoKCHamuMFCirbR7/B4Uh6+goKBgV7RploIre0kin4ni8BUUFBTsiDZVBwICIxWHr6CgoHBeo00txbeTG44u1hIrbj6Kw1dQUFCwE1JKtKm6dgnngOLwz39SN8GqR0Ff0d6WKChc8JTmVVFTabSrQuaZ2P+ZQsE+VBTCmoWw5xvL98F9YeCN7WuTgsIFTm5twVV7ZOiAssM//5AS9nwL7w2Gfctg9EPg1xX2LmtvyxQULni0qTo0zmp8Orm1y/qKwz+fKDgKX86An+8C/25w5yaY9F+ImQ3pm6E4vb0tVFCogzSZqNi6FXNlZXubYnO0qToCIz1RqRouuNqQsYHPkz/HaDZafX3F4Z8PGKphw4vwwUjI3Qcz3oab/4Sg3pbr/a6x/DdpefvZqKBQD+aKCrLuvoeMW27l2MQ48hctwlhc3N5m2QSD3kRBVnmTB7bLjyzn+yPfoxZqq9ugOPx/O6kJ8OEoiH8Jel8G9+yEQXNBdcaP1icSIkdbwjqKKrVCB8GQm0vanBsoT0jAf/58XAYMoODd9zg2MQ7tiy9iyMlpbxOtSn5GGdIsCerc8IFtpaGSf3L+YVzYOJvILiiHtv9WKgrgrydh73fgEwVzfoSucQ2Pj5kFK++F7EQIG2Q3MxUU6qNq/36y7pqPuaKC8I8+xH3MGACqjxyh6NNPKfr6G4q++RavGTPwu+1WnLp0aWeL2442pbalYSNNy//J/Qe9Wc/YsLE2sUHZ4f/bkBJ2f205lE36HsY8DPO3N+7swbL7d3CGfUvtY6eCQgOUrVtH+pwbwEFN5LffnnL2AM7duxPy8st0Wb0an9mz0f3xBynTppN5zz1U7dnTjla3HW1qKZ7+zrh6OjY4JiErAVcHVwYHDbaJDYrD/zeRfxi+mAa/3A3+PWDeZoh7CjQuTd/r7AU9pkLSCjDqbW+rgsI5SCkp/OILsu65F6euXYletgznHt3rHesYFkrwkwvoun4d/vPvonLHTtJmX0v6jTdRvmkz/8aGedo0XaP591JK4rPiGRkyEo1aYxMbrOLwhRCfCSHyhBDJDVwXQoh3hBDHhBD7hBADrbHuBYOhGtY/Dx+MAm0yzHgHbv4DAnu1bJ6Y2VBVBMfW2sZOBYUGkEYjuf/7H3kvvYzH5MlELvkSh4CAJu9z8PUl4L776LpuHYGPPYY+PZ3M228n9cqZlP7+O9Jo/UwWW1BeXE15cU2j4ZzDxYfJq8yzWTgHrLfD/wK4pJHrU4ButV93AB9Yad3zn5SNluybhFegzxW1h7I3nX0o21y6TAS3ACWso2BXTGVlZN45j5Kly/C7/TZC33oTlcvpp1IpJckFyY3u2tXubvjdPJeua/6i0/PPI6urOfHwIxyfMpXipUsx19TY4620Gm1qbfy+c8MOPyErAYAxYWMaHNNWrOLwpZQJQFEjQy4DlkgL2wFvIUQna6x93lJRAD/eCUsuAyTc8BPMXAzuga2fU62BvlfB4T+g6vxMfVPoWOizskm/7joq/v6b4GefIfDhhxHnbFZ2andy7e/Xsj5zfZPzCUdHvGdeSefffyP03XdQe3uT+/T/OBY3iYKPF2MqK7PVW2kT2lQdKgdBQJhHg2Pis+Lp49cHfxd/m9lhrxh+KJB5xvdZta/VQQhxhxBipxBiZ35+fosXkkYjZes3UH3wYOssbW/MZkhcYjmUTf4Bxv4f3LXVsju3BjGzwKSH/T9bZz4FhQao2ruXtFmzMORqiVj8MT5XX13vuH9y/wFgTfqaZs8tVCo8J08mavkyIr74AucePch/4w2OTZhI3uuvY8jLs8p7sBa5qaUEhHug1tTvcouqi0jKT2Jc2Dib2tHhDm2llB9LKQdLKQcHNCPGV+d+k4kTjz1G0Rdf2sA6G5N3yHIou/JeCOgFd22BiU8271C2uXQaAAE9Ya8S1lGwHbo//yT9xptQubgQtfQ73EaMaHDsbu1uABIyEzCYDC1aRwiB2/BhRHz6CVE/rMBtzGgKP/2M43GTyHnqv+jT27+63GQyk59e1qh+zubszUgkY8NtF78H+zn8bCD8jO/Dal+zOionJzwumkzZmjWYq6ttsYT1MVTB+ufgw9GQdwAufQ/m/g4BPay/lhDQfxZkboeiFOvPr3BBI6Wk4KOPyX7gQZx79yZq+bJGc+gNZgP7CvYR6RlJmaGMHdodrV7bpU8fwt58ky5/rMLryisp/eknjk+ZStaDD1K1f3+r520rRdkVGA1mghvJ0InPjMffxZ9evi1MxGgh9nL4K4Eba7N1hgOlUkqbldF5zZiBubKS8g0bbLWE9Ti+ofZQ9lXoO9NyKDvwhtYdyjaX/tcAAvYpUgsK1kPq9eQseJL8N9/Ec+pUIr74HAdf30bvOVR4iCpjFXf0vwMXBxfWZzQdx28Kx8hIOv3vabqsW4vfrbdQkbCJtJlXkXHrbVRs/9vuKZ3aJhQyDWYDW09sZWzYWFTCti7ZWmmZ3wHbgB5CiCwhxK1CiHlCiHm1Q1YBKcAxYDEw3xrrNoTrkCE4BAZS+utvtlymbZTnww+3w1eXW76/8Re48iNwb3kYq8V4hUH0GEtY51+Yz6zQ8TCVlJBx2+2U/vgj/vPnE/L6a6icnJq8LzEvEYDhnYYzOnQ06zPWY5Zmq9ikCQwk8OGH6bphPQEPPUT14cNkzJ1L2qzZ6P76C2m2zjpNkZuqw8VDg4efc73Xd2t3U24oZ2yobcM5YCVpBSnltU1cl8Dd1lirOQi1Gs9p0yj6+mtMJSWovb3ttXTTmM2w+ytY85SlKcm4xywSxpr6fxlsRsy1FlXNrB0QPtS+ayucV+jT08m8cx6G7GxCXnkZr0svbfa9u/N2E+YeRqBrIBPCJ7AmfQ1JBUnEBMRYzT61pyf+d9yO7003UvrTzxR++inZ992PY3Q0frfditeMGQjHhqtf24o21VJw1ZA2TkJWAhqVhuEhw21mw0k63KGttfCaMR0MBnR/rm5vU06TdxA+nwK/3gdBfSyHshOesL+zB+g1AxxcLFo8CgqtpHLXLtJmzcZUUkLE55+1yNlLKdmdt5uBQZY6zLFhY3EQDlYJ69SHyskJn9mz6PLHKkLfeB3h7EzOgic5NvkiCj//AlO59bvCVVcYKNFWNnpgG58Vz5DgIbhpbK+Rf946fKdevXDs0oXS335tb1Msh7LrnrEcyhYchssW2e5Qtrk4eUCv6ZD8Ixg7dtGKQsek9NdfyZh7M2pvb6KWLcV1cMv0X9J0aRRVFzEw0OLwvZy8GBI8hPUZ620aZxcODnhOnUr0jz8QvngxjpGR5L38Msfi4ij4eLFV19amWQquGpJEztBlkKZLs2l17Zmctw5fCIHX9GlU7dyFIdsmCUHN49g6eH84bHod+l1tOZSNnWPJlmlvYmZDdQkcsf1TkKm8gqqkepU3FP5lSCnJf/c9Tvzfo7jExhK19DscIyNbPM/uPEs6ZmxQ7KnXJkZMJE2XRkqp7TPIhBC4jxlN5JIviVq2FJd+/ch/4w1qrFjDo03VgYDABiQVTlbX2iN+D+exwwfwnD4dgNLfV9l/cUO15VD26ytB5QA3roQrPgQ321XRtZjo8eAeZGmFaGNOPPIIaddcQ1VSks3XUrAd5poaTvzfoxQsWoTX5ZcT8cniVp+RJWoT8XbyJtoz+tRrE8InANgsrNMQLjExhLz0IgDlCQlWm1ebWopvJzccnes/Lo3PiifaK5pwz/B6r1ub89rhO4aH4zJgALrf7JytI6UlTp+0HMY+CvO2QGfbVtC1CrWD5anjyGqobEwZo22Ux8dTvnEjCEHu/55Bmkw2W0vBdhiLisi4+RZ0v/1GwAMP0OnFF9p02Lk7bzexgbFnHWYGuQXR378/6zLWWcPkFuHg749z376Ux1vH4Usp0abqGgznVBgq2KndafPq2jM5rx0+gOeM6dQcOUL14SP2W3TLW5Zd84QnYeKC9jmUbS4xs8FssMg42ACzXk/uCy/gGB1Np+eeozo5mZLvV9hkLQXbUZOSQtqs2VQnJxP65hv4z7uzTR2ZCqoKyCjLYFBQ3WY8EyImsL9wP7kVuW0xuVW4jx1L1d69VmmzWJpXRU2lscEOV9tObMNoNtotfg8XgsOfMgXUanT2Orw9tArW/s9SRDX2Efus2RaC+0FgH5uFdYo+/wJDegZBCxbgdcXluA4dSt6bb563fUubS1pSAYUnytvbjGZRsX07abOvxVxRQeSSLy1/U20kUWvJv48NjK1zLS7C0szH3mEdAPdxY8FspmLL1jbPlXuy4KqR+L2HxoMBgQPavFZzOe8dvoOvL26jR1H62++2L7TITYYfboOQWEsmTkc4mG0OMbMt+fgFx6w6rSE3l4IPP8R9Uhzuo0chhCB44ZOYKyrIf+MNq671byLzYBG/v7+PPz5IwmSyT/FPayn54Qcybrsdh8AAopYvw2WAdZzT7rzdOKud65USiPaKprNX53Zx+M59+6L28aE8Ib7Nc2lTdGic1fh0qptuaZZmErISGBU6Co3KNs1O6uO8d/gAXtNnYMzJoWrXLtstUp4P310Lzp4w+1vrCp7Zmn5Xg1BZfZef98qrYDYT9Pjjp15z6tYN3xtvpOT7Ff/6lnWtoaK0hjWf7cfZVUNpfhWHt9s/bNEcpNlM3uuvk7PgSdyGDiXqu+9wDAuz2vyJeYn0C+jXYGeniRET2andSUl1idXWbA5CrcZtzGgqNm1u81mTNk1HUJQnKlXdjd+BwgMUVhfaNZwDF4jD94ibiHB1tZ3UgrEGlt8AFfkWZ+/5L5P69+wEncdbGqNY6Smo4p9/0K1ahd+tt9ZxFP7z5+MQGEjOMxfWAa7ZLFnz2QEM1SYufyiWwChPdvyeisnQsXb55qoqsh94kMLFn+A9axbhH32I2qNhHfeWUmGo4FDRoXrDOSeJi4jDJE0kZFsvY6a5uI8dh6m4mOrk1qcRG/QmCrLKGw3nCASjQ0e3eo3WcEE4fJWrKx5xcehWr0bqrdzPVUr47SHI2AaXvw+h/9Lujf1nQ0mGRUWzjUijEe1zz6MJCcHv9tvqXFe7uxH0+GPUHDhI8TLbp4R2FHb9kUb24WLGzO6OX6g7wy/tTHlRDfs3t2OdyDkY8/NJv2kuZWvWEPjYYwQ//V+Exrohh335+zBLM4MC6x7YnqSPXx8CXQNZl27/bB23USNBpWpTtk5+ehnSLBs8sI3PiicmIAYfZ59Wr9EaLgiHD+A1fRrm0lLKN22y7sTbFsGery2aOH2vtO7c9qTXdNC4WUUnv3jpMmqOHCHw8cfOamV3Jh5TpuA6Yjj5b72NsbCwzWt2dLIPF7Pjt1S6Dw2i10jLE2BYLx9Cunmz8490DDXt/6RTfeQIqbNmUXP0KGHvvoPfzXPblInTEIl5iaiEiv4B/RscI4RgYvhEtp7YSpWxyuo2NIaDjw8uMTFtysc/1dKwnh1+fmU+BwoP2D2cAxeQw3cbORK1j491wzpH/oI1C6H3ZTDu8abHtwPH88v57y/JlNc00ezZ0Q16X2rphGVofR8BY1ER+e+8g9vIEXhMntzgOMsB7kLMVVXkvfZ6q9f7N1Cp0/PXZ/vxCnRl3HU9TjlRIQTDL+tMlU5P0sasdrWxfNMm0q+9DgxGIr/6Co9Jk2y21m7tbnr49MDd0b3RcXGRcVSbqtl6ou0ZMy3FfdxYqpOTMRYUtOp+bWopnv7OuHrWrVPYlG3ZdCoO34YIjQbPKVMo37ABU7kV0uHyDsEPt0JQX7j8A9vq17eSihojdyzZyZfb0lm550TTN/SfBTWlcOSPVq+Z/+abmCsrCVqwoMndoVPnzvjNvYnSn36iMjGx1Wt2ZKRZsvaLA9RUGLn49j51Ki47dfUmoo8fiavTqalq4kPZRhR9+y2Zd85DEx5O1PfLcenbx2ZrnWx40lj8/iSDggbh6ejZPumZYy3OuHzT5lbdr02zKGTWR0JWAkGuQXT36d5q+1pLx/NSNsRzxnRkTQ1la9a2baLKIvhuliUT59qllt1xB0NKyeM/JpFaUIG/uyM/7W7GDjJ6LHiEtDqsU5WUTMmKH/CdM6fRLkdn4j9vHg7BweQ+8yzS2D4Oz5Yk/pVO5oEiRl/TDf8GGlgPv6wzNZVG9qzNsKtt0mxG++JLaJ95FvcxY4j8+ms0wcE2XfNw0WGqjFVn6ec0hEalYXz4eDZmbsRgblnrw7bi1KsXDgEBrUrPLC+upry4pl6FTL1Jz9YTWxkXNs4m4bKmuKAcvsuAAWjCw9H92oYiLKMelt8IuhxLRo5Xvb3Y252vt6fz694TPHxRD24eFc2OtGIyiyobv0mlhv5Xw7G1UNGyR1lpNpP73LOo/fzwv6f5rQ9Ubm4EPf44NYcOUfzd+dVn98SxEv5emUrXQYH0GRPS4LiACA+6xAawd20mVeVWTipoAKnXc+L/HqXoyy/xmTOHsPcXoXa3/cZll9aSGn1SIbMpJoZPRKfXnSrUshdCCNzGjaVi8xakoWUfNqfi9/U4/J25O6kyVjEuvH2kVs5Lh19aU1pv1xwhBJ7Tp1GxfTvG/PyWTywl/PF/kLYJLnsPwlomB2sv9mSW8MxvB5jYM5C7xnXh8ljLh9JPu5uRDdJ/NpiNLZZaKP35F6r37iPwkYdRuzcemz0Xj4svwm3UKPLffrvVMdOORlW5nr8+2Y+HnzMT5vRscjc3dEZnDHoTiattv8s3V1aSefc96H7/nYCHHyJowRMItdrm68LZDU+aw8jQkTirndtFW8d97FjMZWUtrhfRpupQOQgC6nmiS8hOwEntxJDgIdYys0VYq8XhJUKIw0KIY0KIOqeXQoi5Qoh8IcSe2q+6uXpWoqS6hNm/zeadxHfqve41YwaYzehWtUJB85+PYdcXlg5V/a9pm6E2orhCz93fJBLo4cwb18SgUglCvV0Y3tmXn3ZnN631HdQbgvu3qDGKqayMvNdfx2XAgBY1wDiJEIKgJxdgrqkh79VXW3x/R0OaJeu+PEhVuZ5Lbu+Lo0vTjeV8Q9zoMTSYpI1ZVJTYrj+BqaSEjFtupWLLFoKf+R/+t99ut9DCuQ1PzrKrgVoEFwcXRoaMtLlGfn24jRwJDg4tztbJTS0lINwDteZs9yqlJD4znmGdhuHi0D6FmW12+EIINbAImAL0Bq4VQvSuZ+gyKeWA2q9P2rpuQ3g5eTEiZASfJn/K90e+r3PdqXNnnHv3bnm2zrF18Ofj0GMaTFxoJWuti9kseWj5HvLLavhgzkC8XU9nCFwRG0pqQQV7MptRuRgzG07shvzDzVq34L1FmIqKCFr4JKKVh9dO0dH43XILpb+spHLHjlbN0VHYszaT9KRCRs3sRkBE8wuWhkyPRpokO/9Is4ldBm0e6TfcSPX+/YS++SY+19h305KuS6eouqjOgW3mgSI+fjCe7CP16ytNjJiItlLLgcID9jDzFGp3d1wHDWpRPr7JZCY/vazecE6qLpWs8iy7ad/XhzV2+EOBY1LKFCmlHlgKXGaFeVuFEIInhj3BmNAxPL/9eTZl1c2795wxg+rkZGpSU5s3acFR+P5mCOwNV37cITNyAD6IP86Gw/ksnNGb/mFna5RP6dcJJwdV88I6fa8CoW7W4W3N0aMUff013ldfjUuftmV3+N95Bw4hnSwHuC2Mm3YUclNK2f7zcTrHBtBvfMvOd7wCXOg1qhMHNp9AV2Dd3HN9ejrp112HITub8I8/wvPii6w6f3M42fDkzPi9QW9i47eHMBsle9dl1nvf+PDxqIW63cI6NUeOYMjJadb4ouwKjAYzwfVk6CRk1jY7aYd0zJNYw3OFAmf+pLJqXzuXmUKIfUKIFUKIBtX+hRB3CCF2CiF25rcmzg44qBx4bdxrdPfpzsPxD3Ow8OwONp5Tp4AQ6Jqzy68qhm9ngVoD134HTi2LT9uLrccKeP2vw1w2IIQ5wyLqXPd01jCpdxC/7j2B3thEKb9HEHSZCEnfNyq1IKUk9/kXULm7E/DgA219C6hcXQl+4glqjh6l+Ntv2zyfvamuMLD6k2TcfJyYeEPTcfv6GDw1CiEEO35v5makOXYdPEja9XMwV1QQ8eUXuI0YYbW5W8Iu7S5LwxOv0w1Pdv6eiq6gmvBePqTtK6j3g87LyYvBQYPbx+GPq03PTGhewab2pEJmPTv8+Kx4uvl0o5N7+0mv2Gur+isQJaXsD6wBvmxooJTyYynlYCnl4ICAgFYv6Kpx5b249/By8uKedfecpa2tCQrCddgwSn/7rfG4oMkA38+1SA7M/ga86zrSjoBWV819S3fTOcCdF67o16CjuTI2lOJKAwlHmvFBGjMbSjMhfUuDQ8pW/0Xl9u0E3HcvDj7WKRF3j4vDbewY8t95F4M2zypz2gMpJeuXHKSyRM/Ft/XFybV1cgTuPs70HRfK4e25FOe2val25Y4dpN9wI8LBgchvv8GlX782z9lazm14UpBVzu41mfQaHsCEXhZJj/2b6n8CnRAxgZTSFFJLrfdB2Bwcu3RBExLS7Dh+bqoOFw8NHn5n98DQ6XXszttt12Yn9WENh58NnLljD6t97RRSykIp5cmTqE+AhkU0rEigayDvx71PpbGSu9beRZm+7NQ1rxnTMWRkUN1Yy73VT0DKRpjxNkQMt73BrcBgMnPPt4lU6k18OGcgbk4NHxCO7R6An5tj88I6PaaCo0eDYR1zVRXaV17GqUcPfGbNaq35dRBCELxgAVKv/1cd4O5bn0Xq3gJGXNml3t1dSxh4cSRqRzX//No251a2foNF2jgggKhvv8Gpc+c2zdcWTjY8ORnOMZslG785hLObAyODVuGx9XGivQ5xYPMJjPq6MhPtpZF/Kj1z2zbMzdDh0qZaCq7O3XRtzd6KSZrOC4e/A+gmhIgWQjgCs4GVZw4QQpz5DHMpYL0uwU3Qzacbb4x/g7TSNB7a+NCpAg6Piy5CODo2fHi741NLVs7IeyH2enuZ22JeW32YHWnFvHhlP7oGNn5AqFGrmBETwpqDWkqrmoiRO7paJCMO/AL6uvn7hYsXYzyRQ/DCJxEOTWehtATHyEj8br8N3W+/UfH3P1ad2xbkpevY+uMxovr7ExPX9t6krp6OxEwI49iuPPIzy5q+oR5Kfv6ZrHvvxalbNyK/+RpNSMN1APbg3IblyfHZaFN1jJoRhHPi2+jKh2EAACAASURBVBDUl37iW6orjBzdUVcyOtgtmD5+fdqt6lZWVlK1c2ej46orDJRoKwnuXPcDPyErAW8nb/r5t98TFljB4UspjcA9wGosjny5lHK/EOIZIcTJHL37hBD7hRB7gfuAuW1dtyWMCBnBf0f+l+0523lm2zNIKVF7eOA+fjy6VavqVnimxMOq/4NuF8Ok/9nT1Baxen8uHyWkcMPwSC4b0LwDwitiQ9EbzfyR1IxDqJjZoC+Dw2ensOozMyn85FM8p0/HdbBtahH87rgDTWgouc8+06EPcGuqjKxenIyrpyNxN/WyWorjgMkROLo48M/KlBbfW/Tll+Q8/h9chwwh4osvcPD1tYpNbSFRm4iz2pnevr0pL65h+y/HCe/tS/eyxWCshmuWEHrp9fg4ZJC08p96mxVNjJjIvoJ95FXaN9TnNmwYwtGxyWwdbVr9gmkms4lN2ZsYHToatco+9Q4NYZUYvpRylZSyu5Syi5Ty+drXnpJSrqz993+klH2klDFSyglSykPWWLclXN71cubFzOPnYz/z0b6PAIvUgqmwkIptZ0gCFx63VNL6d4OZn1iqTzsg6YUVPLJ8L/3DvHhyet2uQQ3RP8yLzgFu/NicsE7kKPAKrxPW0b70Mjg4EPh/tmvhqHJ2JmjBAvTHjlO05CubrdMWpJRs+OogZUU1XHRbX5zdrCcj7OymIXZyBGlJheSmlDbbnry33kL74kt4TJ5M+McfNVk9+0dSDoXltsv7P8mZDU82LTuCNEnGTXVF7PocBt4Ifl0QI+6if58K8ku90P76eZ05ToZ1NmRssLm9Z6JydcV16NAm4/jaVB0ICDzH4ScVJFFSU9Ku2Tkn6Zj5hTZifsx8ZnSewaI9i/j1+K+4jxuHytPzdL/b6lJL1yqhsmjkOLctFmsrqg0m7vo6EZVKsOi6gTg5NP9DSQjBlbGh/JNa1AypBZWlwOz4OijTAhZVxfJ16/C/ax6aoKC2vI0m8Zg4Affx48lftAhDbsfrDJUcn83xxHyGX9aZTl3qF8pqC/0nhuHioWH7L03v8qXJRO7T/6Pww4/wvvoqQt96E5VjXaXGM9mXVcJd3yTyxE+NnGNZgTMbnqTsySdlTz5DpkfjtfdVUDlYpMVr6X7T7Tiq9ezbkAH7fzprns5enYnyjGq39Ex9air6jIYrobWppfiFuNURyEvISkAt1IwMGWlrM5vkgnL4Qgj+N/J/DA0eylNbn2Jn4R48L76IsjVrMVeUw4pboOg4zPoKfKObnrCdeHrlfg7k6HhzVgzhvq4tvv9k+OeXPc2UWpBmSF6B1OvRPv8CjpGR+N50U4vXbQ1BC54Ao5G8V16xy3rNJT+zjM0rjhLRx4/YybbJ3nJ0dmDgxZFkHy4m61BRg+PMej3ZDz9CybJl+N1+O8HPPNMsqYQl29IBWL1fy/YU2/UkONnwJMYrloSlR/ALdSemb6kl7Xf4vLM6xDm6OtJzdCTHa0ZT8f2jkL7t1DUhBBMiJrAjdwc6vc5m9tZHU+mZUkrLgW09+vfxWfHEBsbi5WT9TUFLuaAcPoBGreHNCW8S6RHJAxseoHz8QMyVlZS9Pd8iGjbtdYiyb9uxlvD9zkyW7sjkngldmdizdTvscF9Xhkb78mNzpBYCuluasu9dStGSJejT0gha8ESTu0dr4Rgejt8dd6Bb9QcV27Y1fUMjmKWZ/279L5O+n8Td6+5m0Z5FrM9YT25FbovK9vXVlri9i5uGSXN7IerpWWot+o4Lxc3bib9XptRro7migqx5d1H2558EPvoogQ8/1KxzhKIKPSv3nuCqQWGEeDnz3O8HMJttI12wO283KqHCsN2HitIaxs/pgXrjs+DsBaPq1m/0nRCBWao5YLoSvpsN+UdOXYuLiMMojSRk2bf1oWNkJI6RkQ2qZ5bmVVFTaazT4Sq3IpcjxUc6RDgHLkCHD+Dp6Mn7k97HycGJews/QOXjhm7tJhh2Fwya297mNcjBHB0Lf0lmZBc/HpzcNi3tK2JDScmvYF9WM+LDMddiSE2mYNEi3CdMOKUVbi/8br8NTXg4uc8+16YWlW/teosfj/5IV++uZJdl8/G+j7l/w/1MXjGZ8cvHM2/tPN5JfIe16WvJLq//w1BKycZvDqPLr+Ki2/rg4tGKD76qEksWWHbTCpAOGjWDp0aRm6IjPfnsXbixuJj0m2+hYvt2Oj3/PH633NxsE5btyERvNHPH2M48NqUnydm65qXrtoLEvEQGizEc2qSl37gwgkUyHP0LRj8ILt51xvsEuxHe25f9NVMxqZzhm5mnQor9/PsR4BLQLtk6buPGUvn3P5ir6haH5TZQcHXyg6m90zFPckE6fIAQ9xDem/geRTWFbOpcTnmuM8YhD7e3WQ1SVm1g/jeJeDpreHt2LOo27iqn9uuEY7OlFmaSt9cbadAT9B/7d/ZSOTkRtOAJ9CkpFH7ZYM1eo6w4soLP93/OrB6z+GDSB/x8+c9su3YbX035iv8M/Q9jQseQX5nPZ8mf8eDGB7nkh0sYs2wMt/91O2/uepM/0/4kU5fJgc0nOLpDy9AZ0YR0a2GxmfYA/PYgvNEbfn8Ils2Bmqab8fQa1QlPf2fLLr92F27IzSV9zg3UHDpE2Dtv4z2z+e01TWbJ19vTGd7Zl+5BHszoH0JMuDevrj5Mpd66PQkMZgNJ2mRiDl6Mm5cTwy+NhrVPg0cnGHZng/f1Gx9Ghc5EauyXFqnub6+BmnJUQsWE8Alszt5MtbH1ndlag/u4cciaGir+/rvONW2KDo2zGp/gsw/JE7ISCHUPPau6uD25YB0+QB+1G68W6ljZ3wHMUPrXmvY2qV6klDz2wz4yiip577qBBHg4tXlOLxcNk3oF8uveExhMjUstVB5KR5fmjG8/E45h7aP/7zF+PO5xcRS8/0GzdU1OsvXEVp7b/hyjQkfx+NDHT4U8XDWuDAgcwHW9ruO50c/xw6U/sP267Xw79VsWDl/IpIhJlNaUsuTAEv4v/v+Y8/WtrP0uGV1ADhv9fmBVyipSS1PrleI+hckIB1bCF9PhgxGw+xvocwVc9j7osiH+pSbtV6tVDJ0eTUFmOcd351OTmkradddhzM0lfPHiFrcjXH8oj+ySKm4aEQWASiVYOK0XubpqFidYt5L1cNFhumcOQ13kxthZ3XHMWANZ/8D4xy0NhBogsq8fHn7OJO1zhKs+h9x9sOJmMBmJi4ijyljF9pztDd5vC1yHDEG4uFBRT7aONs0Sv1edsRE7aWN7NTupD+tWzPybqCmD765lXLWenEn3kvnrBxQs/ZDR117bYX44J/l8SxqrknJ5YmpPhkZbL6f6itgwViXlsulofoPnAdJkIvfZ53Dw98K/yyFITYAuE6xmQ0sI+s9/SJk+He1LLxP29lvNuudY8TEe3vgwnb0789rY13BQNf4r7+zgTL+AfvQLOF0gozfpOaQ9wtb3cjA4mjg4YB37j+xFf8gSXnJ1cKWnb096+/Wmt19vevn2IlrjiXr3V7DjM9BlWdJbJz0NsTeCm59l4sy/Ydv7EHOdRZa6EboNDWbX6gy2rziIKX4BAknEki9bJVi3ZFsanbycmdz79M98cJQv0/p14sP448weGk6Qp3PDE7SAnUf2MihrCiF9POgc4wsfPAN+XWHAnEbvU6kE/caFsfXHYxS4jcZ/2uuWp6NVDzNkyqt4aDxYl7GO8eHjrWJnc1A5OuI2YgTl8QlIKU/5CYPeREFWOQMvPvvwfkfuDmpMNR0mnAMX6g7fbIIfbrPI/179BbMH30fFhEH4H8ln6cZ329u6s9iVXswLqw5yUe8gbh9j3dL4cd0D8HHV8GNiw2Gd4mXLqDl0iKDHF6By84R9y6xqQ0twDAvFf96dlK1eTfnmhjV+TlJQVcDd6+7G2cGZRRMXNdk0u8F11Y7k/aXCVKzm8nlDWTLzM7Zfv50VM1bwzMhnuLTLpZikiRVHVvDE5ie4YuUVjPh+InMOfMQLft78NPFBDt/4PYaR95x29mD5AHD2soR3mjg0VqkEMT1NlBabyAkcTOQ3X7fK2R/PL2fT0QKuHxaBg/rsP//HLumJySx5bXXzZLGbQkpJ3l9qhIDJc/pZfnfyD1rkxdVN7zV7jeqEWqMiKT4LBt9i6UOx6ws0W99hTNgYNmZuxGi2b1tM97FjMWRno085nSqbn16GNMs6PWwTshJwcXBhcHDHaZR0YTr8df+DI3/ClJdP7Van3vkiAAeXfsSa9I4R2iksr+GebxMJ8Xbh1atjrP7k4ehQK7VwQIuuum41q7G4mPy338F12DA8pk2HPpdbwhP6tot6tRbfW25BExmB9tlnG9U2qTZWc//6+ymqLuK9ie+1SaHw0LYcDm/PZfDUKMJ7Wp6wNCoNPXx7cEW3K1gw+P/4OuwytlV78lNWDi8UlTHTNRJ1pwH84mDkqdQfuOq3axjx7Qiu+/06nt32LD8c+YFyB0eY/AxkbIM9jauDlq1di+r5u/DUa8noOROH8MhWvZevtqWjUQtmDambShrh58rNo6JYkZhFcnbzir0a4+gOLW65gVTEpuLuDmx4wZLx1bt56unObhq6Dw3iyN+5VFcYIO4p6HcNrH+WOOlCSU3JKckGe+E+dgzAWVW3p1oanpGSKaUkPiueEZ1G4Ki2T0Zbc7jwHP6e72DL2zD4Vhh6+6mXncLCcYodQNxhR/6T8Dh78lrW1szamMySB5btobBCz/vXD8TLxXpVnGdyRWwoNUYzfybVLWzKf+ttzOXlBD+5wPJhEzMbDBVwsIXNY6yIytGR4CefRJ+eTtFndasxwZJ++cTmJ0gqSOKlMS/Rx7/1Ov1FJyqI/+4wod29GTLtnIM3XY7Fib3ZB368DYfKYrrGPceMu/by2Kzf+fLS5Wy7bhsrL1/JS2NeYnaP2bg4uPBH6h88ve1pFm5ZCAOuh/DhsGYhVNafa1/yw49k3Xc/zr16MuqOEZSVGDi45USL30t5jZEfdmUxrV+nBs+B5k/oio+rI8//frBNHaaqKwzELz+M1j2NbqMDYOdnFvXVSU9DCzYu/caFYdSbObQtx3LfZYsgagyjExbhKBzsnq2jCQnBqVu3s6putamlePo74+p52rEfLTlKbkVuh0nHPMmF5fAz/oZf74PosZbd/Tn4XHopgbnVDND5cN/6+8jQ2b6/aEO8s+4om44W8MylfegbaruCjQHh3kT7u/Hj7qyzXq/av5+S5cvxnXM9Tt26WV4MHw7ekS1qf2gL3MeMwWPyZAo+/BBDdt1w1DuJ77AmfQ0PD36YuMi4s67llFaRWtC8JxSD3sTqT5LROKmZfEsfy4GclJZioO9vhrf6Qvwrll3rnB/gnp2WQiLn0z8vlVAR7RXNtM7TeGTII3x68adsvnYzs3rMIj4rnjJjhaX2o6oE1j1Tx4bCTz8jZ8EC3EaMIPKzz4geFkmnLl7sXJVWr6pkY/y0O5uyGiM3joxqcIyXi4YHJ3VjW0ohaw+2XrNm64/H0FcYSei8jEG+3WHTa9B5vOWrBQREeNCpixdJ8dmWDCUHR5j1Na6+XRhRVcX61D/t3vrQfdxYKnftwlRuybDKrVXIPJOT6ZhjwsbY1bamuHAcfkkmLLsevMLg6i8tDU3OweOSS8DBgceKRyCRzF83n+Lq+tuu2ZL4I/m8s/4oMweGMWtI29UXG0MIwRWxoWxPKSK7xJJfLKVE+9zzqH198b/nntODVSroPwtS4y2723Yk6D+PgxBoXzo7y+Wnoz/xafKnXN39am7sfeNZ18xmyS1f7OTqD7dRbWjaWW5adoSiExVMmtsbNzczJC6Bj8bA55dY5CaGzYP7EuH65dB1UrM7oamEimmdp2EwG9iYuRGC+8Lwuyz9krMsioxSSvJef528V1/FY8olhH/wPio3N4QQDLusMxWlepLim583L6Xkq21p9A31JDa8bu77mVw7NIKuge68sOpg081y6uHE0WIObsmhvFcmJt9KopN/hcpCiPtvi+cCS4qmLr+KjAO1T0Au3jBnBXEGwYnqAg5l2LcIy23sWDAYqNi2jfLiaipKaurk38dnxtPbr3ezm7XbiwvD4deUWzRyjHq4dhm41p/p4uDjg/vo0bB2M++Of5uc8hzu33A/NSbbi0ud5ERJFQ8s3U2PIA+eu7yvXTKGLq+VWvi5Nidft3IlVbt3E/jQQ6g9zpFcjqmVWkiq2y/YnmhCQvC/6y7K1qw99Xh9Ug11ZMhI/jPsP3X+3609qOVgjo6C8hq++6fxp7fDf+dycEsOA8d7E5H9FrzRC1bea+kANv0teOggXPw8+LbuID0mIIZA10D+Sv/L8sL4xy256b89iNTXkPvUUxQu/gTv2bMIfe01xBmVzaHdfQjv5UPi6nT01c07tNyeUsQRbTk3johq8nfKQa1iwdRepBZU8PX29Ba9L5PBzIavD+Pp78zWTj8zwLc3Ytsi6H05hNZtXt4cOscG4OrpSNLGM55CvcIYd+knqKRk3ZqHoNp+UguusbGo3N2pSEg4Hb8/w+EXVxezr2BfhwvnwIXg8M1m+OlOyNsPV31mkQpoBM/p0zHm5tItw8gLY15gd95uFmxe0HiutZXQG83c/W0iBpPk/esH4uJoH6XOCD9XBkf68NPubIxlZWhfew3nmP54XXF53cF+XSBsSLP63doav7k34RgdTe5zz3Nce4iHNjxElFcUr417DY3q7Cc4KSXvrj9GpJ8rQ6J8+Cg+hRpj/bv8ktwK4r8+QCfPXIYdnATbFlnCgHNXwV1bYPDN4Ni4CmVTqISKyZGT2Zq9lXJ9OTh5wCUvYs7eR/YtV1Hy/Qr8599F8H//W68uzrBLu1BdbmiwD+y5LNmWhrerhktjmqeLP75HAGO6+fP2uqOUVDa/unnX6nRKtJUMmNmJlMrjDNIVWuSPJy5s9hznonZQ0WdMCOn7CynJOy345xsxilivrqyXFbD8BsuGzg4IjQa3UaMoj08gN6UUlYMgIOz0xmhz9mbM0tyh0jFPcv47/I0vwKHf4OIXoFvTBSoeEycgXF3R/fobF0ddzEODHmJ12mreSmxe3ndbePGPg+zOKOGVq/rTOcC+vXOvGBjKsbxyDr/yFqaCQoKffBLRUIii/yzLB2iubVUWm0I4OhL05AIMGRn8/MxcHNWOLIpbhIdj3UYwGw/nk5Rdyt0TunJ/XHdyddV8v/PscwtqyjBu/YQ/X/oJlbGMyd5voBr7IDyQBNcsgahRLTpwbIqLIi9Cb9azMWsjAKbISWTu6ErZzmMEPXQ3Affd1+BuPCjak6j+/uxZk2HJYGmEnNIq/jqgZdbgcJw1zdtECCFYMK0XZdUG3ll3rFn3FOdWsOvPNLoNCSLX13JP7LEtMPAG8O/arDkaos+YUFRCkJxwdhgrrsdMjjpqyMzYbDmfs1M8333sWIx5eeQc1BIQ7oFac/pvZVPWJvyc/ejt13htRXtwfjv8pBWQ8KpFb3vYvGbdonJ1xWNSHLrVqzHr9cztM5dZPWbxefLnLD+83Gam/r4vh8+3pHHLqGim9rN/k+Pp/ULoXJEPPyzDa+aVjfc+7TsTVJoOsct3GDaIAzHeTIov5d2eCwlxr7uDlVLy9rqjhPm4cEVsKKO6+hEb4c0HG49bqowLjsKqR+H1Xmz5/jCF1SFMmmLC49EtELcQvGxTXTwgcACBLoH8lfYXxqIiMubeTGVmNSEjyvD1bTrdcNilndHXmNj9V+PhqW//zsAsJXOGtyyVs2ewJ7OGhLNkWxop+Y1LQEizRWNI46hm9NXdSNQm4oSgt9EM49oux+Hm7UTngQEc2pqDoeb0k9nEiIkArOs/3ZJMsOGFNq/VLHvGjMYsVBScqD4rnGM0G9l8YjNjwsagEh3PvXY8i6xF1i74eb6licfU11u0M/OaMQOzTkdFQgJCCB4f+jhjw8by/N/P20Sl73h+OY+u2MvACG8en9LT6vM3B08XBx499jtVakd877u/8cGuvtD9Yksc32TfwpczMUszT255kndGl+Hg4Ij3Rz/WO27T0QL2ZJZw94SuaNQqhBDcN74zPXWbKfxgGrw3GHZ9zlHvO0mumsKAyRFEXXolOLRdwqIxVELFpMhJHDqwidTrrqPm6FHC3nsPrxvvhuQVln7KjeAf5k63QYHs25BJRWn950w1RhPf/ZNBXM/AVklpPzS5B04OKl76o/GeRQe35XDiaAkjZ3bF1dOR3dlb6VdVhWbY2fLHbaHf+DBqKo0c+ed0CnGoeyg9fXuy3kFaNnYJr8Cu1ukttQRNYCCGfqMxSRXBZ2To7MnbQ5m+rEOGc8BKDl8IcYkQ4rAQ4pgQos7HuRDCSQixrPb630KIKGus2yC6E7D0OvAIhmu+sqRytQC3ESNQ+/md6nfroHLg1bGv0sOnB4/EP8KBwgNWM7VKb2L+14k4adS8d91AHB3a5zO4bO1aIlOTWdLzYrYVN+OxuP8sKNc26ZRsyXu732N12mpumvAQwffeR/n69ZRtOLsb0sndfYiXMzMHhlma3Gx5h/F/Xcynjq+jKjyMafwCSm9IZMORsQRFezL8cvs1+76YPiz8spqafC0Rn36Cx4QJFhVJn2j4/REwNp4wMHRGZ0xGSeKf9R+u/pmcS0G5nhtrdXNaSoCHE/MndOWvA1q2Ha9fM79Sp2frD8cI6eZNr5GdqDRUckiXQqwRGF1X/ri1dOrihV+YO0kbz1YynRgxkT35eyiYuMCSLfXbg3DU9sWTVb0tMur+/qc3kwlZCTioHBgRMsLm67eGNnsXIYQaWARMAXoD1wohzg1e3QoUSym7Am8CdZPgrYW+0pKRoy+H65adXcreTISDA55TplC+YQOmMksTaVeNK4viFuHt5M3d6+4mp7ztaYlSShb8nMSRvDLemjWAEO+GxaRsibm6mryXXsaxW3c29xnLT41ILZyi+8Xg7A372ies89PRn1ictJiZ3WZyc5+b8b3hBhy7dEH7/AuYq0+rKG47Xsiu9GLuGt8FR106fDQW1ixEeIWxZ/hbjKx6k1/cZ7P621xUKsFFt/ZBrbbPh25VUhLu97+Io1Tx4/2xp/sDa5xh6mtQeBS2Ni714R3kSs/hwSRvyqasqK565Jdb04j2d2N0V/9W23nr6GhCvV0a1Mzf/P1RDHoT46/vgRCCvcnfYQIGdb8UXFqoKNoIQgj6jw+jMLucnGOnK4HjIuKQSDac2ARXfwFBfWD5TXDCtsWTpZ7RaPQ6VAdONzePz4pncNBg3DRtO9S3Fdb4zR4KHJNSpkgp9cBS4Nza6cuAk89ZK4A4Yat8QyHAvzvM/BQCm9/r9Vy8ZkxH6vWUnaGgGeAawPtx71NtrGb+uvmU6cvaZOqyHZn8mJjN/XHdGNs9oE1ztYXCTz7FkJ1N8MIFTB0Qxl8HcimvaSJU4+AEfa+0VN3WtO3/Q0v5J+cfntn2DMM7DWfBcEsVsHB0JHjhQgxZWRQu/uTU2HfWHyXI04lrwnXw2cWWHf7Nf8DNq+h/0Vy6BvuwacUx8jPKmHhjLzz9bf+hK6WkbONGMm6ai8rdne1PXcYvYi8VhjMKwrpNskgQJLwKxWmNzjd4WhRI2Pn72UqXSVmlJGaUcMPwyLNUHFuKs0bNo5f0YP8JXZ1eyOn7Czm6Q8ugiyMt0sBSsnuPJV0yZtRjDczYeroNDcLJ1eGsFM1u3t0Icw+zVN06ecD134Orn0VSubhlaaUtobBUjXdVNhW1TVEyyzJJKU3pkOmYJ7GGww8FzswNy6p9rd4xUkojUArUu/UWQtwhhNgphNiZn5/fcms0LjBzMfS4pOX3noFz//5oIiIoPdnvtpauPl15c8KbpJWm8eDGBzGYGs+QaIjk7FKeWrmfMd38uXditzbZ2hb0WdkULl6M59QpuA0dyhWxYVQbzPyR1IwnmJhrwVhl0dexEymlKTyw8QEiPSN5ffzrZ6Vfug0fhue0aRQuXow+I4O/UwrZnlLEUzE6nL6eDkINN/8JkZbeoiqV4JaoILqWgEd/HzoPsO2HrrGwkMLPPidl+gyy5t2FJiyMyG+/YfSwmejNeuIzz+mmdMlLlp6vqx5tNPvE08+FPmNCObgtlxLt6bTFJdvScHVUM3NQWJttvzQmhAHh3ry6+tApzXyD3kTCd4fxDnJl0CVRloFH/iSxpoDuLoG4u1m/6EjjqKbXyE6k7M6nvNgS7hJCEBcRx985f1tSXD2CYc4KSzroN1dDlfWLJ6srDJRoqwgIUFOesAlpNne4Zif10eEObaWUH0spB0spBwcEtN+uVwiB1/TpVG7/G4P27BLz4Z2G8/TIp/k752+e3vZ0i0u7S6sszUz83Bx5a9aANjczaQt5L78EKhWBjz4KwMAIb6L8XJvXGCVsiKXwyE5hnaLqIu5eezcalYZFkxbh6Vi3f2jgo48iHBzIff553l13lMtck5m6ez64+sOtqyHw9KG4rqCK0ngtxU6wtFpnkxZ/0mSiPD6erHvv4+i48eS98gpqd3eCn32GqKXfoQkMJDYwlgCXgNNFWCfxDIHx/4Gjq+HwqkbXGTQlErVasKN2l19c28Lw8thQq+gwCSFYOL0XWl0NHydYlCJ3/JaKrqCa8df3sKQlmk0Y1j7NPmdnYiMntnnNhug7LhSzlOzffPp3NC4yDoPZwKbs2p6zAT1g9ndQnApLr2/yLKSlaNMsBVchsRGYioupTk5mU9YmojyjiPC0TY9ja2ANh58NnFn/H1b7Wr1jhBAOgBdgu67JVsJz+nSQEt0fdf/YLut6GfNj5rPy+Eo+3Pdhs+eUUvLI93s5UVLFe9cNxM/dtpkgjVG+ZQtla9bif+edaIKDAcsf9uWxoWxLKSSntG4rt7MQolZqYROUZjU+to3UmGq4f/395Ffl8+7Edwl1rz9VUhMUiP+991IRn8DALR/ypnwF4d8NblkN3qf/EE1GM6s/2Q9SiBDMRgAAIABJREFU0uPKKA7klbPmoNZq9uozM8l76y2OTYwj8855VO7ahe8NN9D5t1+JWrYUn6uvRuVqyZo5ma2zOXszlYbKsycadicE9oE/HmtUpdTNy4l+E8I4skNLYXY5y3dmUmM0c+OI1qlq1segSF+m9e/ER/EpHDpYyJ61mfQa1YnQ7rVx+n3LOVKaQpWAgUG2kwT2CnAlsq8f+zedwFQr/dDfvz++zr5ni6lFjYLLP4D0LfDTPEsRppXQpupAQPiUoSAExRvW8U/uPx06nAPWcfg7gG5CiGghhCMwGzj3GX8lcFPtv68C1kt7Kx61AqfO0Tj36YPu1/rVIefFzOPSLpfy/p73WXm8eWGNjxNSWHNAyxNTezEo0noHWi1F6vVon38BTWQEvuf0Qr18QChSws+7m6HI2H8WIGGf7WoUpJQs3LKQPfl7eGH0C/QP6N/oeN8511Pl48GMfVswBQ+Bub+D+9lPi9t/Pk5emo4JN/TiitFRRPq58u76o20S4jJXV1P666+k3zSX45MvovDjxTj17EHoO2/TbeMGgh57FKeu9RcgXRR5ETWmGuKzzgnrqDUw/Q2L0mT8K42uP/CiSByd1Py9MoWvtqczLNqXnsF1n4LawuOX9MRskqz6PBlnNwdGXln7fow1sOEFdgVaMpxiA2Otuu659BsfRpVOz/FEy9O3WqVmQvgENmVvQm86o+K231UWCer9P8Lap6y2vja1FL8QN1yD/XGJiSF//WoMZkOHDueAFRx+bUz+HmA1cBBYLqXcL4T4f/bOOzyqMn3D95mSmSSTSe+dJIQWSgKBUJJQBOmCskqxo2JDLOu6u/byc9cuithdFbugKFKUGiChJnQI6b33ninn98eBQMhMMqlgua8rF2HmO2dmMsk333m/532eZwVBmHNu2EeAsyAIqcBDQN8Ho3YR7exZNJ48SVN62+g3QRB4OuppRnuM5qm9T7G/oG3W5cXsTy/jpS3JzAjz4NZxAb30jC2jfM0XNKen4/7PfyKzai1bDXCxJdzPgR+ScjueAJ0CJRfNY9/0WpfjqiOr2JSxiQfCH2BqwNT2B4sihRtfIHREBvp6BRV1V4G69aSXeayUI1tzGBLjTXCEGwq5jHtjgzmRV83O5M7tG4miSMOJkxQ88wwpE6LJ//uj6PLzcV3xAMHbt+H33ntop05t5YVjihFuI3CxduHXzF/b3uk3BkYsgYS3odi8Hl6tUTJsih8ZR0vRlTRyczuumF3F18mGO7xdUVUb8J/sg9r2XLno0MdQlU2SRwjeGm/cbU0nqPUUfgOdsHe1brV5O9lvMnW6urbRh2OXw6g7JMXT/ve7/diiKFKUUd3if6+JicYqOQuvJhtGuPfuB1136ZEaviiKG0VR7C+KYpAoii+cu+1JURR/Ovd9oyiKC0RRDBZFMVIUxfT2z3jloJ0xA2Qyqi/ZvD2PUq7ktYmvEWAfwIM7HiS1wnQbenFNI/d9lYSfkw3/vXboZY1R1BUXU7pqFZqYGOxiY02OmRfuw9miWk7mW2BKNewGKDkDBT0vg1ufup73jr3H/JD53D7k9vYHG42w6VE8k15nq9tYbGbOpPyTT2nOzGwZUlPeyNZPT+Hiq2HcdRdW2/PCvfF2sGalhat8Q2Ul5Z+vIWPefDKvu46qdT+giY3F73//I2jLZlyWLWspk1mCXCZnit8UduftblvWAZjyrKRA+eXhdj9Yh0/2RaeAyXpVqwjDnqK2ohG7s3XkqkTezyyQflZNNRD3MmJgNIl1OYS7dc0krTMIMoGwWB8K06spzpJ+R0d7jsZWadvWI18QJDv00Jmw6dFu5zlUFTfQVK/HvZ/UcGU7QSrjXFMe0MbD6Urjitu0vdJQurlhO2Y0VT9vMDsRaK20rJq8CpVCxT3b7qGkvvUqUW8w8sBXR6hp1LF6STh26sv7S1Hy6muIzc24/+ufZsfMCvNEKRdaHDTbZfA1ILeCoz0bf3iw8CBPJ0hXUI+Pebz9D0mDDtbdAQfe5339THImvIT3Y/9AUKkofP6Flvduz7cpGPUi05YOQXGRr4xSLuPu2CCSsivZm2p6e0k0GqmLjyfvoYdJiY6h6IUXEGQy3J98gpDdcXi//BK2Y0ab9yDqgKkBZso6IPWTTHkasva0GzOZW9vIXoUO70aBkvSed5CM+/osGEUGzPJnf2YFv54qgvi3ob6M7LHLKG8s77NV7oAoDxRWshabaCu5FRO8J7AjZwcG4yXGeDI5XPsheEfA2tsh52CXH7cwQ+oBOG+pkOEuUmEL4WldPmWf8deEbwHaWbPR5eTQePSo2TFeGi9WTV5FZVMl9267t9Uq7fWtZ0lIL+OFa8J6vKbaWeoTk6havx6nW2/Fyt/8hp6jrRUTQ91YfzQfvaGDzS5rRwidfs5qoWsy1UvJqMpgxY4V+Nr5tpFftuF8s92J71nntJS3FTdx07h+KFxdcV1+P3V79lDz22/UVTWRcayUsFhvHNzb2gwsGOmDh1bNyu0prW7X5edTsmoVaVdNJfu226nduxeHBQsI/GEdgevW4rRoEXJt99/XcLdwnNXOpss6IAWg+4yCXx83KzX8fF8WJ2wMqO2U7Fuf1qPhIOlJJWQcLWXUrEAWT+pHsJuG1b8kICa8DYPmkkhzy+voC1Q2SkJHe5ByoIjGWun3brLfZMobyzlaYuJv1cpGasa084Svroeyrs3QRenVKNVyqe8A2JW/myNBAvZH0hH1l89qxBL+mvAtwG7qVQgqVYvVgjkGOQ/ilZhXSK5I5u9xf0dv1LP9TBGrdqSxMNK3R/TQ3UE0GCh8/jkU7u643HVnh+Pnh3tTUtPEXjMt9a0YegPUl0Ja9yPnKhoruHfbvShkClZNXoW9qp3Er4YK+PwaSNtGQfR/eSh/EreO64f23FWU46JFqEJDKXrxP5zZnYNoFBkQZdrbRaWQc1dMPw5klLM/uYDqzZvJXnoHqZOnUPrW2yj9fPF65RVC4nbh8cTjqAd2vbHPFHKZnCn+7ZR1ZDKY+ZoUJrL9+TZ31zXp+f5wLleFeRI5M5CC1CpyTpmOTewszQ164r45i7O3hmFTfCXP/JkDmVv9FaKuASY9QWJxIg4qB/rZ9501RVisDwa9kVPnIh/He49HKVOajz60dZHSyQDWXAt1pZ1+zKJMqX5/vpktLieOshEBiDW1NLSzKLwS+GvCtwC5RoNm4kSqN21C1LW/go32ieZfkf8iLjeOx3c/z4pvjjDYS8tTs7ueq9pTVH73PU2nTuP26N+R2Xbc+j1xgBv21kp+SLRAchk8Bayduh1/2GxoZsWOFRTVFfHmxDfxtWsn8aumED6ZCflJcN0nPF8QiUal4LZxF7JnBYUCjyefQFdQwMlfz+IZZN+yMjPFtY5NPHBmA4ob5pC34kGa0tJwuftugrZuxf+TT7CfNROZqvektNMCptFkaDJv0uc5FCLvgoMfQV5iq7t+PJJHTaOem8f6M2icF3ZOavb/lN4jq/x969Opq2pi4pIBLdYTsW713KjYxjoxlkobf5KKkxjuNrxP96ecvTV493fgxK48jEYRjZWG0Z6j2Za9zfzrdg6SgpBqCuDL66UrRAvRNRsoza1tKeeUNpRyouwEnrFXg1zeKtz8SuSvCd9C7GfPwlBeTl1CQodjrx9wPTcOvJlfMtci2u3mncXhFvuQ9xaGykpK3ngDm1GjpI1oC1Ap5Mwc6smWk0XUdWi1YCVJ4M5slOwLusB5+WVicSIvjH+B4W7DzQ8uT4ePpkq2A4u+JcVlMhtPFHDL2ADsbVqXf2wiIjDMupmaZjXBIYo2pzLU1lLxzbdk/O168ubPY2rKHg459qPp/14jeOtvuC6/Hyuf3rFIvpSWss6lTVgXM/FfoHGXTMLO1apFUeSz+CwGe2kJ93NErpQxcmYAxVk1ZBzp/Cr2Ygozqji+K5ewWJ9WVsDCjheRyeW82jSP//52kKzqrD4r51xMWKwPNeWNZB2XXudkv8nk1uZytuKs+YN8R0k1/bzDsHZpy8+xI0qyahCNYkuG7e5cqdFrfOhUbMLDW4WbX4n8NeFbiO2ECci0Wqo2dLzDL4oihRmT0dUMQub8M/lNx/rgGbZPycqVGGpqcH+8g83PS5g/wpsGnYHNJwo7Hjz0BjA0wan1XXqOq4+uZmPGRpaPWM7Vge1YYxQeh4+mSeqQm3+GoIm8vSMVa6Wc28cHmjykOPRq5IYmND+tQhRFRFGk/uBB8v/xGCnjJ1D41FOIDQ24//MxfLdt593Y23mzytlk2lRv0lLWyTVT1gFJZjrtBUkVdehjAA5klJNcVMNNUf4t7++AMR44uNuw/+f0LncRGwxGdq5JxtZexZg5F5Vqik7CsW+QjVnGxMjhrD25F+h9/b0pAoe5oHFUtUg0Y31jERDYntNBeXHgbEm9k/wLbH7MIllxS6ThOUnm7rzduNm4EeoYiiYmmqYzZ9AV9VwDX0/z14RvITIrK7TTplGzdRvG+vYvAT/ak8G6pHxu7/9v+jn04+9xfyenxrIout6g8cwZKr7+BseFC1GHth/xeCkR/o74OVloteAdDs4hXQpG+TntZ1YfXc3coLksDVtqfmBWglTGkSvhts3gE0FaSS0/H83npqgAHG3b6t11TQbSTlTh52mgKX43BY8/TvrV08m68SZqtm7Ffs4cAr79hsCf1uN0881oPVxZOqEfO5JLOJ7btauV7jAtYBqNhkbi8tpZLQ65FvrFwrbnoLaYzxKysLdWMmfYhSsRmVxG5KxAyvPrSDnYtUno6NYcyvJqib6hP1bWF10dbXtW+uAZt4IHp/THyjYLASWDnfu+dCmTyxg8wZuc0xVUFNbhYu3CcLfh5uv4FzP6Loi6Dw6836EzKUgNV1oXNTZaK3QGHfH58UT7RCMIghRuDlf0Kv+vCb8TaGfPQqyvp2b7DrNjdiYX838bTzMjzIOHp4SxcuJKRFFk+fbl5ldsvYgoihQ+9zxye3tc77+v08eft1rYm1ZKYVVb+91LBsOw66VW9k64FB4uOsxT8U8R6RHJU1FPmb8CObsFPp8HGjfJKsE1FIBVO1KxUshYOsH06j4tsRhdk4Hhi8eiHjSIqrXrkLu64Pnii4TsjsPz2WewHtq6N+KmKH+0agVvXaLY6Qs6VOuA9LOe8SroG2jY8E82nyzk+lG+bXKQgyPccPbWcGBDBoaO1FaXUFXSwMENGQQOc2ltLJeVAGc3w7gVYOOEq50KN7d8dHU+HMzs+w9IgEHjvZAphBaJ5mS/yZwpP0NujQX7T1c9B4PnwW9PwIm17Q4tzKhuKeccLj5Mna6upbtWFRKCwtOT2l0mZLVXCH9N+J3AZuRIFJ6eVP9sugkrraSW+79KItRDyysLhiGTCfhqfXkl5hXSq9L5155/9UkY+nlEo5GSV1+l4fBhXB96ELl9O2qXdpg3QrJaWH/EglV+2N+kfy20WsiqzuKBHQ/grfHmtdjXUMrNyC+PfStJL11DpZW9g7SZm1lax/oj+SwZ7Y+LGV+i0/EF2LtZ49nfEb+PPyJo628ErFmDw7xrWvxsLsVOreTWcYH8eqqI0wU9r2dvD4vKOiDlxI57AOsz3zOKkywZ3VZmK8gERs8JpLqkgTPxlmc4iKLIrq+SEeQC0Tf0v/gO2Po0aDxaYkPrdfWU6zKwMYbw/IbTGHrBhK4jbLRWBEe4cSahgOZGPZN8JfM2i1b5Mhlc8y74jZU8dzL3mBxWW9FIXWVTyz7GrpxdWMmsiPSIBKTFkSYmmvr4BIzNfROo3ln+mvA7gSCTYT9zBrV796KvaK2DrmrQccenh7CSy/jgpghsrC5c/kZ5RfFwxMNsy97Ge8fe65PnKjY3k//YY5R9+BEO11+Pw7XXdvlcgS62DPd1sKys4+gP/uMlB80OaqKVjVLPggwZ70x+x7z8ct+7UlOV/1ipZm97IczjnZ2pKGQCd0ablgJWFtWTn1LJwLGeCIKA3MEBKx/L5LG3jQtEo1Lw9g7LQrx7kqn+U2k0NF5wfzRDc9SD5OLGa7af4WffdkMaIGCoC24BWg5tzESvs2xzMuVgETmnyhkzNwiNo/rCHWe3QM4+iP2HpGsHjpUewyAaWDgsmlMF1ayzRNXVC4TF+qBrNJC8rxBfrS8hjiEd1/HPo1TDDV9ISWNfLZL2KC7hfP3+fKRhXG4ckZ6R2CgvLBo00TEY6+tpOHy4+y+oF/hrwu8k2tmzQa+netOmltsMRpH7v0oip6Ked2+MwMfRBoPOyNFtOdRXS5/0Nw66scVobVv2tl59jobaWnKWLaP6p59xXbECj6ef6nL353nmh3tzprDGstXusOuhLLWNbPBimg3NPLDjAfJr83lz0pv4ak3IL0URtr8Am/8BA2bB4u9b+eLklNezLjGPhZF+uGnVbY9HyloVBBgwpvO5qvY2Sm6K8mfj8QJSi/s25CXCPQIntVP7ZR1gU3IljzffjJcuG/atMjlGEATGzO1HbUUTJ+M6NsRrrNOx57sU3AO1DIm5SJ1kNMC2ZyRL7BE3ttycVJSEgMCdkRMZ4efAy1uSWzzz+xL3AC1u/nYc3yl5QE32m0xScRLljZb1IuzI0fOG538QrWxgzXVtHGALM6qRKQRcfDRkVmWSXZPdxh3TdsxoBKXyipVn/jXhdxJ1aCiqkJBWDpr/2XSauLMlPDd3CKMCnBBFkZ1fnmHPdyns/EIyuxIEgSejnmSI8xD+tftfpFT0Tm1YV1RM1uIl1B04iOeLL+Ky7K4e0UXPGuqFQiZYtsofNBcUarOafFEUeSr+KRKLE3l+3POmlR1GI2x8RAqlHrEEFnwqrcIuYvWuNGSCwLKYIJOPYzQYSU4owG+IM7YOXdPO3z4+ELVCzqodfds3f7G3ToPevE31ZwlZZDqOQxwwS3LTrMw2Oc5ngCPe/R04vDkTXVP7q/z4tak01umJXTygdVLW8e+g+BRMelzaND9HYnEioU6haFVaHp85iOKaJt7b1fd2WYIg+etUFNaTl1zBJN9JGEUjO3N2tntcXZOef647zq2fHOSNgw38NuJtKSJ1zbWtOpqLMqpw9bVDrpS12F9cOuHLbGywiYy8Yjdu/5rwu4B29mwakpJozs3l+8O5fLA7g1vGBnBDpOS3fnRbDmcSCnH1syPjaCnpRyRvHZVcxRsT38BGacPy7cupaurZDa6m1FQyF96ALicH33ffxWHeNT12bidbK2JD3Vh/JK/jGq3aHkJnSBtg+ra1zHePvcuG9A3cO/xeZvQz0ROgb4Z1S+Hgh5LT4Zy3Qd66XJFf2cB3h3K4fpQvHvamV/fZp8qpq2pm4NjOr+7P46xRsWSMH+uP5JFZat6PvjeYGjCVBn1Di9b7Uk7kVXE4q4IlY/wRrv6PdOMm00a0giAwem4QDTU6ju0wrxjLO1vB6fgChk/xxcVHc+EOfRPseAE8h8GgeRduNuo5WnK05UM7wt+RWUM9eS8ureNN/l4geKQbalslx3fmMcBpAF62Xu3W8Q9nlTNj5W6+PpjNXdH9GOip5b9JCox/WyP1eny1CHSNGAxGSrJqWso5u3N3E+wQbDKXQRMTTXN6Os05l0+ZZ46/JvwuYD9TmqTOrPmOf607zrhgZx6fKbXZZ50sI35tKkEjXLn20QicvTXs/uYszY3SJa67rTuvx75OUX0Rj+x6BL2xZy596w8dInPRYkSdDv81n6MZP65Hznsx88O9KapuIj7NgkaeYTdAQzmk/tbq5l/Sf+GdI+8wJ2gOdw29q+1xzXXw1Q3Sh8WUZ2Dqc5Ii5RLe3SWtuJfFml7dA5yJL0CtURIQ1vUAb4A7ovuhlMt4Z2ff1vJbyjpmmrA+T8jCWilnQYSvtIkd+5ikKU/eZHK8Z5A9/kOcSfo1m6b6th3jep2BnV8ko3VRM2rWJYqnQ59IVw+Tn5I2Oc+RXJ5Mg76hVcPVP64egFGEl7ckd+FVdw+FUs6g8V5kHJUiECf5TSIhP6F1XjDQrDfy381nWPBuAgajyDd3RvHPGQNZFtOPtJI6fmsMhXnvQnY8rFtKeU41ep0R90AtNc01HC46bDbsRHMFyzP/mvC7gNLbG/mw4RT/8BOe9ireXhiOQi6jorCOXz88iZO3hsm3DEKukBG7OJTayiYO/HTBT3+423CeGPME+wr28drh17r9fKo3byH7tttRODsT8NXXqAcN6vY5TTFpgBt2agU/JFpQ1gmaBLaurTT5iUWJPLH3CUa6jzQtv6wvh8+ugfQdMOctGL/C5KkLqxr5+kAO10X44O1gOnS8oaaZjGOlhI72QK7o3q+5m52ahZF+rEvMI6e876S1CpmCyX6TicuNa1PWqaxv5scjeVKE4fnO4jH3gOsAyQLYjF3A6Dn9aKrXc2Rr29Xn4c1ZVBbVE7MoFOXF8s5z9scERkvv60UkFkv7NBd3Rfs62XDbuEDWJuZelj6GwdFeAJyIy2Oy32Sajc3sybugvDlTWM3cVXtZvTONBRG+bF4RTWSgEwAzwzzxdbJm9c40xMHzYdqLcPpnin75DJAcMuPz49GLerNhJ1YBASj9/f6a8P8oNDQb+M5hMN5Vhbw/1h5HWysa63RsXH0cuUJgxt1hKFXSH4xHP3uGTPDm2I4cSrIvbPzNC5nH4oGL+fzU5xanZZmi/LPPyHvwQdSDB+P/5Re9agGgVsqZNdSTzScLO96UkythyHWSXruhopX88o2Jb2Alv6RBqroA/jdT6h5d8CmE32T21O/FpWEQRe6JNZ0eBXD2QBFGg9itcs7F3BXTD5kgtFxZ9BXnyzoXT1gA3x3KbRthKFdK5mqV2bD7FZPnc/WzIyjclaPbcmiouVBuKy+oI3FzFiGj3PEb5Nz6oIRVkjHe5KfbXG0lFSfhrfHGw7a19/89E4NwtrXiuV9O9ahjpyVona0JGOrCqT35hDkOw1HlyPbs7RiMIu/tSmPOW3spqWnkw5tG8t/rhqJRXSgXKuQy7owO4khOJfszyiHqHhh7P4UpJVirddg5q4nLjUNrpW03eU0THUP9vv0YG/u+rNUe3ZrwBUFwEgThN0EQUs79azKzTxAEgyAIR859dX12uwIQRZFH1x7jG9v+iHI5DvHbMRqM/PbRSapLG7j6zjC0zq1XnWOu6Ye1nRU7vzjTqsX94ZEPE+kRyTPxz3C85HjnnofRSNF/X6Lo/17Ebspk/D75GIVj70cmzhvhQ32zgS0nLbBaGHYDGJo5eWg1N22SJnCT7pdlafDxVGmiWvw9DJpj4mQSxTWNfLk/m/kjvPF1Mq2hF0WR0/H5uPnb4eytMTmms3jaW3PdSB++O5Tbp7Xpke4jcVQ5tlLrGIwin+/LIjLAiYGel9gyB4yDYQth70ooMe0lEzm7H/pmA4lbpOY40Siy84szKFVyxi8IaT24rlTqQB04B3wiWt0liiKHiw6b9M/RqpU8eFV/DmSUs+Vk31sNhE30obFWR0ZSKbG+sezKieOG9/fw4qYzTBzgypYV0UwxExCzIMIHF40Vq3ee+3Cf8ixFsgjcxSTEI1+xJ28P473Ho5CZlsGCVNYRm5qoP3CgN15el+nuCv8xYJsoiiHANsxHFzaIojj83Jf5v+bfAe/sTOPno/ksmxOOXXQ01b/8QvzaFLJPlROzMBSvEIc2x6hslIz/WwjFWTWc2HVB6qWUKXkl5hVcbVxZsWNFm+AUcxibm8l/5O+Uf/IJjosX4/3GG8jUpjcue5qR/o74OFqzzpKyjucwdnuEcGva16jlaj6d/il+Wr/WYwqOwcfTpNr9zT9Dv/YzQT/cnYHOYOTeieZX9yXZNZTl1TFwnJclL8li7o4JwiiKfbrKV8gUTPafzK7cXS1lnV1ni8kur+emsWbyDK56TtLIbzSdjuXkaUv/0R4c35VHXWUTp+MLKEitYuy1wdhoL7nyinsFdPUw6Yk258muyW438OSGUb6EuGl4cdNpmvV913AI4BPqiKOHDcd35GLVNJQ6fS1nKpN4dcEw3l0SgbOZJj2QrmRvHRfIrrMlnMqvprHBQGW9Fg93HSe2PER5Y3mH2bU2kaMQ1OorTp7Z3Ql/LvDpue8/BXpOFnIF8tupIl75NZk5w7y4OyYI+9mzyBYCObo9j7CJPgwab36CCY5ww2+QE/vWp1Nb0dRyu6PakTcnvkmNroYVO1e0DmA2gaG6mpyld1C9cSNujzyM++P/7lODL5lM4Jrh3uxNLaW4uv2V7g+pP3K/dTMBzU2sGftCW5/0zL1SGUeugls3S1487VBW28TnCVnMHe5NgIt5i+PTewuQK2WEjOrZiD9fJxvmjfDmqwPZFNf03Sp/qn/rss6n8Vm42amYNthMhKLGVdpczYgzaxUwamYgokFkz3cpxK9LxSvEoW35qyILDn0kyWJd23owJRZJ9XtzDpnnPfOzyur5LCHTotfaUwiCQMAYD4qzatiwyQqZqGLGmDKujfCxSKa8ZIw/GpWCd3elUZR5zjBt9q3scvFBJoqMk9u1e7xMpcJ2zBhq4+L6vKTVHt2d8N1FUTzfr10ImPsLUwuCcEgQhH2CIPwuPxTOFtWw4uskhnjZ89J1ku9KbcBIkvsvxFVZzvjrzK84QfoFjF4YitEgsufb1pfaoU6hvDD+BY6VHOO5fc+Z/QXRFRSQtXgJ9UlJeL38Ms5Ll16WbNx54d4YRVh/xHQTjyiKrD66mifjn2S02wg+KSjG9ezW1oOSN8Ga+WDnAbdvMTmhXMqHezJo1BvaXd3rmw2cPVhEULgrKmvzl9xd5d6JwegMRj7c3TbUvrcY5TGqpayTWVrHrrMlLBrth1Lezp9vxC3gFQ5b/mXSrtre1ZqB471IPVyMrtlA7OLQtr9LO18EBIgxfeGeVJyEvcqeQHvTHkYAsaFuRPd3ZeW2FCrq+s5uYPOJAh7cn0KTIHKziweT/aM5WLzbYmsTe2sli0f7seFYPmd3YFmmAAAgAElEQVRPloIAbiEe7HbxZbhewP7bWyXZZjtoYqLR5eTQnJHZA6+oZ+hwwhcEYasgCCdMfM29eJwozVLmPsr8RVEcCSwC3hAEwayWThCEO899OBwqKbGsxNHbVNQ1s/TTQ9ioFLx/UwRqpZya8kY2/+8sNopmBh18C/QdR/vZu1ozamYAaUklZB5rLW28yv8q7hp6Fz+m/siXZ75sc2xj8lkyb1iIrqAAvw/ex372rB57fZ0lyFXDMB971plowtIb9TyT8EyL9PLtqR9iGzBeUuuc/yA78hV8vRjcBkkre/uOrQ4q6pr5LD6TWUO9CHYzX5dPP1JCc4OegWN7tpxzngAXW+YM82LNvizK+2gCu7is80lCCgqZwKJIv/YPkslh1mtQVyJ1K5tg5PQArO2UjJ7dr20oTNEp6T0bfSfYmxYCJBUnMcJ1BDKh/Wnk8ZkDqW3S8+a23jeiq27U8dC3R1i2JhFXJzXBo9whp45Yl8mUNJRwrMRyq/LbxgeikMk4fqwEZy9bKgxlnK5KJTpsCRj1HSZmnQ83r427cszUOpzwRVGcIoriEBNf64EiQRA8Ac79W2zmHHnn/k0HdgJmTbNFUXxfFMWRoiiOdHV1NTesz9AZjNzzRSKFVY28d2MEnvbW6JoNbFx9DH2zgSkz7JFXFlvskDd8ih+Onrbs+jq5TcfjPcPvIdY3lpcPvsz+gv0tt9ft20/W4sUgivh/sQbbMWN69DV2hXkjvDldUM2ZwgtWC/W6eh7Y8QBrU9ZyR9gdPD/ueckMbdhCqMiAnAOQ8A78uAwCxsPNP0nh3Bbw8d4M6poN3D+p/Sup0/EFaF3UeJvYS+kp7psUTIPOwEd7+q6b9HxZZ93prUwP8zRrJdEKrxEwaikc/ADyj7S5W+Oo4ub/jCN8mom9gG3PgkoL4x8yeerShlIyqzMJd+848KS/ux0LI/1Ysy+LtJLajp93F4lPLeXq1+NYfySf5ZOCWXf3OCbMCMSoF3HOCkYhKCz31gHctWrmj/BCLGvC3kfTYlcd0/9aWPQtVOfDFwuk/ScTWPl4YxUcRN0VJM/sbknnJ+Dmc9/fDLRJvhAEwVEQBNW5712AccCpbj5un/H8hlMkpJfxf/PDCPdzRBRFtn96mtLcWqbePhjvq6OQu7hQveEXi87Xos0vb+LghtZlAZkg48XxLxKgDeCRXY+QW5NL1S+/kHPHHSg83An4+ivUoaG98TI7zexhra0WyhrKuH3L7ezJ28MTY55gefjyCyWCgbNBYS0ZoG35p/T/xd+Bqv066HmqGnT8b28mM8I86O9u/pjq0gZyz1QwIMoTQdZ7pa5gNztmDPHk0/gsqkw0MPUGozxGYS3XolMfaS3F7IiJ/wYbF/jlIZOpTnJTZaHsfXB2E4xbDjZOJk97pFj6ALE08OTBq/qjVsp5ceMZy5+7hTTqDDz78ykWfbgflVLO98uieGhqKFYKGY4etvgMcCR1bymR7qPZnr29UzX1xYO9UIsCp5sbicuNw8vWiyCHIPCNhOs+kWTE390CBtO/B5roGOoOHsJQ27dd2ubo7oT/H+AqQRBSgCnn/o8gCCMFQfjw3JiBwCFBEI4CO4D/iKL4u5jwv9yfzacJWdwxIZDrzgWQH96USerhYqKuCSIgzAVBoUA7fTq1O3diqLHMYMsr2IFB4zw5si2H0tzWx2isNKyctBKDUc+3Ty8m/+FHsB42jIAvvkDp1Ttliq7grFER09+V9Un5ZFRmceOmG0mtTOX12Nf5W+jfWg9W2UmTfGWWpK9f8CkoLPe2+d/eTGqa9Nw3MaTdcWcSCkDAbEh5T3LfpGBqm/R8Et83tXy5IEeoD8NKe4Yh3qabzUxi7SClY+UdhsRPOx7fYn/sDmPuNjsssTgRlVzFIGfLmvxcNCrunRjM1tNFxKd2L3LxYo7nVjHrrT18vDeDm6P82bh8AiP8WsuTh070obaiifG6q8mqziKt0nKVlbJK6jf5MaeQffn7WsJOABgwQ+p7SPkVNqwwqYjSxMSATkf9vo6jUfuCbk34oiiWiaI4WRTFkHOln/Jztx8SRXHpue/jRVEME0Vx2Ll/P+qJJ97b7E8v48n1J4jp78pj0yXbhPSkEvb/lEH/0e6MmHqhhmo/exZiczM1v7bvbHgxUfODUdsq2PlFMuIl3jS+tt6sOh7B9F+KSYvwwOfDD7rsZd+bzAv3prg5hcUbl1DTXMMHUz9gkt8k04OnPg/XfQyzV0r1ZQupadTx0Z50rhrkziAvrdlxolHkdEIBvgOdsHPqfYnqQE8tVw1y5+M9GdQ09v4q/2BmBaVFAxCFJuLz4zt3cNgCCJgAW5+B2g72xVJ+hewEiHkUrMwroZKKkhjiMqRtA1073DouAG8Ha57/pfue+XqDkZXbUpj3zl5qG/V8dlskz8wd0iYABsA/zAU7JzWq09JCoDNlnaL0auQqGXlWyTQaGonxvUSOOfJWiPkHJK2BHf/X5nib8BHIbG2vGHnmX522JsitqOfuLxLxc7Zh5cIRyGUCZXm1/Pa/U7gFaJm4ZEArRYM6LAylvx9VP3ecd9tyjK2ScdeFUJRRzcndFzY/jU1N5D34EOoftlE4axT/uqqED5MtWJldBtTaZGz930evV/L59M/bDx23c5di+TqpKvosIYvqRj3LJ7W/us9NrqC2vKnHOmstYfmkEKob9XyWYHm6V1f5LCETG0N/7K0c2JK1pXMHCwLMfFWqNW99yvw4o1H6UHAMhPCbzQ6r19Vzuvx0pwPL1Uo5j00fwKmCatZ2wzM/vaSWa99N4LXfzjJzqCdbVkQT3d/8fp9MJjAkxpuStDrGqGI6ZU9elFmNZ6A9vj6ZYLRiqIuJ1xz7T8kuOu6llozh8whKJbbjxl0x8sy/JvxLqGvSs/TTQ5L07qaR2Fsraahp5pd3jqFSy5mxLAyFsvUqQhAE7GfNpn7//k4FGPePdMdngCMJP6ZTV9WEobKS7Ntup+bXX3F77B/EvvwpM4Nm8/aRty1L7ulD1p5dyyNxD6JV+FCXsQx3axN+9t2ktknPB7vTmTTAjTCf9q9wTscXoLJREDise0ZpnSHMx57YUFc+2pPRq/7vRdWNbD5RyPUjA5jiP5ldObto1HeyD8A1FMbeD0e+gCwzVwjHv4Pik23sjy/lfOCJJRu2lzJrqCcj/Bx4ZUsydU2d+5kZjSKfJWQyY+VuMkvreHvRCN68YcQFL6F2GDTOC7lSRkTpFE6VnaKgtuP0L12zgdLcWtwDtIg2p9DVBbHxqIlylCDArDcgZBr88jCcbr3w08REoy8qoums6c7nvuSvCf8ijEaRR747ytmiGt5eFE4/Vw0GvZHN75+gvqqZ6XcPNeurbj97Fogi1b9stPjxBEEgZmEoBp2RuE+Pkbl4CY3HjuH9+ms433ILgiDwVNRTDHYezD93/5PUir5PXroUURR558g7PJ3wNGO8xvDCmFXUNdjy6ykLrBY6yZp9WVTW6zpU5jTW6UhPKqF/pEebD+Pe5v5JIZTXNfPFPtM+9D3Bl/uzMYgiS8b4M9V/KvX6evbm7+38iaL/DvZ+sOGhtpuM+mbY8Tx4DIXB89s9zfnAk2Guwzr9FARB4IlZ5zzz4yxXORVUNXDzJwd4cv1JRgc68+uD0cwaavmellqjlBrxku2x0ltbVNYpyapBNIoY3eopbyrCXTGC9+PSTZej5ApY8ImkjFp7O2RfUNnZjp8AcEWUdf6a8C9i5fYUNp0o5F8zBhLT3xVRFNn9zVnyUyqZeOMA3APM15CtAgJQh4VRtcF03q05HNxtGDbShvRTNRQ2OuD70Ydop09vuV+tUPPGxDewVlizfEfPe+h3Bp1Rx9MJT7P66GrmBs3lrUlvER0kOVZaZLXQCeqb9XwQl050f9c2m3CXknKwCIPe2KflnPNE+DsyLtiZ9+LSabQwPrAzNOuNfHkgm9j+rgS42DLKcxT2KvsOk7BMYmUDM16CktOwb3Xr+w6fsz+e0tr+2BSJxYn0d+yPnZVlKqtLCfdzZPYwL96PS6Ogyny4C0gLjPVH8pj2ehyHMit4/poh/O/WUbhbIku9hKGxPhh0ImNrplt0xXw+0vCU4hAAd42cRXppHb+a85GyspXkmlpv+Or6Fi8jpbsbqkEDrwg9/l8T/jk2HS/gja0pXBfhw+3jpc7BE7vyOLk7n/BpfoSONtPGfhH2s2fRdOo0TWmWqwDq4uNxePt+bJpKSRt5B1bDI9qM8bD14I2Jb1BQV8CjcY/2mId+Z6jX1bN8+3LWpazjrqF38dy451DKlMhkAnOHe7E7paRH7Qa+3J9NWV0zD0xuf3UPUjnHxVeDq1/XJqDucv+kEEprm/j6QM+v8recLKSkpombogIAyX9psp/UhNVkaGr/YFOETpfCaXb+50KEX1ONlJYVMAGCJrd7+KWBJ13l0Wmhkmf+ZvOe+RV1zdz3VRIPfH2EIDcNGx+YIIW9dLG73NXPDo9+WkILxnC4MJHKxsp2xxdlVKF1UbO7bCcDnQZyffgQApxtWL0rzXw93tYFlqwFmVLqJK+WSkea6Ggako5gqLp8Czb4a8IH4FR+NQ99e5RwPwdemDcEQRDIPVPO7m9TCAhzZvRc8yEbF6OdPh1kMqp+tmyVX/XTT2TfeRcqLw8mLRtJTZWBQxszTY4d7jacf4/+N/H58byZ+KalL61HKGso47YttxGfH8+TUU9y34j7Wv3RzT9ntfCTGauFztKoM/BeXDpjg5yJ8DetAz9PSU4NJdk1l2V1f54x/ZyJDHDi3V3pNOl7dpX/WUImfk42xFy0KTnVfyp1ujr25nWhrANw9X9ANMLmc5YJCe9I9sdTnu5wUz254lzgSRfq9xfj62TD7eMDWZeUx7HcthPvjuRipr0Rx5YThfx9Wijf3RVFYDv+SZYSFuuDUKXCszK4JabQHIUZ1Tj523Ck5AgTfCYglwncGR3EsdwqEtLKzB/oFCj1mTRUwBfXQWMVmugYMBioi++kwqqH+dNP+KW1Tdzx2SEcbJS8e2MEKoWcqpJ6Nn9wAgd3G666bXDrXM92ULi6YhsVRfWGX9rdkRdFkdL3PyD/0X9gExGB/xdr8B/djwFRHhz5NZuyPNPdiNf1v44bQm/gfyf/x89pnSsddZWs6iyWbFxCWmUab058kwX9F7QZE+xmR5i3PT8e6ZmyztcHsimpaWL55PaVOSClWskUAv1HdXwF1pvcPzmYwupGvj/cdfXJpZzKr+ZgZgU3Rfm3+h2M9IyUyjpmkrA6xNEfYv4Op3+WbC7i35JC4n1GdnjoecO07q7wAe6JlTzzn99wuuXvpa5Jz79/kPJlHWyU/HjvOO6dGIyiPd+gThAU7oa11oqRJVPaVevUVjRSV9lEtUMhRtHY4o45P9wbVzsVqztyTPUaDn/7DErOwDdLsB4citze/rLX8f/UE36z3sg9axIprW3i/RtH4manprlBzy/vHAcRZt4ThlUnDbi0s2ahy82l4UjbVnYA0WCg6LnnKHntNbQzZ+L7wfvI7aRSxNhrg7GyVrDry7ba/PM8GvkoI91H8nT805wsPdm5F9xJjpUc48aNN1Knq+OjaR8R6xtrduy8Ed6cyKsmpciy5jNzNOoMrN6VRmSgE2P6tW+7YNAZST5QSL9hrqg1HSs1epPxwS4M93Vg9c40dIaesQL+fF8maqVMijC8CKVMySTfSezM2dm1sg5A1P3g0l+yudDVweQnLTrMXOBJV7BTK3loan8OZJaz5WQhh7MqmLFyN18eyOaOCYH8dN94hnj3bP+JXCFj8Hgv3EuDOZZ+hnqd6WSwlvq9PBEntRNDXIYAkrT09vGB7E4p7TjNK3gyzF0FGXEIP9+H7fhx1O7ejWjsW6voi/nTTviiKPLUTyc4kFnOywuGEeZjj2gU+e2TU1QW1TPtziHYu5oO2GgPu6umIKhUVJvQ5BsbG8l94AEqvvwK56W34/XyS8isLjSuWGusGHttMAVpVZzaa7o8opQpeTX2VVysXVi+YzmlDT3XtXgxu3J2cfuW27FV2vL5jM/bTfcBmDPcC7lMMGmo1hm+O5xLUXUTD1iwus84VkpTnf6ylnPOIwgCyycHk1vR0GI30R2q6nX8kJTHNcO9TcoOpwVMo05XR3xeF0sECitJmw8wfJEk2+wAURRJLErskdX9ea4f6Ut/dw2PrTvOgnfj0RtEvrpjDP+eOQh1LymuBk/wRhAEQvJGkZBvugO2MKMauUJgZ8NmxnuPb2UQt2i0H3YqBe/GWbBXN+wGqVR2Yi0ax2IMZWU0nrx8RgN/2gn/831ZfHUgh3snBjFnmCTv2vdTOpnHShm/IATfAe3Xjs0h12jQTJpI9aZNiLoL0jd9RQXZt9xK7bbtuP/737g98giCCTXEgCgPvEIcSPghjfpq026MTmon3pz0JjXNNTy448EOPfQ7y3dnv2P5juUEOQTx+YzP8dd27N3iolERHeLC+qS8VqlenaFZb2T1jlQi/B0ZG9Sxqdrp+Hw0jip8BnbtveppJoa6McRbyzs7UtF3c5X/3eEcGnVGbjTjm3O+rNPpJqyLCYyGO3bAjFctGp5Tk0NZY1mPTvgKuYwnZg2iplHPteE+bF4xocMru+6icVTRb4QLA0ui2J6+w+SYoowqrD1kVOor2oSdaNVKlkT5s+l4ARmlFnjkjFsBkXdhW7sBhMvrnvmnnPDjU0t55udTTBnoxsNXSSubswcLSdycxaAJXoTFdi8X1n72bAwVFS0bNM25uWQtXETjqVN4v/EGTjcuMXusIAjELg5F12Rg71rzdrIDnAbw3LjnOFJyhBf2v9AjXXyiKPJ20ts8m/As47zG8fG0j3GxtryRaV64D/lVjezLaGdDqx3WJeaSX9XI/ZOCO1Ri1JQ3kn2qnAFRnhbvsfQ2giBw38QQMsvq2XCs48YecxjPRRiOCnBksJfpkkaPlHVACp1RWiZxPB9Y3tkO246YEOLK8aen8vKCYdip+6Y0N2yiLyq9DdlJVeiMrXsSDAYjJVk1VDkUohAURHlFtTn+1nEBKOQy3rekl0AQ4OoXUYTPRu3UTO3mH3vqZXSaP92En1VWxz1fJhLkasvr1w9HJhMozqpm+2dn8Ay2J/r6/t0OFdGMH4/c3p6qnzfQcOIkmTcsRF9Rgd8nH6OdNrXD4x09bAmf5s/Z/UXknC43O25awDTuCLuDdSnr+Dr56249Z51Rx5PxT/LesfeYHzKflZNWYqPsXElr6iB3NCoFP3RBk68zGFm1M5VhPvatFCnmSN5XCGLfGKV1hqmD3Al1t+PtHaldvtLZlVJCVlk9N56TYpp9rICp3SvrdJLEokTsVfb0c+jX8eBOYmPV82E17eEZ7IDKVSQ4dxSHCg+1uq88rw69zsgpxWEi3CNM9hu42alZEOHD2sO5HSa/AZJ/1Lz30Qx0ozElB32S5TYsPcmfasKvadSx9FPpzf3gppHYqZXUVTWxcfVxbOysmH5XGHJF938kgpUVdldfTc3WrWTddBMyKysCvvwCm4i2GntzREz3x97Vml1fJqNvp6HnvhH3EeMTw0sHXuJg4cEuPd96XT33b7+fH1N/5J5h9/B01NPtBjSbQ62UM32IB5tOFNLQ3Dl54o9JeeSUN7B8ckiHH7iiUQop9w51wN61E86RfYBMJnDfpGBSi2vZdKJr3cefxWfiaqfianMRhucY7TkarZW262qdTmJp4MnvAUEQiJgchEu9D7sOtv67KcqQNmOPCfuZ4DPB7DnujO6H3mjk472Zlj2oUo1m2auAQN2q+6HweBeffdf5/b9zFmI0ijz4zRHSS+t4Z1E4/s626HUGNr17nKYGPTPuGYq1neXOfx1hP2c2YmMjVv7++H/9Faogy7T851Eo5cQsCqWqpIHDm8ybc8kEGS9OeBFfrS8P73yYvNrOra5LG0q5dcut7MvfxzNjn+Hu4Xd36wpnXrg3tU16fjttuaeQ3mBk1Y5UBntpmTTArcPx+amVVJc29lqqVXeZEeZJP1db3tqe0ulVflZZHTvPlrAo0g+rDhYfSpmSSX5SWaen93EupayhjMzqTLOB5b9HhkT5YlDqqEwUWkUfFmZUI9gYqFG1H1bu72zLjDBPvtiXRbWFjqnq8DHInRypLVDDmuuk7uY+5E8z4b/6WzJbTxfz1OxBjA12QRRFdq5JpiijmqtuGYSLj/nYvK5gExGB36ef4v/55yjdOp7ETOE70In+o91J3JJFRaH5zSE7KztWTlyJ3qjnge0PmJWaXUpmVSZLNi4hoyqDlZNWMj+kfQ8VSxgT6IynvZofOuGG+POxfDLL6i1a3YPUWWulltNvxOVPRDOFXCZw38RgzhTWsLUTH3wg+QfJBYFFozuIMDzHVP+p1OpqO2+Z3EnOB570dP3+cqJUybEfKuJVPICkzAur7aKMaqocCvG39yfAPqDdcyyLCaKmSW+xl5Igk6GJiaW2WIPY3CDFJNabL9v2NH+KCX/9kTxW7UhjYaQfN46RVA9HfssheX8hkbMDe23isB0diVzTve7AcdeGoFTJJd/8djZmA+wDeCnmJVIqU3hi7xMdbuIeLTnKjZtupEHfwMfTPibaJ7pbz/M8ktWCN3EppZTUdLyZaDCKvLU9lQEedlw10L3D8c0NetIOFxMyyh2lCe/zK4U5w7zwd7bhre2pFm+oNzQb+OZgDtOGeFjsFTPGcwx2VnZd89bpBIeLD2Mls7I48OT3wuTpI5CLcvZulaSSjXU6KovqOas8ygRv8+Wc8wzxtmdCiAsf7cmw2EtJExONsaaWhmHPQkUWfHUD6Nr3FOop/vAT/vHcKh79/hiRAU48M2cwgiCQebyU+B9SCQp3Y+SMgMv9FNvFRmvF2PnB5KdUciah/ZrweO/xrAhfwa9Zv/Lh8Q/NjtuRvYOlW5aitdKyZvqalqaSnmJ+uDcGo8jPRzu2Wth4vID0kjrunxRikdom5VARep3xii3nnEchl3FPbBDH86rYebaD0JFzrD+SR3Wjnps72Ky9GKVcUuvsyNnRq2WdpKIkwlzDOhV48nvAx8edKvd89CckZ9yiTKnhKt82rW3YiRnujg2itLbJYo9/27FjQS6n9mwlzH9fynpeu9RkBGVP060JXxCEBYIgnBQEwSgIgtm+bEEQrhYEIVkQhFRBEB7rzmN2huKaRu747BAuGhWrl4RjpZBRUVjHbx+dxMVHw+SbB3ZbkdMXDBzriWeQPfFrU2mobf+P+pbBtzAjcAZvJb3Fzpydbe7/NvlbVuxcQYhjCJ/P+Bxfbc/72Pd3t2Owl7ZDqwWjUeSt7SmEuGmYPsSyzs3T8QU4edniFnB5jNI6w7wRkpPoW9tSOlzli6LIZwlZDPCwY1RA++6glzI1QCrrmGsi6i5dDTz5veA9Wo2qyZZ98ScpSq9CFETqHMqIcLNMZBHVz5lhvg7mrZMvQa7VYjNiBLVxcTD4Gpj+XzizATY+YjImsSfp7gr/BDAfMGsQIQiCHFgFTAcGAQsFQej168ImvYG7Pj9MVYOOD24aibNGRWOdjl/eOYZcKWPG3UNRqq7cksDFCDKBmMWhNDfoiV/bvie+IAg8M/YZBjgN4LHdj5FeKemERVFkZeJKntv3HBO8J/Dh1A9xUvdew9K8Ed4cy60itdi0LxBITpBni2q5b1KwRav78vw6ijKqGTjW83fxQW2lkLEsNojE7Eri2zPbAg5nVXCqoJqbogI6/dqiPKOksk4vqXWOlx7HIBp6tOHqSmLqhHFUqUo5uiObooxqqm2LifQbibKdEJiLEQSBu2P6kVVWz6YTlvVf2MZE03T6tBSYNPouqTnr0Mew+5XuvJQO6W6m7WlRFM37m0pEAqmiKKaLotgMfA3M7c7jWvC8+PcPJ0jKruS1vw1jkJcWo8HIrx+eoKaskel3hfVJ7mlP4uylYfhUP84kFJKXXNHuWLVCzZsT30QlV7F8x3LKG8t5fO/jfHD8A64NuZY3Jr7RaY19Z5kz3AuZAD8kmb7MNRpF3tyWQj8XW4uDLE4nFCCTCfSPvLxGaZ1hQYQP7loVK7eZb6ID+DQhCzu1gmtGdL5UpZQrmeg7kR3ZvVPWSSxOlAJP3DofePJ7wNPOk7KgVMQCa3KSy8mzSbOofn8xUwd50M/VltU727FOvghNtFQuqtu9W7phytMw9AbY/ryUj9tL9EUN3xvIuej/uedu6zU+2pPB94dzWTElhOlhUmPO3rWp5JyuIGZRKJ7BDr358L3GyBkBaF3U7PwyGYOu/dZ9T40nr8e+Tl5tHjPXzeSntJ+4d/i9PBX1VJc09p3FzU7NhBBXfkzKNylN3Hq6iDOFNdw3KRi5Bat7g8FI8r4CAoa6YKP9/dSR1Uo5d0UHsT+jnAMZptUYxdWNbDpewN9G+na5AWlawDRqdDXsK9jXnadrksQiKfBEa2U+AOj3TugYd3SyJkQDFNlltqu/N4VMJrAsOoiT+dXsTunY30rVPwSFh8cF90xBgDlvQdAk+Gk5nO2dq7UOJ3xBELYKgnDCxFevrNIFQbhTEIRDgiAcKimxbLPrYirrm3lzWwrTh3i0BF+f2pvPse25DJvky6BxV/ZmX3soreTELAylsqiexF87Ds4Odw/n8dGPYxANPDv2WZYNW9anpZD54d7kVTZwILP1RCeKIiu3p+DvbNPiY9QRWcfLaKjRXRFGaZ1lYaQfLhor3tpuepX/1YEc9EYpwrCrRHlGYae0Y0tmN7x1TNBTgSdXOlP6TyTFRWrKtPe16pSlyHnmjvDCQ6vm3Y6sk5HKQJroaOri4xGbz12VKawkS2WPIfDDXdBkvhzaVTqc8EVRnCKK4hATX+stfIw84OKdQZ9zt5l7vPdFURwpiuJIV9fOyyUdbKxYd/dYXlkwDJlMoCC1kl1fJuM70JGx13au+elKxG+wMyEj3Ti8KYvKoo719nc3GjMAABQYSURBVNf2v5b4hfHMC5nXB8+uNVMHeWBrJW9jtbAzuYQTedXcG2u5z/np+AJstFb4Db4yjNI6g7WVnDsm9GN3SilJ2a3LcTqDkS/2ZxHT37VbAR9KuZKJfhPZkbMD3aV5td2gpwJPrnT6OfSjcNAJ4gK/JWJAWJfOoVJI1snxaWUcyWk/TQvOyTPr6qhPTLroJHaw6DtY+DWoerY3CPqmpHMQCBEEIVAQBCvgBuCn3nzAEHc7bFUKasob2fTeceyc1UxdOgRZD4UoXG7GLQhBrpSx88v2tfnn6YsSjimsreRcPcSTjccLWjTKoijV7r0drJkXblllr66qiawTZQyI8vjdvodLxvjjaKPkre2tN923nCykuKaJm8d2fXV/nmkB06hpriGhoOfUOklF0mT0R1/hA4wPGcMpj73E+Ha9J2XhaD+0agXv7ux4lW87ZgwolZJa52Ls3MFvdJefQ3t0V5Y5TxCEXCAK+EUQhC3nbvcSBGEjgCiKeuA+YAtwGvhWFMXeTe4AdE0GNq4+hkFnZOY9Q1HbXt6AjJ7E1l5F1Lwg8pIrOHugc52cfc28Ed7UNOlbOk53p5RyJKeSeycGo7Rw8k7eV4hoFK84o7TOYKtScPv4QLafKeZE3oXgjM8SsvB1siamf9e6sS/mfFmnJ5uwEosT8bL16pHAkyudWwffyvPjnmeQU9dFhBqVgpvHBrDlVCFpJe2XZGS2ttiOGtmndsndVen8IIqijyiKKlEU3UVRnHbu9nxRFGdcNG6jKIr9RVEMEkXxhe4+aQueF9s+PUVZbi1Tlw7B0aP7WZhXGoPHe+EeqGXv9yk01vXcJXxPExXkjLtWxQ+JeS2rey97NddGWLa6F0WR0/EFeAbZ/+7fx5vGBqBVK1pq+acLqjmQUc6NY/wt2rjuiPNlne0523ukrHM+8OSPXs45j4PagbnBc7u9z3Xz2ACs5DLe39WxdbJtdDTNqWk05/ZMPGhH/D6vjzvg0MZM0hJLiJofjP+Q3g1TuFwIMoHYxQNorNOTsK59bf7lRC4TuGa4N7vOlrDhWAGHsyq4OzYIlcKyHojC9Goqi+oZ8DvcrL0UrVrJLeMC2XKyiDOF1XyWkIVKIeNvI3uu+W2q/1RqmntGrdMbgSd/Blw0Kq4f5cu6pFwKq9q3Tr4gz+ybrNs/3ITfWKvj6PYcQsd4MHxKz3eRXkm4+GgYPtmXU3sLyE/teJPocjEv3Bu9UeSR747iZqdiQScmuNPx+ShUcoIjul/yuBK4bVwAtlZy/rvpDD8m5TF3uBcONj0nM43yikKj1PSIWqe3Ak/+DNwxoR9GET7em9HuOKvAAJR+ftTu7Juyzh9uwldrlCx4bBSxi0N/F92Y3WXUrEDsnNTs/CIZg/7yhSO3xwAPLQM9tTTpjSyLCbI4q7S5UU/qoWJCItywUl+ejeeexsHGipvGBrAjuYQGnYGbOuGbYwlWcism+vZMWSepOAmtlbZXAk/+6Pg62TBrqGSdXFVv/n1okWfu34+x0YIglW7yh5vwAexdrVH0UgDylYZSJSf6hv5UFNRxZGvfemt3hqXjAxnirWVhpGW2vwBpiSXomgy/S+19eywdH4i1Uk64nwNDvE1HGHaHqQE9U9Y5H1j+Rwg8uRwsiwmirtnA5/sy2x2niYlGbGyk/mDXAow6w1/v5B+AgKEuBI1w5eAvmVSVWOaF39dcG+HDhvsnYN0JS+PT8fk4uNvgEdTzk+LlxFmjYs3S0bxxfe/Uxsd6jUWj1HTLW+d84MmfZcO2NxjoqWViqCuf7M1s1zrZZtQoBLX6QtdtL/LXhP8HYfzf+iOTC8R9dbZHAs0vN5VF9RSkVv1ujNI6S4S/I37OveNnZCW3ItY3lu3Z29sEdFvKHzHw5HJwd+z/t3fn0VXW6QHHv09ys9wsECABs0ACYQmKshgii0lQaFDH6tAZR2Zax5l26uixM9PRno6O+k+dOfWcTm17Tqcute0cW4+MiqhTcUG0ahskCQkCkiDIErIQEhIgJEC2p3/cmxEkN9td3su9z+ecHJObN3mf88p9cu/z/n7PM5sTXT28XHXU5zExiYkkX3cdZz78MOjPXUv4ESJlUgLLbp9F/d52DlQddzocv9Vua0ZihHnLIn/9dzCU5ZZxuuc025u3j+vnq49XR+TAk1BbmjeJJTPSeOajg/T1+77HllxaQu/Ro/QcPhzUeCzhR5AFpTlMzU3l45f3c36YG0XhbqB/gH3bmsm9ajLJExOcDueytCJ7BclxyePehFVzvIYF6QsibuBJqIkI962aTUPHWd7c7bt1ckqJZ3dv11d33QaYJfwIEjO4Nr+zh22vjbzpI1zV722n61RP2E+1CmcJsQmess7RsZd1unu7qT1Ra/X7AFldMJU5U1OGbZ0cn5NDfH5+0Ov4lvAjTMaMVK65cTqffdzIsYOnRv6BMFRX3ow7NY7cqyNz01yorM1dy6nzp6horhjTz+1u202f9ln9PkBiYoQfluZTd6xz2HGXKSUldFdWMtDVFbxYgvabjWOK/nAmKWkJ/M8LdfQPUzcMR2c7ezi0q425111BrMv+efrj92WdMa7WifSBJ064bWEWWRMTeWqYpmoppSVoby9d28d332U07BkVgeITXRTfOZcTjV18utX36oBw9HlFCwP9yvzLuFFauBgs62yt3zqmsk5NSw1zJs2J6IEnoRbviuEHxbOoONTOjiNDT6xLWrKEmKSkoJZ1LOFHqFmLMpi5MJ3K3x3idNtZp8MZFU+jtCam5k1gSnbge4FHo7LcMk6dP0Vl8+g29UTLwBMnrC+aTlpSnM8BKRIfT/LKFZz56KOgLc+0hB/Biu+cCzHCRxsuj7X5rfWdnGjsiridtU5amb1yTGWdfR376O7rtvp9ECTFu7h7eR5b9rawv6VzyGOSS0roa27m/P7hZyCPlyX8CJY6OZFlt83iyJ4TbH5qN92nAz/gOpBq/6+Z2LgY5iyd5nQoESMhNoHSnNJRl3UGB57YCp3guHtFHu64WJ75aOhVdMFenmkJP8Jdc2MOK785m6N729nw+HYO7hz7nOBQ6Ovp5/PKFvKXZJDgjoxGaeGiLK+Mk+dPUnls5LJONA08ccLk5HjWF03ntZpGmk5eWmqNmzaNhIKCoNXxLeFHOBFh0ZoZ3PHzQpLTEnjr6d28/3wtPWf7nA7tIl/UtNJzts/W3gfByqyVJLmSRtyEparUHK9h8TSr3wfTD4o93Uef+3jo1skppaUMdHWhfYF/jvo74vAOEflMRAZEpHCY4w6LyG4R2SkiVf6c04zPlKwUvvmzQq69OZe6bc1s+EUFTfvDp4d+bXkzE9ITyZ6T5nQoESfRlUjpdE9Zp2/AdxJp6Gyg7Wyb1e+DLDvNzW2LsthQWU9H16Vl1owf/4iZr25EXIF/p+vvK/w9wB8Bo3n/cYOqLlJVn38YTHDFumJYdns+6/7qWiRG2PRkNeWvHqC/19m1+qfbztK4r4OC5ZlIAEb9mUutzV3LyfMnqTjmexPWjuM7gOgYWO60e0vz6e7p5/ltRy75nsQGr7W7vzNta1V1X6CCMaGRmT+ROx9ZypXXZ1Hzbj0vP1FFW8PwA5eDqXZbMwiX9ZDycLcye+SyzuDAk/y0/BBGFp3mTktlzfyp/Kb8EN09oSuvhqqGr8C7IrJDRO4Z7kARuUdEqkSkqrU1PG8wRoL4RBc3/HEBX7v/Gro7e3j5iUqq3z3CwEBol28ODCh15c3MmD+Z1MmJIT13NEl0JVKaU8r79e/7LOvYwJPQum9VPh3dvbxUGbrNkSP+nxWR90RkzxAft4/hPNer6hLgZuB+ESnxdaCqPquqhapamJGRMYZTmPHIuzqdbz9WRN6CdLa9+gWvPVkd0o1ajXUdnOk4HxFDysNdWV4ZHec7hlyt036uncOnD1s5J4SuzZ1MUd5k/vXjQ/SGqAXKiAlfVdeo6oIhPl4f7UlUtdH73+PAJqBo/CGbQHOnxnPTDxew+u75tDWcYcMvKqgtbwrJZq3a8iYSkl3MWmh/3IPt+uzrcbvcQ27Cqjlu6++dcN+qfBpPnuV3nzaF5HxBf+8mIskikjr4OVCG52avCSMiQsHyTNY/VkTG9FTef76Ot54O7matc129HNzZxtyiK4iNszJCsCW6ElmVs4qtRy5drVPd4hl4ctWUqxyKLjqtmpdBwRWpPP3hFyEpp/q7LHOdiDQAy4E3ReQd7+NZIrLZe9g04H9F5FOgAnhTVd/257wmeCZMcfP1ny5mxTdmc+SzE2x4fDuHdrUF5Vz7K1vo7xuwVgohNFjWqWq5eHW0DTxxhohwb2k+n7ec4YN9wZ9U5+8qnU2qmqOqCao6TVXXeh9vUtVbvJ8fVNWF3o+rVPWXgQjcBI/ECIv/YAbfengpSRMT2Pwvu/jgP2vpORfY1QS15c2kT08hY3pqQH+v8e33ZZ0LVuvYwBNn3XpNJjmT3MO2Tg4Uex9tfJqSncIdPytkydpc9pY389tfVNB8IDCbtVqPdtJa32k7a0NscLXOhZuw9rTtoU/77IatQ1yxMfx58SyqjnRQebg9qOeyhG+GFRsXw/J1+ax70PPqb9PfV7Nt0xf09/m3qqCuvJkYlzC3yBqlhVpZXhnt59rZ0eLZaDU48GTR1EUORxa9vlU4ncnJ8Twd5Ff5lvDNqGTNTuPOR4uYvyKT6neO8PITVZxoHN9mrf7eAfZVHGPWogwSk+MCHKkZyVfLOtUt1TbwxGHu+Fi+vyKPrXXHqTt2OmjnsYRvRi0+0cUNd83nlvuupvvUeV7620pqttSjY1xdcGhXG+e7+uxmrUPcLjclOSW8V/8ePf09NvAkTNy1PJek+Fie+XDo1smBYAnfjNnMhRmsf+w6cq+aQvnGA7z2DzWcPjH6zVq15U2kTEogp2ByEKM0wynL9ZR1Xqx70QaehIm0pHi+UzSDNz5toqGjOyjnsIRvxiVpQjw333s1N363gNajnfz28QrqPmkecbNWZ/s56ve2U7A8kxhrlOaY4pxi3C43z3z6DGAbrsLFnxXPJEZ8t072lyV8M24iwvwVWax/tIgpOSls/U0tbz+7h7NnfG/W2vfJMVBrlOY0t8tNcXYxnb2dZCZn2sCTMJE50c26xdm8vrORc739Af/9lvCN3yaku/n6A0tYvi6fw7vbePFvKji8+9LNWjrgGVKePS+NiRluByI1FyrLKwPs1X24ebBsHlseKCUxLvBtki3hm4CIiRGWrM3ljoeWkpQax5u/3sUHL9RdtFmraf9JTreds7X3YaI4u5i5k+ZSllvmdCjmAtMmJJKekhCU323DQ01ApeekcMdDS9n+xkFq3qunoa6DNd+7ksz8idSWNxOfGMusxdYoLRwkxSWx8baNTodhQshe4ZuAi42LYcU3ZrPugcXogLLpVzso33iAL6qPM2fpNOLigzfRxxjjmyV8EzRZcyax/tEi5i3PpGZLPX29A1bOMcZBVtIxQRXvdrH6u/OZtTCdE41nmJpnjdKMcYolfBMSMxdmMNOGnBjjKCvpGGNMlLCEb4wxUcISvjHGRAl/Rxz+nYjUicguEdkkImk+jrtJRPaJyAERecifcxpjjBkff1/hbwEWqOo1wOfAw189QERigV8DNwNXAt8WkSv9PK8xxpgx8nem7buqOrh3/hMgZ4jDioAD3tm2PcAG4HZ/zmuMMWbsAlnD/1PgrSEezwaOXvB1g/exIYnIPSJSJSJVra2tAQzPGGOi24jr8EXkPWCo3qmPqOrr3mMeAfqAF/wNSFWfBZ4FKCwsHNsoJWOMMT6NmPBVdc1w3xeR7wG3Aqt16OkXjcD0C77O8T42oh07drSJyJHRHDuEdODSHr3Rya7Fxex6XMyux5ci4Vrk+vqGjDShaDgichPwJFCqqkPWX0TEheeG7mo8ib4S+I6qfjbuE48utipVLQzmOS4Xdi0uZtfjYnY9vhTp18LfGv4/A6nAFhHZKSJPA4hIlohsBvDe1P0L4B2gFngp2MneGGPMpfzqpaOqs3083gTccsHXm4HN/pzLGGOMfyJ5p+2zTgcQRuxaXMyux8Xsenwpoq+FXzV8Y4wxl49IfoVvjDHmApbwjTEmSkRcwrdGbV8Skeki8oGI7BWRz0TkJ07H5DQRiRWRGhH5b6djcZqIpInIK94GiLUistzpmJwkIj/1Pk/2iMiLIpLodEyBFlEJ3xq1XaIPeFBVrwSWAfdH+fUA+Ame5cEG/gl4W1ULgIVE8XURkWzgx0Chqi4AYoH1zkYVeBGV8LFGbRdR1WZVrfZ+3onnCe2zj1GkE5Ec4GvAc07H4jQRmQiUAP8GoKo9qnrS2agc5wLc3s2iSUCTw/EEXKQl/DE1aosmIpIHLAa2OxuJo/4R+GtgwOlAwsBMoBX4D2+J6zkRSXY6KKeoaiPwK6AeaAZOqeq7zkYVeJGW8M0QRCQF2Aj8paqedjoeJ4jIrcBxVd3hdCxhwgUsAZ5S1cVAFxC197xEZBKeasBMIAtIFpE/cTaqwIu0hD/uRm2RSkTi8CT7F1T1VafjcdBK4DYROYyn1HejiPyXsyE5qgFoUNXBd3yv4PkDEK3WAIdUtVVVe4FXgRUOxxRwkZbwK4E5IjJTROLx3HR5w+GYHCMigqdGW6uqTzodj5NU9WFVzVHVPDz/Lt5X1Yh7BTdaqnoMOCoi87wPrQb2OhiS0+qBZSKS5H3erCYCb2L71Usn3Khqn4gMNmqLBf49yhu1rQTuAnaLyE7vYz/39jYy5kfAC94XRweB7zscj2NUdbuIvAJU41ndVkMEtlmw1grGGBMlIq2kY4wxxgdL+MYYEyUs4RtjTJSwhG+MMVHCEr4xxkQJS/jGGBMlLOEbY0yU+H9ml/upW55VNgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = np.arange(1, 11); print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlnK3gnSiOoO",
        "outputId": "47ffe3c7-ab6e-4160-dd40-ca14cc3f5923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2  3  4  5  6  7  8  9 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((k[:, np.newaxis], k[:, np.newaxis]), axis=1).reshape(-1)[np.newaxis, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1icQD_WiR_r",
        "outputId": "db7d07cf-692a-441f-c01b-bb1bcc163934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,\n",
              "         9,  9, 10, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.cbook import file_requires_unicode\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "_patterns = [r\"\\'\", r\"\\\"\", r\"\\.\", r\"<br \\/>\", r\",\", r\"\\(\", r\"\\)\", r\"\\!\", r\"\\?\", r\"\\;\", r\"\\:\", r\"\\s+\"]\n",
        "_replacements = [\" '  \", \"\", \" . \", \" \", \" , \", \" ( \", \" ) \", \" ! \", \" ? \", \" \", \" \", \" \"]\n",
        "\n",
        "_patterns_dict = list((re.compile(p), r) for p, r in zip(_patterns, _replacements))\n",
        "\n",
        "class TokenTokenizer(object):\n",
        "  \"\"\"Turn text into eassily digestible tokens\"\"\"\n",
        "  def __init__(self, vocab_size=50):\n",
        "    self.patterns_dict = _patterns_dict\n",
        "    self.vocab_size = vocab_size\n",
        "    self.vocab = None\n",
        "    self.merges = None\n",
        "  \n",
        "  def pre_tokenizer(self, text):\n",
        "    text = text.lower()\n",
        "    for pattern, repl in self.patterns_dict:\n",
        "      re.sub(pattern, repl, text, count=100)\n",
        "    return text\n",
        "\n",
        "  def compute_pair_freqs(self, splits, word_freqs):\n",
        "    pair_freqs = defaultdict(int)\n",
        "    for word, ct in word_freqs.items():\n",
        "      split = splits[word]\n",
        "      if len(split) == 1:\n",
        "        continue\n",
        "      for i in range(len(split) - 1):\n",
        "        pair = (split[i], split[i+1])\n",
        "        pair_freqs[pair] += ct\n",
        "\n",
        "    return pair_freqs\n",
        "  \n",
        "  def merge_pair(self, a, b, splits):\n",
        "    for word, split in splits.items():\n",
        "      if len(split) == 1:\n",
        "        continue\n",
        "      i=0\n",
        "      while i<len(split) - 1:\n",
        "        if split[i] == a and split[i+1] ==b:\n",
        "          split = split[:i] + [a+b] + split[i+2:]\n",
        "        else:\n",
        "          i += 1\n",
        "      splits[word] = split\n",
        "    return splits\n",
        "\n",
        "\n",
        "  def train_tokenize(self, text):\n",
        "    text = self.pre_tokenizer(text)\n",
        "    words = text.split()\n",
        "    word_freq = Counter(words)\n",
        "    vocab = []\n",
        "    for w, ct in word_freq.items():\n",
        "      for l in w:\n",
        "        if l not in vocab:\n",
        "          vocab.append(l)\n",
        "    merges = {} # tuple to merge\n",
        "    splits = {word: [ c for c in word] for word in word_freq.keys()}\n",
        "    while len(vocab) < self.vocab_size:\n",
        "      pair_freqs = self.compute_pair_freqs(splits, word_freq)\n",
        "      best_pair, ct = max(pair_freqs.items(), key=lambda x: x[1])\n",
        "      merges[best_pair] = best_pair[0] + best_pair[1]\n",
        "      vocab.append(merges[best_pair])\n",
        "      # apply the merge to the splits\n",
        "      splits = self.merge_pair(*best_pair, splits)\n",
        "    self.vocab = vocab\n",
        "    self.merges=merges\n",
        "\n",
        "# Write a bpe tokenizer for a corpus of text, consisting of training and segmentation\n",
        "# 1. Throw away punctuation\n",
        "# 2. Input, one long string or list of strings?\n",
        "# 3. find top pairs\n",
        "# 4. merge top pairs\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "examples = [(\"ASDFASDF\", \"asdfasdf\"), (\".\", \" .  \")]\n",
        "examples = [(\"ASDFASDF\", \"asdf asdf\"), (\"aaaa ssss aa asdflkjzc,mvnawkeilkvzn\", \" .  \")]\n",
        "\n",
        "t = TokenTokenizer(vocab_size=7)\n",
        "for input, out in examples:\n",
        "  print(t.train_tokenize(input), out)\n"
      ],
      "metadata": {
        "id": "uTqzz_HV-W8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f513b1d-8414-4bf4-e1c0-aa80d3e8e900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None asdf asdf\n",
            "None  .  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Head attention"
      ],
      "metadata": {
        "id": "SBWMGSWVbrvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention2(torch.nn.Module):\n",
        "  \"\"\" Computes single head of attention. \"\"\"\n",
        "\n",
        "  def __init__(self, batch_size, seq_len, input_dim, dk, dv):\n",
        "    \"\"\"Compute attention for an input of shape (seq_len, input_dim)\n",
        "     Args: batch_size should be 1\n",
        "           seq_len is the tokens\n",
        "           input_dim is the len of embedding vector\n",
        "    Outputs: attention() = Softmax(K @ Q/sqrt(dk)) @ V\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.input_dim = input_dim\n",
        "    self.dk = dk\n",
        "    self.dv = dv\n",
        "    # torch.nn -> Modules (layers) -- params that are maintained & updated\n",
        "    # torch.nn.functional -> functions -- no params, just computation\n",
        "    self.WQ = torch.nn.Linear(input_dim, dk).to(device)# (seq_len, input_dim) (input_dim, dk) ->(seq_len, dk)\n",
        "    self.WK = torch.nn.Linear(input_dim, dk).to(device)# (seq_len, input_dim) (input_dim, dk) ->(seq_len, dk)\n",
        "    self.WV = torch.nn.Linear(input_dim, dv).to(device)# (seq_len, seq_len) * (seq_len, dv) -> (seq_len, dv)\n",
        "\n",
        "  def create_qkv_mat(self, x):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    Q = self.WQ(x) # x= (Seq_len, input_dim), Q = ()\n",
        "    K = self.WK(x)\n",
        "    #pdb.set_trace()\n",
        "    V = self.WV(x)\n",
        "    return Q, K, V\n",
        "\n",
        "  def forward(self, x, use_mask=False):\n",
        "    Q, K, V = self.create_qkv_mat(x)\n",
        "    QK_t = Q @ K.T  # (seq_len, dk)(seq_len, dk).T = (seq_len, seq_len)\n",
        "    if use_mask:\n",
        "      mask = torch.tril(torch.ones_like(QK_t)).to(device)\n",
        "      QK_t[mask==0] = -torch.inf #  (seq_len, seq_len)\n",
        "      \n",
        "    norm_qk_t = QK_t / torch.sqrt(torch.tensor(self.dk)) # (seq_len, seq_len)\n",
        "    probs = F.softmax(norm_qk_t, dim=0) # (seq_len, seq_len)\n",
        "    reweighted_V = probs @ V # (seq_len, seq_len) (seq_len, dv) \n",
        "    return reweighted_V"
      ],
      "metadata": {
        "id": "xq8xFngn9TNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(torch.Tensor([0,0,-torch.inf,1]) , dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoDC00uhRFQr",
        "outputId": "d24e7560-5dec-4663-98b0-b6c6478fdb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2119, 0.2119, 0.0000, 0.5761])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(10, 4)\n",
        "bart_tron = SingleHeadAttention2(1, 10, 4, 5, 3)\n",
        "print(bart_tron(data)) # __ call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a74wvyQv75Lz",
        "outputId": "f435bb69-3ad0-4479-840a-e15e3721c8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1547, -0.4380, -0.1854],\n",
            "        [-0.1666, -0.4731, -0.2169],\n",
            "        [-0.1605, -0.4501, -0.2088],\n",
            "        [-0.1645, -0.4650, -0.2198],\n",
            "        [-0.1649, -0.4663, -0.2196],\n",
            "        [-0.1561, -0.4391, -0.1937],\n",
            "        [-0.1578, -0.4446, -0.2012],\n",
            "        [-0.1560, -0.4433, -0.1919],\n",
            "        [-0.1621, -0.4584, -0.2094],\n",
            "        [-0.1711, -0.4876, -0.2355]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Untitled drawing.svg](data:image/svg+xml;base64,<svg version="1.1" viewBox="0.0 0.0 960.0 720.0" fill="none" stroke="none" stroke-linecap="square" stroke-miterlimit="10" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><clipPath id="p.0"><path d="m0 0l960.0 0l0 720.0l-960.0 0l0 -720.0z" clip-rule="nonzero"/></clipPath><g clip-path="url(#p.0)"><path fill="#000000" fill-opacity="0.0" d="m0 0l960.0 0l0 720.0l-960.0 0z" fill-rule="evenodd"/><path fill="#cfe2f3" d="m93.67979 82.973755l311.81104 0l0 286.3937l-311.81104 0z" fill-rule="evenodd"/><path stroke="#000000" stroke-width="1.0" stroke-linejoin="round" stroke-linecap="butt" d="m93.67979 82.973755l311.81104 0l0 286.3937l-311.81104 0z" fill-rule="evenodd"/><path fill="#000000" d="m122.50791 235.43748q2.109375 1.453125 3.890625 2.125l-0.890625 2.109375q-2.46875 -0.890625 -4.921875 -2.8125q-2.546875 1.421875 -5.625 1.421875q-3.109375 0 -5.640625 -1.5q-2.53125 -1.5 -3.90625 -4.21875q-1.359375 -2.71875 -1.359375 -6.125q0 -3.390625 1.375 -6.171875q1.375 -2.78125 3.90625 -4.234375q2.546875 -1.453125 5.6875 -1.453125q3.171875 0 5.71875 1.515625q2.546875 1.5 3.875 4.21875q1.34375 2.703125 1.34375 6.109375q0 2.828125 -0.859375 5.09375q-0.859375 2.25 -2.59375 3.921875zm-6.671875 -3.875q2.625 0.734375 4.328125 2.1875q2.671875 -2.4375 2.671875 -7.328125q0 -2.78125 -0.953125 -4.859375q-0.9375 -2.078125 -2.765625 -3.21875q-1.8125 -1.15625 -4.078125 -1.15625q-3.390625 0 -5.625 2.328125q-2.234375 2.3125 -2.234375 6.921875q0 4.46875 2.203125 6.859375q2.21875 2.390625 5.65625 2.390625q1.625 0 3.0625 -0.609375q-1.421875 -0.921875 -3.0 -1.3125l0.734375 -2.203125zm14.078133 6.328125l0 -22.90625l3.03125 0l0 11.359375l11.375 -11.359375l4.109375 0l-9.609375 9.28125l10.03125 13.625l-4.0 0l-8.15625 -11.59375l-3.75 3.65625l0 7.9375l-3.03125 0z" fill-rule="nonzero"/><path fill="#ff0000" d="m101.71129 84.31233l297.10236 0l0 38.803154l-297.10236 0z" fill-rule="evenodd"/><path stroke="#000000" stroke-width="1.0" stroke-linejoin="round" stroke-linecap="butt" d="m101.71129 84.31233l297.10236 0l0 38.803154l-297.10236 0z" fill-rule="evenodd"/><path fill="#cfe2f3" d="m438.51443 82.973755l196.7244 0l0 286.3937l-196.7244 0z" fill-rule="evenodd"/><path stroke="#000000" stroke-width="1.0" stroke-linejoin="round" stroke-linecap="butt" d="m438.51443 82.973755l196.7244 0l0 286.3937l-196.7244 0z" fill-rule="evenodd"/><path fill="#ff0000" d="m443.87402 88.32809l36.125977 0l0 275.68503l-36.125977 0z" fill-rule="evenodd"/><path stroke="#000000" stroke-width="1.0" stroke-linejoin="round" stroke-linecap="butt" d="m443.87402 88.32809l36.125977 0l0 275.68503l-36.125977 0z" fill-rule="evenodd"/><path fill="#000000" fill-opacity="0.0" d="m125.80052 377.39896l267.65356 0l0 42.015747l-267.65356 0z" fill-rule="evenodd"/><path fill="#000000" d="m135.64427 400.02206l1.65625 -0.140625q0.125 1.0 0.546875 1.640625q0.4375 0.640625 1.34375 1.046875q0.921875 0.390625 2.0625 0.390625q1.0 0 1.78125 -0.296875q0.78125 -0.296875 1.15625 -0.8125q0.375 -0.53125 0.375 -1.15625q0 -0.625 -0.375 -1.09375q-0.359375 -0.46875 -1.1875 -0.796875q-0.546875 -0.203125 -2.390625 -0.640625q-1.828125 -0.453125 -2.5625 -0.84375q-0.96875 -0.5 -1.4375 -1.234375q-0.46875 -0.75 -0.46875 -1.671875q0 -1.0 0.578125 -1.875q0.578125 -0.890625 1.671875 -1.34375q1.109375 -0.453125 2.453125 -0.453125q1.484375 0 2.609375 0.484375q1.140625 0.46875 1.75 1.40625q0.609375 0.921875 0.65625 2.09375l-1.6875 0.125q-0.140625 -1.265625 -0.9375 -1.90625q-0.78125 -0.65625 -2.3125 -0.65625q-1.609375 0 -2.34375 0.59375q-0.734375 0.59375 -0.734375 1.421875q0 0.71875 0.53125 1.171875q0.5 0.46875 2.65625 0.96875q2.15625 0.484375 2.953125 0.84375q1.171875 0.53125 1.71875 1.359375q0.5625 0.828125 0.5625 1.90625q0 1.0625 -0.609375 2.015625q-0.609375 0.9375 -1.75 1.46875q-1.140625 0.515625 -2.578125 0.515625q-1.8125 0 -3.046875 -0.53125q-1.21875 -0.53125 -1.921875 -1.59375q-0.6875 -1.0625 -0.71875 -2.40625zm19.459198 1.1875l1.6875 0.203125q-0.40625 1.484375 -1.484375 2.3125q-1.078125 0.8125 -2.765625 0.8125q-2.125 0 -3.375 -1.296875q-1.234375 -1.3125 -1.234375 -3.671875q0 -2.453125 1.25 -3.796875q1.265625 -1.34375 3.265625 -1.34375q1.9375 0 3.15625 1.328125q1.234375 1.3125 1.234375 3.703125q0 0.15625 0 0.4375l-7.21875 0q0.09375 1.59375 0.90625 2.453125q0.8125 0.84375 2.015625 0.84375q0.90625 0 1.546875 -0.46875q0.640625 -0.484375 1.015625 -1.515625zm-5.390625 -2.65625l5.40625 0q-0.109375 -1.21875 -0.625 -1.828125q-0.78125 -0.953125 -2.03125 -0.953125q-1.125 0 -1.90625 0.765625q-0.765625 0.75 -0.84375 2.015625zm15.297592 9.46875l0 -4.734375q-0.375 0.546875 -1.0625 0.90625q-0.6875 0.34375 -1.46875 0.34375q-1.71875 0 -2.96875 -1.375q-1.234375 -1.375 -1.234375 -3.765625q0 -1.46875 0.5 -2.625q0.515625 -1.15625 1.46875 -1.75q0.96875 -0.59375 2.109375 -0.59375q1.796875 0 2.828125 1.515625l0 -1.296875l1.46875 0l0 13.375l-1.640625 0zm-5.046875 -8.5625q0 1.859375 0.78125 2.796875q0.78125 0.9375 1.875 0.9375q1.046875 0 1.796875 -0.890625q0.765625 -0.890625 0.765625 -2.703125q0 -1.9375 -0.796875 -2.90625q-0.796875 -0.96875 -1.875 -0.96875q-1.0625 0 -1.8125 0.90625q-0.734375 0.90625 -0.734375 2.828125zm7.750717 8.5625l0 -1.1875l10.859375 0l0 1.1875l-10.859375 0zm11.844467 -3.703125l0 -13.359375l1.640625 0l0 13.359375l-1.640625 0zm10.816696 -3.109375l1.6875 0.203125q-0.40625 1.484375 -1.484375 2.3125q-1.078125 0.8125 -2.765625 0.8125q-2.125 0 -3.375 -1.296875q-1.234375 -1.3125 -1.234375 -3.671875q0 -2.453125 1.25 -3.796875q1.265625 -1.34375 3.265625 -1.34375q1.9375 0 3.15625 1.328125q1.234375 1.3125 1.234375 3.703125q0 0.15625 0 0.4375l-7.21875 0q0.09375 1.59375 0.90625 2.453125q0.8125 0.84375 2.015625 0.84375q0.90625 0 1.546875 -0.46875q0.640625 -0.484375 1.015625 -1.515625zm-5.390625 -2.65625l5.40625 0q-0.109375 -1.21875 -0.625 -1.828125q-0.78125 -0.953125 -2.03125 -0.953125q-1.125 0 -1.90625 0.765625q-0.765625 0.75 -0.84375 2.015625zm9.141342 5.765625l0 -9.671875l1.46875 0l0 1.375q1.0625 -1.59375 3.078125 -1.59375q0.875 0 1.609375 0.3125q0.734375 0.3125 1.09375 0.828125q0.375 0.5 0.515625 1.203125q0.09375 0.453125 0.09375 1.59375l0 5.953125l-1.640625 0l0 -5.890625q0 -1.0 -0.203125 -1.484375q-0.1875 -0.5 -0.671875 -0.796875q-0.484375 -0.296875 -1.140625 -0.296875q-1.046875 0 -1.8125 0.671875q-0.75 0.65625 -0.75 2.515625l0 5.28125l-1.640625 0zm14.465271 0l3.53125 -5.03125l-3.265625 -4.640625l2.046875 0l1.484375 2.265625q0.421875 0.640625 0.671875 1.078125q0.40625 -0.59375 0.734375 -1.0625l1.640625 -2.28125l1.953125 0l-3.34375 4.546875l3.59375 5.125l-2.015625 0l-1.984375 -3.0l-0.515625 -0.8125l-2.546875 3.8125l-1.984375 0zm14.948929 -2.890625l1.625 -0.25q0.125 0.96875 0.75 1.5q0.625 0.515625 1.75 0.515625q1.125 0 1.671875 -0.453125q0.546875 -0.46875 0.546875 -1.09375q0 -0.546875 -0.484375 -0.875q-0.328125 -0.21875 -1.671875 -0.546875q-1.8125 -0.46875 -2.515625 -0.796875q-0.6875 -0.328125 -1.046875 -0.90625q-0.359375 -0.59375 -0.359375 -1.3125q0 -0.640625 0.296875 -1.1875q0.296875 -0.5625 0.8125 -0.921875q0.375 -0.28125 1.03125 -0.46875q0.671875 -0.203125 1.421875 -0.203125q1.140625 0 2.0 0.328125q0.859375 0.328125 1.265625 0.890625q0.421875 0.5625 0.578125 1.5l-1.609375 0.21875q-0.109375 -0.75 -0.640625 -1.171875q-0.515625 -0.421875 -1.46875 -0.421875q-1.140625 0 -1.625 0.375q-0.46875 0.375 -0.46875 0.875q0 0.3125 0.1875 0.578125q0.203125 0.265625 0.640625 0.4375q0.234375 0.09375 1.4375 0.421875q1.75 0.453125 2.4375 0.75q0.6875 0.296875 1.078125 0.859375q0.390625 0.5625 0.390625 1.40625q0 0.828125 -0.484375 1.546875q-0.46875 0.71875 -1.375 1.125q-0.90625 0.390625 -2.046875 0.390625q-1.875 0 -2.875 -0.78125q-0.984375 -0.78125 -1.25 -2.328125zm16.609375 -0.21875l1.6875 0.203125q-0.40625 1.484375 -1.484375 2.3125q-1.078125 0.8125 -2.765625 0.8125q-2.125 0 -3.375 -1.296875q-1.234375 -1.3125 -1.234375 -3.671875q0 -2.453125 1.25 -3.796875q1.265625 -1.34375 3.265625 -1.34375q1.9375 0 3.15625 1.328125q1.234375 1.3125 1.234375 3.703125q0 0.15625 0 0.4375l-7.21875 0q0.09375 1.59375 0.90625 2.453125q0.8125 0.84375 2.015625 0.84375q0.90625 0 1.546875 -0.46875q0.640625 -0.484375 1.015625 -1.515625zm-5.390625 -2.65625l5.40625 0q-0.109375 -1.21875 -0.625 -1.828125q-0.78125 -0.953125 -2.03125 -0.953125q-1.125 0 -1.90625 0.765625q-0.765625 0.75 -0.84375 2.015625zm15.297592 9.46875l0 -4.734375q-0.375 0.546875 -1.0625 0.90625q-0.6875 0.34375 -1.46875 0.34375q-1.71875 0 -2.96875 -1.375q-1.234375 -1.375 -1.234375 -3.765625q0 -1.46875 0.5 -2.625q0.515625 -1.15625 1.46875 -1.75q0.96875 -0.59375 2.109375 -0.59375q1.796875 0 2.828125 1.515625l0 -1.296875l1.46875 0l0 13.375l-1.640625 0zm-5.046875 -8.5625q0 1.859375 0.78125 2.796875q0.78125 0.9375 1.875 0.9375q1.046875 0 1.796875 -0.890625q0.765625 -0.890625 0.765625 -2.703125q0 -1.9375 -0.796875 -2.90625q-0.796875 -0.96875 -1.875 -0.96875q-1.0625 0 -1.8125 0.90625q-0.734375 0.90625 -0.734375 2.828125zm7.750717 8.5625l0 -1.1875l10.85939 0l0 1.1875l-10.85939 0zm11.844467 -3.703125l0 -13.359375l1.640625 0l0 13.359375l-1.640625 0zm10.816711 -3.109375l1.6875 0.203125q-0.40625 1.484375 -1.484375 2.3125q-1.078125 0.8125 -2.765625 0.8125q-2.125 0 -3.375 -1.296875q-1.234375 -1.3125 -1.234375 -3.671875q0 -2.453125 1.25 -3.796875q1.265625 -1.34375 3.265625 -1.34375q1.9375 0 3.15625 1.328125q1.234375 1.3125 1.234375 3.703125q0 0.15625 0 0.4375l-7.21875 0q0.09375 1.59375 0.90625 2.453125q0.8125 0.84375 2.015625 0.84375q0.90625 0 1.546875 -0.46875q0.640625 -0.484375 1.015625 -1.515625zm-5.390625 -2.65625l5.40625 0q-0.109375 -1.21875 -0.625 -1.828125q-0.78125 -0.953125 -2.03125 -0.953125q-1.125 0 -1.90625 0.765625q-0.765625 0.75 -0.84375 2.015625zm9.141327 5.765625l0 -9.671875l1.46875 0l0 1.375q1.0625 -1.59375 3.078125 -1.59375q0.875 0 1.609375 0.3125q0.734375 0.3125 1.09375 0.828125q0.375 0.5 0.515625 1.203125q0.09375 0.453125 0.09375 1.59375l0 5.953125l-1.640625 0l0 -5.890625q0 -1.0 -0.203125 -1.484375q-0.1875 -0.5 -0.671875 -0.796875q-0.484375 -0.296875 -1.140625 -0.296875q-1.046875 0 -1.8125 0.671875q-0.75 0.65625 -0.75 2.515625l0 5.28125l-1.640625 0z" fill-rule="nonzero"/><path fill="#000000" fill-opacity="0.0" d="m493.8294 388.10498l156.5669 0l0 42.015747l-156.5669 0z" fill-rule="evenodd"/><path fill="#000000" d="m503.67316 410.72812l1.65625 -0.140625q0.125 1.0 0.546875 1.640625q0.4375 0.640625 1.34375 1.046875q0.921875 0.390625 2.0625 0.390625q1.0 0 1.78125 -0.296875q0.78125 -0.296875 1.15625 -0.8125q0.375 -0.53125 0.375 -1.15625q0 -0.625 -0.375 -1.09375q-0.359375 -0.46875 -1.1875 -0.796875q-0.546875 -0.203125 -2.390625 -0.640625q-1.828125 -0.453125 -2.5625 -0.84375q-0.96875 -0.5 -1.4375 -1.234375q-0.46875 -0.75 -0.46875 -1.671875q0 -1.0 0.578125 -1.875q0.578125 -0.890625 1.671875 -1.34375q1.109375 -0.453125 2.453125 -0.453125q1.484375 0 2.609375 0.484375q1.140625 0.46875 1.75 1.40625q0.609375 0.921875 0.65625 2.09375l-1.6875 0.125q-0.140625 -1.265625 -0.9375 -1.90625q-0.78125 -0.65625 -2.3125 -0.65625q-1.609375 0 -2.34375 0.59375q-0.734375 0.59375 -0.734375 1.421875q0 0.71875 0.53125 1.171875q0.5 0.46875 2.65625 0.96875q2.15625 0.484375 2.953125 0.84375q1.171875 0.53125 1.71875 1.359375q0.5625 0.828125 0.5625 1.90625q0 1.0625 -0.609375 2.015625q-0.609375 0.9375 -1.75 1.46875q-1.140625 0.515625 -2.578125 0.515625q-1.8125 0 -3.046875 -0.53125q-1.21875 -0.53125 -1.921875 -1.59375q-0.6875 -1.0625 -0.71875 -2.40625zm19.459167 1.1875l1.6875 0.203125q-0.40625 1.484375 -1.484375 2.3125q-1.078125 0.8125 -2.765625 0.8125q-2.125 0 -3.375 -1.296875q-1.234375 -1.3125 -1.234375 -3.671875q0 -2.453125 1.25 -3.796875q1.265625 -1.34375 3.265625 -1.34375q1.9375 0 3.15625 1.328125q1.234375 1.3125 1.234375 3.703125q0 0.15625 0 0.4375l-7.21875 0q0.09375 1.59375 0.90625 2.453125q0.8125 0.84375 2.015625 0.84375q0.90625 0 1.546875 -0.46875q0.640625 -0.484375 1.015625 -1.515625zm-5.390625 -2.65625l5.40625 0q-0.109375 -1.21875 -0.625 -1.828125q-0.78125 -0.953125 -2.03125 -0.953125q-1.125 0 -1.90625 0.765625q-0.765625 0.75 -0.84375 2.015625zm15.297607 9.46875l0 -4.734375q-0.375 0.546875 -1.0625 0.90625q-0.6875 0.34375 -1.46875 0.34375q-1.71875 0 -2.96875 -1.375q-1.234375 -1.375 -1.234375 -3.765625q0 -1.46875 0.5 -2.625q0.515625 -1.15625 1.46875 -1.75q0.96875 -0.59375 2.109375 -0.59375q1.796875 0 2.828125 1.515625l0 -1.296875l1.46875 0l0 13.375l-1.640625 0zm-5.046875 -8.5625q0 1.859375 0.78125 2.796875q0.78125 0.9375 1.875 0.9375q1.046875 0 1.796875 -0.890625q0.765625 -0.890625 0.765625 -2.703125q0 -1.9375 -0.796875 -2.90625q-0.796875 -0.96875 -1.875 -0.96875q-1.0625 0 -1.8125 0.90625q-0.734375 0.90625 -0.734375 2.828125zm7.7507324 8.5625l0 -1.1875l10.859375 0l0 1.1875l-10.859375 0zm11.844482 -3.703125l0 -13.359375l1.640625 0l0 13.359375l-1.640625 0zm10.81665 -3.109375l1.6875 0.203125q-0.40625 1.484375 -1.484375 2.3125q-1.078125 0.8125 -2.765625 0.8125q-2.125 0 -3.375 -1.296875q-1.234375 -1.3125 -1.234375 -3.671875q0 -2.453125 1.25 -3.796875q1.265625 -1.34375 3.265625 -1.34375q1.9375 0 3.15625 1.328125q1.234375 1.3125 1.234375 3.703125q0 0.15625 0 0.4375l-7.21875 0q0.09375 1.59375 0.90625 2.453125q0.8125 0.84375 2.015625 0.84375q0.90625 0 1.546875 -0.46875q0.640625 -0.484375 1.015625 -1.515625zm-5.390625 -2.65625l5.40625 0q-0.109375 -1.21875 -0.625 -1.828125q-0.78125 -0.953125 -2.03125 -0.953125q-1.125 0 -1.90625 0.765625q-0.765625 0.75 -0.84375 2.015625zm9.141357 5.765625l0 -9.671875l1.46875 0l0 1.375q1.0625 -1.59375 3.078125 -1.59375q0.875 0 1.609375 0.3125q0.734375 0.3125 1.09375 0.828125q0.375 0.5 0.515625 1.203125q0.09375 0.453125 0.09375 1.59375l0 5.953125l-1.640625 0l0 -5.890625q0 -1.0 -0.203125 -1.484375q-0.1875 -0.5 -0.671875 -0.796875q-0.484375 -0.296875 -1.140625 -0.296875q-1.046875 0 -1.8125 0.671875q-0.75 0.65625 -0.75 2.515625l0 5.28125l-1.640625 0zm14.902771 -10.90625l0.421875 -1.296875q1.453125 0.515625 2.109375 0.890625q-0.171875 -1.65625 -0.1875 -2.265625l1.328125 0q-0.03125 0.890625 -0.21875 2.25q0.9375 -0.46875 2.15625 -0.875l0.421875 1.296875q-1.15625 0.390625 -2.265625 0.515625q0.546875 0.484375 1.5625 1.71875l-1.09375 0.78125q-0.53125 -0.734375 -1.25 -1.96875q-0.671875 1.28125 -1.1875 1.96875l-1.078125 -0.78125q1.0625 -1.296875 1.515625 -1.71875q-1.171875 -0.234375 -2.234375 -0.515625zm19.365479 10.90625l0 -1.21875q-0.90625 1.4375 -2.703125 1.4375q-1.15625 0 -2.125 -0.640625q-0.96875 -0.640625 -1.5 -1.78125q-0.53125 -1.140625 -0.53125 -2.625q0 -1.453125 0.484375 -2.625q0.484375 -1.1875 1.4375 -1.8125q0.96875 -0.625 2.171875 -0.625q0.875 0 1.546875 0.375q0.6875 0.359375 1.109375 0.953125l0 -4.796875l1.640625 0l0 13.359375l-1.53125 0zm-5.171875 -4.828125q0 1.859375 0.78125 2.78125q0.78125 0.921875 1.84375 0.921875q1.078125 0 1.828125 -0.875q0.75 -0.890625 0.75 -2.6875q0 -1.984375 -0.765625 -2.90625q-0.765625 -0.9375 -1.890625 -0.9375q-1.078125 0 -1.8125 0.890625q-0.734375 0.890625 -0.734375 2.8125zm11.969421 4.828125l-3.6875 -9.671875l1.734375 0l2.078125 5.796875q0.328125 0.9375 0.625 1.9375q0.203125 -0.765625 0.609375 -1.828125l2.140625 -5.90625l1.6875 0l-3.65625 9.671875l-1.53125 0z" fill-rule="nonzero"/><path fill="#000000" fill-opacity="0.0" d="m495.16797 255.61417l467.0551 0l0 42.015747l-467.0551 0z" fill-rule="evenodd"/><path fill="#000000" d="m507.9336 282.53418l-3.53125 -13.359375l1.8125 0l2.03125 8.765625q0.328125 1.375 0.5625 2.71875q0.5 -2.140625 0.59375 -2.46875l2.546875 -9.015625l2.125 0l1.921875 6.765625q0.71875 2.515625 1.03125 4.71875q0.265625 -1.265625 0.671875 -2.890625l2.09375 -8.59375l1.78125 0l-3.671875 13.359375l-1.703125 0l-2.8125 -10.171875q-0.359375 -1.28125 -0.421875 -1.5625q-0.203125 0.90625 -0.390625 1.5625l-2.828125 10.171875l-1.8125 0zm17.764893 0l-3.6875 -9.671875l1.734375 0l2.078125 5.796875q0.328125 0.9375 0.625 1.9375q0.203125 -0.765625 0.609375 -1.828125l2.140625 -5.90625l1.6875 0l-3.65625 9.671875l-1.53125 0z" fill-rule="nonzero"/></g></svg>)"
      ],
      "metadata": {
        "id": "9Q2C_8TK0afE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi Headed attention "
      ],
      "metadata": {
        "id": "l-5a868M2DBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(torch.nn.Module):\n",
        "  \"\"\"For input, compute multi headed attention.\"\"\"\n",
        "\n",
        "  def __init__(self, batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim, mask):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.seq_len = seq_len\n",
        "    self.input_dim = input_dim\n",
        "    self.dk = dk\n",
        "    self.dv = dv\n",
        "    self.num_heads = num_heads\n",
        "    self.output_dim = output_dim\n",
        "    self.mask = mask\n",
        "\n",
        "    self.single_heads = [SingleHeadAttention2(self.batch_size, self.seq_len, self.input_dim, self.dk, self.dv) for i in range(self.num_heads)]\n",
        "    # (seq_len, input_dim)\n",
        "    # (seq_len, dv) -> (seq_len, dv * num_heads)\n",
        "    self.linear_layer = torch.nn.Linear(self.dv * self.num_heads, self.output_dim)  \n",
        "\n",
        "  def forward(self, x): # (seq_len, input_dim)\n",
        "    attention_output = [head(x, use_mask=self.mask) for head in self.single_heads] # -> (seq_len, dv) * num_heads\n",
        "    attention_concat = torch.concat(attention_output, dim=1) # -> (seq_len, dv * num_heads)\n",
        "    output = self.linear_layer(attention_concat) # (seq_len, output_dim)\n",
        "    return output\n",
        "\n",
        "data = torch.rand(10, 4)\n",
        "bart_tron = MultiHeadedAttention(1, 10, 4, 5, 3, 2, 7, False)\n",
        "print(bart_tron(data)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "8R0QYxg_2Cb2",
        "outputId": "b3acfd7c-42d6-4fcc-d2c7-b6740dc9fd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-0b2b6dd7e7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbart_tron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadedAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbart_tron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0b2b6dd7e7df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# (seq_len, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_heads\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# -> (seq_len, dv) * num_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mattention_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (seq_len, dv * num_heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0b2b6dd7e7df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# (seq_len, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_heads\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# -> (seq_len, dv) * num_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mattention_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (seq_len, dv * num_heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-c44d9f06dfb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, use_mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_qkv_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mQK_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# (seq_len, dk)(seq_len, dk).T = (seq_len, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-c44d9f06dfb5>\u001b[0m in \u001b[0;36mcreate_qkv_mat\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x= (Seq_len, input_dim), Q = ()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Block"
      ],
      "metadata": {
        "id": "vRHjAvxf-Vti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(torch.nn.Module):\n",
        "  \"\"\" One multi headed attention and one FF network \"\"\"\n",
        "  def __init__(self, batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.seq_len = seq_len\n",
        "    self.input_dim = input_dim\n",
        "    self.dk = dk\n",
        "    self.dv = dv\n",
        "    self.num_heads = num_heads\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.multi_headed_attention = MultiHeadedAttention(batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim, mask=False) # (seq_len, output_dim)\n",
        "    self.feed_forward = torch.nn.Sequential(\n",
        "        torch.nn.Linear(output_dim, output_dim // 2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(output_dim //2, output_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    attention_output = self.multi_headed_attention(x) # (seq_len, output_dim)\n",
        "    assert self.output_dim == self.input_dim\n",
        "    attention_normed = F.layer_norm(x + attention_output, attention_output.shape)  # (seq_len, output_dim)\n",
        "\n",
        "    output = self.feed_forward(attention_normed) # (seq_len, output_dim//2 )\n",
        "    output_normed = F.layer_norm(output + attention_normed, output.shape)\n",
        "    return output_normed\n",
        "\n",
        "data = torch.rand(10, 4)\n",
        "bart_tron = EncoderBlock(1, 10, 4, 5, 3, 2, 4)\n",
        "print(bart_tron(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "LaFqx-Cv-U38",
        "outputId": "136cb37e-b6be-4376-800f-ddca8c57c540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b2e9a0006ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbart_tron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbart_tron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-b2e9a0006ca1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_headed_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mattention_normed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0b2b6dd7e7df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# (seq_len, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_heads\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# -> (seq_len, dv) * num_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mattention_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (seq_len, dv * num_heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-0b2b6dd7e7df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# (seq_len, input_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_heads\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# -> (seq_len, dv) * num_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mattention_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -> (seq_len, dv * num_heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-c44d9f06dfb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, use_mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_qkv_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mQK_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# (seq_len, dk)(seq_len, dk).T = (seq_len, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-c44d9f06dfb5>\u001b[0m in \u001b[0;36mcreate_qkv_mat\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x= (Seq_len, input_dim), Q = ()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(torch.nn.Module):\n",
        "  \"\"\" One masked multi headed attention, one unmasked multi headed attention and one FF network \"\"\"\n",
        "  def __init__(self, batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.seq_len = seq_len\n",
        "    self.input_dim = input_dim\n",
        "    self.dk = dk\n",
        "    self.dv = dv\n",
        "    self.num_heads = num_heads\n",
        "    self.output_dim = output_dim\n",
        "    self.masked_multi_headed_attention = MultiHeadedAttention(batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim, mask=True) # (seq_len, output_dim)\n",
        "    self.multi_headed_attention = MultiHeadedAttention(batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim, mask=False) # (seq_len, output_dim)\n",
        "    self.feed_forward = torch.nn.Sequential(\n",
        "        torch.nn.Linear(output_dim, output_dim // 2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(output_dim //2, output_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    attention_output = self.masked_multi_headed_attention(x) # (seq_len, output_dim)\n",
        "    assert self.output_dim == self.input_dim\n",
        "    attention_normed = F.layer_norm(x + attention_output, attention_output.shape)  # (seq_len, output_dim)\n",
        "    \n",
        "    attention_output_2 = self.multi_headed_attention(attention_normed) # why not have a mask\n",
        "    attention_output_2normed = F.layer_norm( attention_normed + attention_output_2, attention_output_2.shape )\n",
        "    \n",
        "    output = self.feed_forward(attention_output_2normed) # (seq_len,)\n",
        "    output_normed = F.layer_norm(output + attention_normed, output.shape)\n",
        "    return output_normed\n",
        "\n",
        "# data = torch.rand(10, 4)\n",
        "# bart_tron = DecoderBlock(1, 10, 4, 5, 3, 2, 4)\n",
        "# print(bart_tron(data))"
      ],
      "metadata": {
        "id": "cRmx17NXU4-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(torch.nn.Module):\n",
        "  \"\"\"Decoder only language model\"\"\"\n",
        "  def __init__(self, vocab_size, batch_size, seq_len, input_dim, dk, dv,\n",
        "               num_heads, output_dim, n_iter):\n",
        "    super().__init__()\n",
        "    #assert input_dim == output_dim ==dv\n",
        "    self.batch_size = batch_size\n",
        "    self.seq_len = seq_len\n",
        "    self.input_dim = input_dim\n",
        "    self.dk = dk\n",
        "    self.dv = dv\n",
        "    self.num_heads = num_heads\n",
        "    self.output_dim = output_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.pos_embedding = PositionalEmbedding(seq_len, input_dim, True)\n",
        "    self.embedding = EmbeddingModule(self.vocab_size, self.input_dim)\n",
        "    self.n_iter = n_iter\n",
        "    self.decoder = DecoderBlock(batch_size, seq_len, input_dim, dk, dv, num_heads, output_dim)\n",
        "    self.linear = torch.nn.Linear(self.input_dim, self.vocab_size) # y =  (seq_len*output_dim) * m\n",
        "\n",
        "  def forward(self, x): # (seq_len)\n",
        "    pemb = self.pos_embedding(x) #(seq_len, input_dim)\n",
        "    emb = self.embedding(x) #(seq_len, input_dim)\n",
        "    emb = emb.reshape(self.seq_len, self.input_dim)\n",
        "    output_sofar = emb + pemb # (seq_len, input_dim)\n",
        "    #print(output_sofar.shape)\n",
        "    for i in range(self.n_iter):\n",
        "      output_sofar = self.decoder(output_sofar) # (seq_len, output_dim)\n",
        "    vocab_scores = self.linear(output_sofar) # seq_len, vocab_size\n",
        "    # vocab_probs = F.softmax(vocab_scores, dim=1)\n",
        "    # return vocab_probs\n",
        "    return vocab_scores\n",
        "\n",
        "x = torch.randint(0, 10, (1, 10)).to(device)\n",
        "tessnet = Transformer(vocab_size=50, batch_size=1, seq_len=10, input_dim=6,\n",
        "                      dk=5, dv=3, num_heads=2, output_dim=6, n_iter=3).to(device)\n",
        "ret = tessnet(x)\n",
        "print(ret)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pySoAA2ilSk",
        "outputId": "4102381c-0f56-4a03-f63a-5659b69284b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-9.7888e-01, -4.3803e-02,  6.3744e-01,  5.6731e-01, -4.4684e-01,\n",
            "          1.1047e-01, -1.7762e-01, -7.8596e-01,  8.3556e-01,  8.4169e-02,\n",
            "         -3.9172e-01,  9.8802e-02, -1.1116e+00,  1.9350e-01, -5.1177e-01,\n",
            "          8.9474e-01, -3.3718e-01, -9.0381e-02,  1.0305e-01,  2.4366e-01,\n",
            "          3.8544e-02,  4.4166e-01,  2.7463e-01, -5.8168e-01,  6.2907e-01,\n",
            "          9.2202e-02, -1.0096e+00, -5.9019e-02, -2.2597e-01,  1.1297e-01,\n",
            "         -2.7611e-01, -4.2991e-01, -4.4143e-01, -6.7549e-01, -2.1527e-01,\n",
            "         -4.6445e-01,  1.2388e-01,  4.9269e-01,  6.7246e-01, -8.2479e-01,\n",
            "         -6.7629e-01, -5.8613e-01,  3.6058e-01, -4.4129e-01,  8.1227e-01,\n",
            "          2.0587e-01, -7.1310e-01, -2.1889e-01,  8.3677e-01,  1.0875e-01],\n",
            "        [-9.4309e-01, -1.7975e-02,  8.3512e-02,  8.1356e-01, -7.3327e-02,\n",
            "          4.1351e-01,  2.7484e-01, -7.4846e-01,  9.8321e-01,  1.9517e-01,\n",
            "         -3.7474e-01, -1.1777e-02, -1.0547e+00,  1.0992e-01, -4.1311e-01,\n",
            "          8.9929e-01, -4.7590e-01, -2.7250e-01,  1.4999e-01,  3.8569e-01,\n",
            "         -1.1699e-01,  1.0346e-01,  3.7644e-01, -2.5138e-01,  5.6563e-01,\n",
            "          5.1277e-01, -1.2632e+00, -7.9777e-03, -4.1498e-01, -1.0631e-01,\n",
            "         -3.3053e-01, -3.1249e-01, -8.6561e-01, -4.7206e-01, -3.7446e-01,\n",
            "         -3.1874e-01,  6.7461e-01,  4.6193e-01,  5.3514e-01, -5.4225e-01,\n",
            "         -7.7024e-01, -6.9117e-01,  4.8730e-01, -2.8868e-01,  1.0307e+00,\n",
            "          7.6433e-02, -7.2945e-01, -5.9934e-01,  1.1913e+00, -1.7110e-02],\n",
            "        [-8.7425e-01,  2.9018e-01,  3.2258e-01,  5.1090e-01,  1.1255e-01,\n",
            "          6.9558e-02,  3.7438e-01, -7.6705e-01,  1.0916e+00, -1.0357e-01,\n",
            "         -4.1613e-01, -1.8899e-01, -1.1166e+00, -1.9916e-01, -7.4064e-01,\n",
            "          4.0556e-01, -7.4226e-01, -4.5727e-01,  1.4062e-01,  2.4148e-01,\n",
            "         -1.8735e-01, -8.3871e-02,  3.1714e-01,  1.1382e-01,  7.8894e-01,\n",
            "          7.0266e-01, -1.1841e+00, -1.7075e-01, -3.8002e-01, -4.5917e-01,\n",
            "         -2.9390e-01, -2.3383e-01, -1.2394e+00, -3.9780e-01, -2.8089e-01,\n",
            "         -5.1322e-01,  2.6584e-01,  4.6956e-01,  4.7950e-01, -4.6948e-01,\n",
            "         -9.8864e-01, -5.1884e-01,  1.2037e-01, -6.8673e-01,  9.6303e-01,\n",
            "         -9.1520e-02, -6.5251e-01, -7.5762e-01,  8.1091e-01,  2.9702e-01],\n",
            "        [-1.0976e+00,  2.5650e-01,  5.4644e-01,  2.9041e-01, -1.8514e-01,\n",
            "          9.0652e-02,  2.3798e-01, -7.6178e-01,  1.2555e+00, -1.3654e-02,\n",
            "         -5.6264e-01, -3.5150e-01, -1.1661e+00, -2.9048e-01, -7.6205e-01,\n",
            "          5.8885e-01, -3.7689e-01, -3.5789e-01, -9.8934e-03,  3.6211e-01,\n",
            "         -3.2782e-01,  2.2889e-01,  2.0413e-01, -1.8141e-01,  7.4628e-01,\n",
            "          3.2314e-01, -1.2439e+00, -3.3662e-01, -2.9090e-01, -1.2980e-01,\n",
            "         -4.0170e-01, -3.5976e-01, -1.0567e+00, -7.5114e-01, -2.7091e-01,\n",
            "         -6.2082e-01,  3.1105e-02,  3.7963e-01,  4.4002e-01, -7.0351e-01,\n",
            "         -1.0279e+00, -5.8880e-01,  1.9248e-01, -4.2191e-01,  1.1305e+00,\n",
            "         -5.3814e-02, -5.8586e-01, -5.8096e-01,  8.3084e-01,  1.9057e-01],\n",
            "        [-1.2145e+00,  3.6603e-01,  1.1838e+00,  1.6375e-01, -2.5704e-01,\n",
            "         -4.0908e-01, -5.4909e-03, -3.1630e-01,  1.1563e+00,  3.5591e-03,\n",
            "         -8.6925e-01, -2.2298e-01, -1.4667e+00, -2.9413e-01, -9.6982e-01,\n",
            "          4.8199e-01, -1.2692e-01, -4.4364e-01,  2.7476e-01,  5.6558e-01,\n",
            "         -1.8629e-01,  3.2341e-01,  7.0471e-02, -7.4749e-01,  7.8578e-01,\n",
            "         -2.4029e-01, -1.0300e+00, -5.6173e-01, -1.1555e-01, -1.5154e-01,\n",
            "         -3.8075e-01, -4.1598e-01, -8.4067e-01, -7.2217e-01, -2.9858e-02,\n",
            "         -9.4133e-01, -5.2451e-01,  2.7902e-01,  7.1857e-01, -7.4140e-01,\n",
            "         -1.1624e+00, -8.6887e-01,  2.0337e-01, -3.9866e-01,  1.0255e+00,\n",
            "          7.1576e-02, -2.4142e-01, -3.5876e-01,  8.2314e-01,  5.4304e-01],\n",
            "        [-1.0027e+00,  4.3501e-01,  8.9802e-01, -2.4355e-02,  4.3589e-03,\n",
            "         -3.5413e-01,  1.5557e-01, -9.5016e-01,  1.1894e+00, -4.2900e-01,\n",
            "         -3.9751e-01, -3.9536e-01, -1.1350e+00, -4.4786e-01, -1.1773e+00,\n",
            "          1.1599e-01, -8.5896e-01, -3.8304e-01, -5.6916e-02,  1.1439e-02,\n",
            "         -2.9676e-01,  7.0852e-02,  2.7321e-01,  2.1858e-01,  1.0910e+00,\n",
            "          6.4479e-01, -1.0751e+00, -4.0307e-01, -1.3869e-01, -4.9479e-01,\n",
            "         -3.1764e-01, -3.3003e-01, -1.3511e+00, -6.5951e-01, -1.1371e-01,\n",
            "         -8.2533e-01, -4.4493e-01,  4.2903e-01,  3.8685e-01, -7.2052e-01,\n",
            "         -1.1540e+00, -2.5339e-01, -3.2689e-01, -1.0480e+00,  8.8821e-01,\n",
            "         -2.6091e-01, -6.8882e-01, -6.9099e-01,  2.2304e-01,  5.9408e-01],\n",
            "        [-1.3518e+00,  3.5470e-01,  9.9060e-01, -3.1157e-01, -1.6245e-01,\n",
            "         -2.8504e-01,  1.9447e-01, -7.1886e-01,  1.4608e+00, -2.2131e-01,\n",
            "         -6.4845e-01, -7.2705e-01, -1.0850e+00, -6.5743e-01, -1.1647e+00,\n",
            "          3.3861e-01, -2.7715e-01, -3.2773e-01, -3.1162e-01,  3.7591e-01,\n",
            "         -6.0729e-01,  2.9408e-01,  9.0209e-02, -1.2527e-01,  9.5151e-01,\n",
            "          1.4618e-01, -1.2033e+00, -7.7191e-01,  3.2606e-02, -1.5057e-01,\n",
            "         -5.0885e-01, -4.4343e-01, -1.2540e+00, -1.0560e+00, -1.1822e-01,\n",
            "         -9.7241e-01, -6.4488e-01,  1.3507e-01,  1.6626e-01, -8.1975e-01,\n",
            "         -1.2187e+00, -4.4931e-01, -1.3712e-01, -4.5865e-01,  1.1858e+00,\n",
            "         -4.1860e-01, -4.6852e-01, -6.0710e-01,  4.3761e-01,  3.4202e-01],\n",
            "        [-8.9349e-01,  4.4887e-01,  1.0102e+00,  2.2499e-01,  1.7144e-01,\n",
            "         -5.7698e-01,  1.1442e-01, -5.7573e-01,  9.4301e-01, -3.5734e-01,\n",
            "         -5.0383e-01, -9.8803e-02, -1.2875e+00, -2.6808e-01, -1.1438e+00,\n",
            "          4.7202e-02, -8.7531e-01, -5.0354e-01,  3.0344e-01,  1.4788e-01,\n",
            "         -4.6098e-02, -1.0537e-01,  2.7481e-01, -5.4128e-02,  1.0350e+00,\n",
            "          4.9547e-01, -9.0180e-01, -3.6223e-01, -1.3524e-01, -6.9150e-01,\n",
            "         -2.1750e-01, -2.6273e-01, -1.2308e+00, -3.1829e-01, -2.6673e-06,\n",
            "         -8.6537e-01, -4.3881e-01,  4.2668e-01,  6.4274e-01, -5.1576e-01,\n",
            "         -1.1330e+00, -4.9044e-01, -2.0348e-01, -1.0741e+00,  7.0233e-01,\n",
            "         -1.3777e-01, -4.8840e-01, -6.4574e-01,  4.0086e-01,  7.9674e-01],\n",
            "        [-9.5335e-01,  1.2271e-01,  4.5925e-01,  7.3231e-02, -4.8715e-02,\n",
            "         -1.9865e-01,  2.6543e-01,  1.3862e-01,  9.4290e-01,  1.2562e-01,\n",
            "         -7.5620e-01, -3.8963e-01, -6.6541e-01, -3.4373e-01, -3.7138e-01,\n",
            "          3.2248e-01,  2.3971e-01, -3.9054e-01, -2.7949e-01,  8.1365e-01,\n",
            "         -2.4745e-01, -2.7613e-02, -2.8779e-01, -4.2092e-01,  2.8368e-01,\n",
            "         -4.6581e-01, -6.8651e-01, -8.1089e-01,  9.6972e-02, -1.8250e-01,\n",
            "         -2.8773e-01, -1.7853e-01, -5.4999e-01, -5.4955e-01, -1.1477e-01,\n",
            "         -5.9552e-01, -3.8596e-01, -1.0954e-01,  9.8752e-02, -1.4777e-01,\n",
            "         -5.7808e-01, -6.7877e-01,  4.6206e-01,  1.4267e-01,  6.9610e-01,\n",
            "         -5.0065e-01,  3.5383e-02, -3.1007e-01,  8.8849e-01, -2.3596e-01],\n",
            "        [-1.4343e+00,  6.7002e-01,  8.3367e-01, -1.7286e-01,  9.4058e-01,\n",
            "         -5.9059e-01,  8.9901e-01, -5.7794e-01,  1.6891e+00, -4.3843e-01,\n",
            "         -6.5341e-01, -8.8655e-01, -1.3433e+00, -9.8689e-01, -1.8389e+00,\n",
            "         -1.5846e-01, -1.0914e+00, -8.1533e-01,  1.2270e-01,  4.4613e-01,\n",
            "         -8.5393e-01, -5.5261e-01,  4.9498e-01,  5.0064e-01,  1.4292e+00,\n",
            "          1.1589e+00, -1.5737e+00, -8.9171e-01, -4.5897e-02, -1.1119e+00,\n",
            "         -5.9268e-01, -2.8820e-01, -2.5621e+00, -4.9914e-01, -5.4544e-02,\n",
            "         -1.2906e+00, -3.6398e-01,  5.7493e-02,  1.2538e-01, -3.6508e-01,\n",
            "         -1.8861e+00, -6.3252e-01, -5.1672e-01, -9.0056e-01,  1.4555e+00,\n",
            "         -8.1028e-01, -4.5318e-01, -1.5337e+00,  5.8901e-01,  1.0567e+00]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchdata.datapipes.iter.util.tfrecordloader import TFRecordExampleFeature\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english') # _basic_english_normalize, which normalize the string first and split by space.\n",
        "\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>']) # any word not in vocabulary is unk\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "def data_process(raw_text_iter):\n",
        "  \"\"\"applies tokenization to vocab\"\"\"\n",
        "  \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "  data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "  return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "def chunker(data, window_size):\n",
        "  \"\"\"Creating input into smaller sequences\"\"\"\n",
        "  seq_len = data.size(0) // window_size # num windows\n",
        "  data = data[:seq_len * window_size] # drop_last=True\n",
        "  data = data.view(window_size, seq_len).t().contiguous()\n",
        "  return data.to(device)\n",
        "\n",
        "window_size = 10\n",
        "eval_window_size = 10\n",
        "train_data = chunker(train_data, window_size)  # shape [seq_len, batch_size]\n",
        "val_data = chunker(val_data, eval_window_size)\n",
        "test_data = chunker(test_data, eval_window_size)\n",
        "\n",
        "bptt = 1\n",
        "def get_batch(source, i):\n",
        "  seq_len = min(bptt, len(source) - 1 - i)\n",
        "  data = source[i:i+seq_len]\n",
        "  target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "  return data, target"
      ],
      "metadata": {
        "id": "znMeVGD88a6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
        "ntokens = len(vocab)\n",
        "epochs = 10\n",
        "\n",
        "print(train_data.shape) # train_data = [seq_len, batch_size]\n",
        "tessnet = Transformer(vocab_size=ntokens, batch_size=1, seq_len=10, input_dim=16,\n",
        "                      dk=5, dv=10, num_heads=2, output_dim=16, n_iter=3).to(device)\n",
        "optimizer = torch.optim.SGD(tessnet.parameters(), lr=5.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "tessnet.train()\n",
        "print(device)\n",
        "for i in range(epochs):\n",
        "  for p in range(train_data.shape[0]):\n",
        "    data, target = get_batch(train_data, p) # data is tokens, target is tokens\n",
        "    #data = data.reshape(10)\n",
        "    target = target.reshape(10)\n",
        "    ## cross entropy loss\n",
        "    #print(data)\n",
        "    data = data.to(device)\n",
        "    #print(next(tessnet.parameters()).is_cuda, data.is_cuda)\n",
        "    pred = tessnet(data)\n",
        "    #print(pred.view(-1, ntokens).shape, target.shape)\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    output = loss(pred, target)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    output.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(tessnet.parameters(), 0.5)\n",
        "    optimizer.step()\n",
        "    if p % 100 ==99:\n",
        "      print(output.item())\n"
      ],
      "metadata": {
        "id": "7bhWIgF3GCo6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b689811-b04d-4de5-9159-83cb667a0522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([204999, 10])\n",
            "cuda\n",
            "9.407470703125\n",
            "8.549514770507812\n",
            "8.150704383850098\n",
            "8.068041801452637\n",
            "7.712569236755371\n",
            "8.697060585021973\n",
            "7.427594184875488\n",
            "8.379158020019531\n",
            "7.042017459869385\n",
            "7.030007362365723\n",
            "9.458014488220215\n",
            "6.34900426864624\n",
            "8.666813850402832\n",
            "8.984743118286133\n",
            "8.003644943237305\n",
            "7.869693756103516\n",
            "8.297019004821777\n",
            "7.932302951812744\n",
            "7.850955009460449\n",
            "7.639202117919922\n",
            "7.164543151855469\n",
            "7.44292688369751\n",
            "8.805148124694824\n",
            "7.069933891296387\n",
            "8.83287525177002\n",
            "7.141129970550537\n",
            "7.47350549697876\n",
            "6.714293479919434\n",
            "10.11689567565918\n",
            "7.7196550369262695\n",
            "7.966147422790527\n",
            "6.618116855621338\n",
            "6.429417610168457\n",
            "7.485820770263672\n",
            "6.254817008972168\n",
            "7.770826816558838\n",
            "8.826681137084961\n",
            "7.426016330718994\n",
            "6.958164215087891\n",
            "6.894402980804443\n",
            "7.524172306060791\n",
            "7.398170471191406\n",
            "7.199459075927734\n",
            "8.566872596740723\n",
            "8.441158294677734\n",
            "9.211034774780273\n",
            "6.901258945465088\n",
            "6.522246360778809\n",
            "6.310817718505859\n",
            "6.010660648345947\n",
            "7.070153713226318\n",
            "6.5841064453125\n",
            "6.632681369781494\n",
            "6.680120944976807\n",
            "7.782346248626709\n",
            "7.912947654724121\n",
            "8.569764137268066\n",
            "8.23784065246582\n",
            "8.049644470214844\n",
            "7.452307224273682\n",
            "10.015893936157227\n",
            "7.839575290679932\n",
            "5.891360759735107\n",
            "6.781299591064453\n",
            "5.577021598815918\n",
            "6.718047142028809\n",
            "6.759812831878662\n",
            "6.232504367828369\n",
            "7.003334999084473\n",
            "7.198418617248535\n",
            "9.010259628295898\n",
            "6.7554192543029785\n",
            "7.591388702392578\n",
            "7.188697814941406\n",
            "6.821459770202637\n",
            "7.367000579833984\n",
            "5.877154350280762\n",
            "6.620567321777344\n",
            "7.231972694396973\n",
            "7.129055976867676\n",
            "7.707062721252441\n",
            "7.735264778137207\n",
            "6.294547080993652\n",
            "6.1661376953125\n",
            "7.409018516540527\n",
            "6.470470428466797\n",
            "5.898797512054443\n",
            "7.080633640289307\n",
            "6.218478202819824\n",
            "9.093255043029785\n",
            "7.271589756011963\n",
            "8.058329582214355\n",
            "8.943181991577148\n",
            "8.166361808776855\n",
            "5.546477317810059\n",
            "6.880265235900879\n",
            "7.601529121398926\n",
            "7.917661190032959\n",
            "6.811666965484619\n",
            "7.388950347900391\n",
            "7.365106105804443\n",
            "8.178044319152832\n",
            "6.9470415115356445\n",
            "5.913541316986084\n",
            "7.995907783508301\n",
            "7.697983741760254\n",
            "7.437330722808838\n",
            "8.813026428222656\n",
            "8.074424743652344\n",
            "8.456197738647461\n",
            "8.054666519165039\n",
            "9.529923439025879\n",
            "6.854334354400635\n",
            "5.3755974769592285\n",
            "6.978013515472412\n",
            "6.329078197479248\n",
            "6.315131187438965\n",
            "8.545854568481445\n",
            "7.933130741119385\n",
            "7.972599983215332\n",
            "7.39218282699585\n",
            "9.263269424438477\n",
            "7.820525169372559\n",
            "4.967037677764893\n",
            "7.360040187835693\n",
            "7.681385040283203\n",
            "7.2496137619018555\n",
            "6.831122398376465\n",
            "6.1862897872924805\n",
            "7.069394588470459\n",
            "7.045493125915527\n",
            "6.439553737640381\n",
            "7.884759426116943\n",
            "7.9366302490234375\n",
            "7.273340702056885\n",
            "6.342062950134277\n",
            "7.4661054611206055\n",
            "7.578093528747559\n",
            "6.0006914138793945\n",
            "6.933126926422119\n",
            "5.526369094848633\n",
            "7.828176975250244\n",
            "7.043511390686035\n",
            "6.279239654541016\n",
            "7.397607326507568\n",
            "6.787023067474365\n",
            "6.931785583496094\n",
            "7.313961982727051\n",
            "6.509417533874512\n",
            "6.694433689117432\n",
            "5.513958930969238\n",
            "6.998513698577881\n",
            "7.233796119689941\n",
            "7.064527988433838\n",
            "7.751506805419922\n",
            "5.572717189788818\n",
            "7.40762186050415\n",
            "6.857003688812256\n",
            "8.058439254760742\n",
            "6.696737766265869\n",
            "6.568070411682129\n",
            "6.261447906494141\n",
            "5.311148643493652\n",
            "7.163621425628662\n",
            "6.154798984527588\n",
            "5.7461042404174805\n",
            "6.7238311767578125\n",
            "9.245291709899902\n",
            "8.20973014831543\n",
            "6.316364765167236\n",
            "8.306899070739746\n",
            "5.056572914123535\n",
            "7.2803215980529785\n",
            "9.051706314086914\n",
            "5.982395648956299\n",
            "6.284989833831787\n",
            "7.197012424468994\n",
            "7.979223728179932\n",
            "7.060626029968262\n",
            "6.102074146270752\n",
            "6.168985843658447\n",
            "6.195504188537598\n",
            "7.390120506286621\n",
            "7.630366325378418\n",
            "7.606783390045166\n",
            "6.074665546417236\n",
            "6.605544090270996\n",
            "7.463923454284668\n",
            "6.235636234283447\n",
            "8.12418270111084\n",
            "7.643491268157959\n",
            "6.9376540184021\n",
            "9.061765670776367\n",
            "7.931161403656006\n",
            "6.815677642822266\n",
            "8.584136009216309\n",
            "7.803758144378662\n",
            "7.844533443450928\n",
            "6.323074817657471\n",
            "7.584572792053223\n",
            "6.242350101470947\n",
            "5.8337907791137695\n",
            "7.202127933502197\n",
            "6.436690330505371\n",
            "5.872304916381836\n",
            "8.805989265441895\n",
            "5.485086917877197\n",
            "6.145733833312988\n",
            "6.89951229095459\n",
            "6.729058742523193\n",
            "6.933279991149902\n",
            "6.448341369628906\n",
            "7.035041809082031\n",
            "6.641149997711182\n",
            "7.0508551597595215\n",
            "5.868710517883301\n",
            "8.17689323425293\n",
            "7.114628791809082\n",
            "7.514254093170166\n",
            "7.368100643157959\n",
            "8.824216842651367\n",
            "7.102442741394043\n",
            "6.407330513000488\n",
            "6.239480018615723\n",
            "7.77645206451416\n",
            "9.624271392822266\n",
            "7.459256649017334\n",
            "7.794227600097656\n",
            "6.099259376525879\n",
            "5.661210536956787\n",
            "4.6745758056640625\n",
            "7.715371608734131\n",
            "7.069890022277832\n",
            "5.720278739929199\n",
            "7.358174800872803\n",
            "9.296257972717285\n",
            "7.890313148498535\n",
            "6.186218738555908\n",
            "5.670242786407471\n",
            "6.812023162841797\n",
            "6.768285274505615\n",
            "6.640233516693115\n",
            "7.107015132904053\n",
            "9.603075981140137\n",
            "7.077567100524902\n",
            "6.880607604980469\n",
            "5.842792987823486\n",
            "5.755631923675537\n",
            "7.5913896560668945\n",
            "7.192769527435303\n",
            "6.670472621917725\n",
            "6.757826805114746\n",
            "5.585107803344727\n",
            "6.5812249183654785\n",
            "7.053877353668213\n",
            "5.553071975708008\n",
            "6.330198287963867\n",
            "6.06525182723999\n",
            "8.155763626098633\n",
            "6.570870876312256\n",
            "7.262843132019043\n",
            "8.902408599853516\n",
            "6.517088890075684\n",
            "6.840488433837891\n",
            "8.415570259094238\n",
            "8.046895980834961\n",
            "7.430920600891113\n",
            "7.9643144607543945\n",
            "7.695397853851318\n",
            "5.685774803161621\n",
            "6.518553256988525\n",
            "5.88823938369751\n",
            "7.52752685546875\n",
            "8.093382835388184\n",
            "8.08019733428955\n",
            "7.1380109786987305\n",
            "7.7723894119262695\n",
            "5.83077335357666\n",
            "6.592185974121094\n",
            "6.494758605957031\n",
            "7.911398410797119\n",
            "7.963901519775391\n",
            "7.012307167053223\n",
            "7.972070217132568\n",
            "6.764489650726318\n",
            "8.17130184173584\n",
            "6.127657413482666\n",
            "6.175525188446045\n",
            "6.598467826843262\n",
            "6.024603366851807\n",
            "7.0361328125\n",
            "7.270190238952637\n",
            "6.73101806640625\n",
            "6.808876037597656\n",
            "8.230620384216309\n",
            "9.354811668395996\n",
            "7.9446611404418945\n",
            "6.8079705238342285\n",
            "6.786586761474609\n",
            "6.589926242828369\n",
            "5.601205348968506\n",
            "7.590588569641113\n",
            "8.336263656616211\n",
            "8.863327980041504\n",
            "8.087991714477539\n",
            "7.0293779373168945\n",
            "6.430226802825928\n",
            "7.452275276184082\n",
            "6.872838497161865\n",
            "5.182071208953857\n",
            "5.953341007232666\n",
            "6.791456699371338\n",
            "6.058810710906982\n",
            "7.850010871887207\n",
            "6.733006954193115\n",
            "6.232000350952148\n",
            "7.878602504730225\n",
            "7.9343414306640625\n",
            "7.817301273345947\n",
            "8.442854881286621\n",
            "7.443929195404053\n",
            "7.011961460113525\n",
            "8.274835586547852\n",
            "8.703129768371582\n",
            "6.038851261138916\n",
            "7.313864231109619\n",
            "7.417629241943359\n",
            "7.938721656799316\n",
            "5.078316688537598\n",
            "5.951476097106934\n",
            "5.848219394683838\n",
            "5.803395748138428\n",
            "6.6640305519104\n",
            "9.321208953857422\n",
            "7.402488708496094\n",
            "6.386302471160889\n",
            "5.365625381469727\n",
            "5.483635902404785\n",
            "5.674595832824707\n",
            "7.157157897949219\n",
            "8.313334465026855\n",
            "7.81896448135376\n",
            "8.633888244628906\n",
            "8.449003219604492\n",
            "6.707582950592041\n",
            "5.774616241455078\n",
            "8.105766296386719\n",
            "8.012720108032227\n",
            "6.308358192443848\n",
            "7.438840389251709\n",
            "7.565855503082275\n",
            "9.079170227050781\n",
            "6.278729438781738\n",
            "7.792137145996094\n",
            "7.346341133117676\n",
            "6.194764137268066\n",
            "7.180398464202881\n",
            "5.827744483947754\n",
            "7.024720191955566\n",
            "5.821535110473633\n",
            "5.90944766998291\n",
            "6.761199951171875\n",
            "9.469940185546875\n",
            "8.377057075500488\n",
            "7.518881797790527\n",
            "7.128897190093994\n",
            "7.822857856750488\n",
            "6.533108711242676\n",
            "9.280572891235352\n",
            "7.077480316162109\n",
            "8.268256187438965\n",
            "7.759267330169678\n",
            "6.746229648590088\n",
            "6.6723127365112305\n",
            "7.423413276672363\n",
            "6.6347198486328125\n",
            "6.457630157470703\n",
            "8.448668479919434\n",
            "8.869436264038086\n",
            "7.31027364730835\n",
            "6.298202991485596\n",
            "5.981504440307617\n",
            "8.956464767456055\n",
            "5.891661167144775\n",
            "6.069813251495361\n",
            "6.116434097290039\n",
            "5.991486549377441\n",
            "7.0659589767456055\n",
            "8.345540046691895\n",
            "7.871562957763672\n",
            "4.748776435852051\n",
            "7.255736351013184\n",
            "7.461245059967041\n",
            "6.985942840576172\n",
            "5.400660991668701\n",
            "7.3742218017578125\n",
            "8.552133560180664\n",
            "6.670453071594238\n",
            "7.818948268890381\n",
            "5.303661346435547\n",
            "7.685203552246094\n",
            "10.071687698364258\n",
            "6.5476884841918945\n",
            "7.028990745544434\n",
            "8.364340782165527\n",
            "7.665642738342285\n",
            "6.7384138107299805\n",
            "6.556490421295166\n",
            "6.623202323913574\n",
            "5.543055534362793\n",
            "6.182415008544922\n",
            "7.438973903656006\n",
            "7.8335089683532715\n",
            "6.416034698486328\n",
            "10.105512619018555\n",
            "4.697503089904785\n",
            "8.087034225463867\n",
            "6.6591033935546875\n",
            "7.161572456359863\n",
            "8.784456253051758\n",
            "4.384544372558594\n",
            "5.9820942878723145\n",
            "5.995530128479004\n",
            "6.671573638916016\n",
            "5.0334343910217285\n",
            "8.619470596313477\n",
            "5.176320552825928\n",
            "6.369312763214111\n",
            "7.1260552406311035\n",
            "7.204582214355469\n",
            "6.713627815246582\n",
            "6.751107215881348\n",
            "7.261562347412109\n",
            "6.854184627532959\n",
            "7.2773332595825195\n",
            "6.35181999206543\n",
            "6.153120994567871\n",
            "7.581931114196777\n",
            "7.510897159576416\n",
            "6.910747528076172\n",
            "6.561731815338135\n",
            "6.826085567474365\n",
            "6.9642133712768555\n",
            "5.797511100769043\n",
            "8.242744445800781\n",
            "8.056754112243652\n",
            "7.1760053634643555\n",
            "8.161191940307617\n",
            "5.001518726348877\n",
            "5.908726692199707\n",
            "6.5333757400512695\n",
            "7.85404109954834\n",
            "7.291177272796631\n",
            "6.1042304039001465\n",
            "6.197955131530762\n",
            "7.975299835205078\n",
            "9.198653221130371\n",
            "5.95403528213501\n",
            "6.356950283050537\n",
            "6.5902299880981445\n",
            "8.84052562713623\n",
            "5.688082695007324\n",
            "6.443367958068848\n",
            "5.949231147766113\n",
            "7.84097146987915\n",
            "6.24210262298584\n",
            "6.913521766662598\n",
            "7.420554161071777\n",
            "7.705728054046631\n",
            "8.707306861877441\n",
            "6.305229187011719\n",
            "6.852649688720703\n",
            "7.294806480407715\n",
            "7.049797058105469\n",
            "7.677151679992676\n",
            "8.20739459991455\n",
            "7.11016845703125\n",
            "7.830419063568115\n",
            "7.517709255218506\n",
            "8.073486328125\n",
            "5.209653854370117\n",
            "5.996462821960449\n",
            "5.8492231369018555\n",
            "5.89517068862915\n",
            "6.742574214935303\n",
            "7.389141082763672\n",
            "8.341479301452637\n",
            "6.423135280609131\n",
            "7.117406368255615\n",
            "5.388922691345215\n",
            "6.785926818847656\n",
            "6.061823844909668\n",
            "6.923399448394775\n",
            "8.085326194763184\n",
            "5.164282321929932\n",
            "6.849279880523682\n",
            "5.685556411743164\n",
            "6.902606010437012\n",
            "6.8531036376953125\n",
            "6.538412570953369\n",
            "5.371904373168945\n",
            "7.232541084289551\n",
            "7.5799455642700195\n",
            "7.246730804443359\n",
            "7.049521446228027\n",
            "7.1883544921875\n",
            "6.483056545257568\n",
            "7.924005031585693\n",
            "5.825816631317139\n",
            "7.851663112640381\n",
            "7.271298408508301\n",
            "9.191495895385742\n",
            "6.766323089599609\n",
            "7.867665767669678\n",
            "7.152368068695068\n",
            "7.619326114654541\n",
            "7.573397159576416\n",
            "7.707016944885254\n",
            "7.394541263580322\n",
            "6.6226487159729\n",
            "7.4342756271362305\n",
            "6.196292400360107\n",
            "6.544641971588135\n",
            "6.461677551269531\n",
            "7.388816833496094\n",
            "7.40032958984375\n",
            "6.153218746185303\n",
            "8.272346496582031\n",
            "7.853127479553223\n",
            "7.1866455078125\n",
            "5.6946306228637695\n",
            "8.561153411865234\n",
            "5.452666759490967\n",
            "6.6424150466918945\n",
            "7.421222686767578\n",
            "5.091615200042725\n",
            "6.294027328491211\n",
            "9.33747673034668\n",
            "6.551270961761475\n",
            "7.310599327087402\n",
            "6.911073207855225\n",
            "8.332341194152832\n",
            "8.129968643188477\n",
            "5.427098274230957\n",
            "6.694302558898926\n",
            "9.25090217590332\n",
            "7.15976619720459\n",
            "8.676411628723145\n",
            "8.565265655517578\n",
            "6.5010576248168945\n",
            "6.391786098480225\n",
            "6.6388959884643555\n",
            "7.249639987945557\n",
            "7.413681983947754\n",
            "8.4362211227417\n",
            "6.99663782119751\n",
            "7.744726657867432\n",
            "6.494009494781494\n",
            "6.793641090393066\n",
            "6.526041507720947\n",
            "5.8423357009887695\n",
            "6.2647881507873535\n",
            "5.2806501388549805\n",
            "6.0646562576293945\n",
            "6.099144458770752\n",
            "8.066091537475586\n",
            "6.017496585845947\n",
            "6.761898040771484\n",
            "5.74814510345459\n",
            "6.53798770904541\n",
            "6.791047096252441\n",
            "8.185544967651367\n",
            "9.161423683166504\n",
            "6.470833778381348\n",
            "6.761624336242676\n",
            "6.486868858337402\n",
            "6.726860046386719\n",
            "5.881472587585449\n",
            "5.505147457122803\n",
            "6.1787214279174805\n",
            "6.802552700042725\n",
            "7.308557033538818\n",
            "5.809088230133057\n",
            "5.844906330108643\n",
            "6.560050010681152\n",
            "7.492949485778809\n",
            "7.1284966468811035\n",
            "7.0771965980529785\n",
            "7.664614677429199\n",
            "8.342523574829102\n",
            "7.565769195556641\n",
            "5.946046352386475\n",
            "6.641949653625488\n",
            "9.815472602844238\n",
            "8.449289321899414\n",
            "5.635052680969238\n",
            "7.143010139465332\n",
            "6.136347770690918\n",
            "6.811783790588379\n",
            "6.80643367767334\n",
            "5.285078525543213\n",
            "5.856100559234619\n",
            "8.24525260925293\n",
            "7.484799861907959\n",
            "5.72300386428833\n",
            "9.767412185668945\n",
            "6.462708950042725\n",
            "6.596805572509766\n",
            "5.571413993835449\n",
            "5.337272644042969\n",
            "7.680860996246338\n",
            "7.456925868988037\n",
            "6.302599906921387\n",
            "5.537458896636963\n",
            "7.817584991455078\n",
            "7.929970741271973\n",
            "6.918693542480469\n",
            "7.567086219787598\n",
            "7.203250885009766\n",
            "7.112044334411621\n",
            "6.782607078552246\n",
            "7.193346977233887\n",
            "6.323792457580566\n",
            "6.154274940490723\n",
            "5.243906021118164\n",
            "5.716656684875488\n",
            "5.479068756103516\n",
            "7.631319999694824\n",
            "8.633574485778809\n",
            "5.147709846496582\n",
            "8.230730056762695\n",
            "8.8535795211792\n",
            "5.944592475891113\n",
            "4.900572776794434\n",
            "8.012643814086914\n",
            "6.305153846740723\n",
            "6.105591297149658\n",
            "5.276207447052002\n",
            "6.429556369781494\n",
            "5.797324180603027\n",
            "8.69901180267334\n",
            "7.03509521484375\n",
            "6.589947700500488\n",
            "7.938536643981934\n",
            "6.545444488525391\n",
            "6.34137487411499\n",
            "8.075655937194824\n",
            "8.780255317687988\n",
            "7.191658973693848\n",
            "7.872641086578369\n",
            "6.900806427001953\n",
            "5.651531219482422\n",
            "6.580041408538818\n",
            "8.235245704650879\n",
            "8.193912506103516\n",
            "6.584561347961426\n",
            "7.067591190338135\n",
            "7.137975215911865\n",
            "4.84885311126709\n",
            "6.050026893615723\n",
            "7.052584648132324\n",
            "6.686685085296631\n",
            "7.753775119781494\n",
            "6.9644293785095215\n",
            "7.400269508361816\n",
            "8.026034355163574\n",
            "7.342541694641113\n",
            "7.164114475250244\n",
            "5.96157693862915\n",
            "8.207318305969238\n",
            "5.936023235321045\n",
            "5.391144752502441\n",
            "7.988990783691406\n",
            "5.243872165679932\n",
            "6.090360641479492\n",
            "6.03316068649292\n",
            "7.062947750091553\n",
            "6.254244804382324\n",
            "6.7616167068481445\n",
            "6.921810150146484\n",
            "7.091361999511719\n",
            "6.977620601654053\n",
            "6.747289180755615\n",
            "8.317520141601562\n",
            "7.03115177154541\n",
            "7.488543510437012\n",
            "5.889382839202881\n",
            "7.2423248291015625\n",
            "6.037744045257568\n",
            "7.345375061035156\n",
            "8.035207748413086\n",
            "9.534346580505371\n",
            "6.594491004943848\n",
            "7.968308448791504\n",
            "6.403814792633057\n",
            "6.572843074798584\n",
            "8.734068870544434\n",
            "7.467075347900391\n",
            "4.655961036682129\n",
            "6.015933036804199\n",
            "6.321396827697754\n",
            "6.485145568847656\n",
            "6.816683769226074\n",
            "7.417167663574219\n",
            "8.524688720703125\n",
            "6.6946916580200195\n",
            "6.213242530822754\n",
            "6.559421539306641\n",
            "6.360929012298584\n",
            "5.770553112030029\n",
            "8.09276008605957\n",
            "6.836606502532959\n",
            "5.630549907684326\n",
            "7.166790962219238\n",
            "6.439731597900391\n",
            "5.158881187438965\n",
            "5.455391883850098\n",
            "7.064853668212891\n",
            "8.5441312789917\n",
            "7.303093910217285\n",
            "8.642081260681152\n",
            "8.216459274291992\n",
            "9.464459419250488\n",
            "6.766343593597412\n",
            "7.3138298988342285\n",
            "6.839657783508301\n",
            "4.901392459869385\n",
            "5.4074506759643555\n",
            "6.3959856033325195\n",
            "5.702476978302002\n",
            "7.186588287353516\n",
            "7.281289100646973\n",
            "6.807021141052246\n",
            "9.573813438415527\n",
            "6.864938259124756\n",
            "6.537171840667725\n",
            "7.442712306976318\n",
            "9.557515144348145\n",
            "5.4039201736450195\n",
            "6.8871355056762695\n",
            "6.413519382476807\n",
            "5.8087029457092285\n",
            "6.04010534286499\n",
            "7.036489963531494\n",
            "7.937102317810059\n",
            "7.096869468688965\n",
            "6.268951416015625\n",
            "6.677122592926025\n",
            "8.438241004943848\n",
            "6.4919939041137695\n",
            "6.85608434677124\n",
            "7.165434837341309\n",
            "6.0168633460998535\n",
            "6.661374092102051\n",
            "6.788154602050781\n",
            "5.3189263343811035\n",
            "6.287152290344238\n",
            "5.381779193878174\n",
            "7.364910125732422\n",
            "6.640953063964844\n",
            "7.484510898590088\n",
            "6.794409275054932\n",
            "5.925642013549805\n",
            "5.880348205566406\n",
            "8.965385437011719\n",
            "6.4173994064331055\n",
            "5.748302459716797\n",
            "7.131654262542725\n",
            "7.933262825012207\n",
            "9.925554275512695\n",
            "5.281096458435059\n",
            "6.451083183288574\n",
            "6.576009273529053\n",
            "7.894059658050537\n",
            "7.961239814758301\n",
            "6.820194244384766\n",
            "7.310993194580078\n",
            "6.071878433227539\n",
            "7.838294982910156\n",
            "7.336298942565918\n",
            "9.054632186889648\n",
            "6.255501747131348\n",
            "7.457495212554932\n",
            "6.544260501861572\n",
            "6.186015605926514\n",
            "7.12549352645874\n",
            "5.2199931144714355\n",
            "6.862448215484619\n",
            "5.299958229064941\n",
            "7.428038120269775\n",
            "7.610583305358887\n",
            "8.521655082702637\n",
            "6.795262336730957\n",
            "7.024737358093262\n",
            "8.458359718322754\n",
            "7.560375213623047\n",
            "7.771833896636963\n",
            "7.875022888183594\n",
            "6.289438724517822\n",
            "6.285906791687012\n",
            "8.106971740722656\n",
            "6.191234588623047\n",
            "8.407472610473633\n",
            "7.980318546295166\n",
            "5.90852165222168\n",
            "6.633999824523926\n",
            "5.517419338226318\n",
            "5.2361650466918945\n",
            "5.716341495513916\n",
            "8.132194519042969\n",
            "6.16280460357666\n",
            "6.184403419494629\n",
            "6.465868949890137\n",
            "6.667061805725098\n",
            "7.638439178466797\n",
            "6.209136009216309\n",
            "5.282173156738281\n",
            "6.102334976196289\n",
            "7.646131992340088\n",
            "7.733299255371094\n",
            "6.8867902755737305\n",
            "6.050032138824463\n",
            "5.953097343444824\n",
            "6.038638114929199\n",
            "8.043853759765625\n",
            "7.467912197113037\n",
            "7.354417324066162\n",
            "7.288388729095459\n",
            "6.1981072425842285\n",
            "7.2067461013793945\n",
            "6.987547397613525\n",
            "8.9147367477417\n",
            "6.396541118621826\n",
            "7.309899806976318\n",
            "6.584832668304443\n",
            "6.0731940269470215\n",
            "5.598010063171387\n",
            "7.4311323165893555\n",
            "6.714252471923828\n",
            "6.867441654205322\n",
            "6.950003623962402\n",
            "6.151334285736084\n",
            "7.577998161315918\n",
            "6.523612022399902\n",
            "7.547779083251953\n",
            "6.339276313781738\n",
            "6.606125831604004\n",
            "7.478673458099365\n",
            "6.598962306976318\n",
            "8.151762962341309\n",
            "6.568950653076172\n",
            "7.0392022132873535\n",
            "6.078742980957031\n",
            "7.340497016906738\n",
            "7.530503273010254\n",
            "6.288506507873535\n",
            "7.067761421203613\n",
            "7.458560943603516\n",
            "6.803698539733887\n",
            "5.902340412139893\n",
            "8.556955337524414\n",
            "8.791766166687012\n",
            "6.740049839019775\n",
            "8.092086791992188\n",
            "6.8742170333862305\n",
            "5.170391082763672\n",
            "7.100916385650635\n",
            "7.475296974182129\n",
            "6.5565361976623535\n",
            "6.791853904724121\n",
            "7.703402042388916\n",
            "7.380974769592285\n",
            "7.045809745788574\n",
            "6.828034400939941\n",
            "8.015497207641602\n",
            "5.795712471008301\n",
            "8.86874771118164\n",
            "6.185417652130127\n",
            "5.66599702835083\n",
            "6.060945987701416\n",
            "6.805612087249756\n",
            "6.278655052185059\n",
            "6.541685581207275\n",
            "6.677941799163818\n",
            "7.982095241546631\n",
            "5.472340106964111\n",
            "5.9431304931640625\n",
            "8.415108680725098\n",
            "8.003575325012207\n",
            "5.4087114334106445\n",
            "7.690106391906738\n",
            "9.889521598815918\n",
            "9.154696464538574\n",
            "7.399438381195068\n",
            "7.178393363952637\n",
            "5.716099739074707\n",
            "7.259685516357422\n",
            "8.456300735473633\n",
            "6.806757926940918\n",
            "8.312809944152832\n",
            "7.409060478210449\n",
            "6.5911736488342285\n",
            "6.692892551422119\n",
            "6.891125679016113\n",
            "5.909636497497559\n",
            "7.4688897132873535\n",
            "6.586583614349365\n",
            "5.427412986755371\n",
            "8.2147855758667\n",
            "8.980162620544434\n",
            "6.831106662750244\n",
            "6.094865798950195\n",
            "5.9664483070373535\n",
            "7.250399589538574\n",
            "5.880741596221924\n",
            "7.520455360412598\n",
            "5.813274383544922\n",
            "5.430190563201904\n",
            "5.504652976989746\n",
            "8.196649551391602\n",
            "6.09000301361084\n",
            "8.398012161254883\n",
            "7.097485542297363\n",
            "6.338055610656738\n",
            "4.054162979125977\n",
            "5.654698371887207\n",
            "5.154385089874268\n",
            "6.68270206451416\n",
            "7.238908290863037\n",
            "8.504007339477539\n",
            "7.590689182281494\n",
            "8.172033309936523\n",
            "7.875344276428223\n",
            "5.423134803771973\n",
            "6.575435638427734\n",
            "6.4967451095581055\n",
            "7.626456260681152\n",
            "6.647159576416016\n",
            "6.076813697814941\n",
            "7.572470188140869\n",
            "7.523481845855713\n",
            "6.590666770935059\n",
            "7.498203277587891\n",
            "6.869050025939941\n",
            "7.095993995666504\n",
            "8.680541038513184\n",
            "6.560921669006348\n",
            "6.817866325378418\n",
            "8.102266311645508\n",
            "6.278445720672607\n",
            "8.57535457611084\n",
            "5.156060218811035\n",
            "6.021135330200195\n",
            "6.842904090881348\n",
            "7.269425868988037\n",
            "6.715171813964844\n",
            "6.616735935211182\n",
            "5.987017631530762\n",
            "6.483354091644287\n",
            "5.329298973083496\n",
            "7.018826484680176\n",
            "6.628198146820068\n",
            "6.2311296463012695\n",
            "7.203367710113525\n",
            "7.095278263092041\n",
            "6.40298318862915\n",
            "5.438859939575195\n",
            "7.276589393615723\n",
            "5.903489112854004\n",
            "8.103700637817383\n",
            "5.956730365753174\n",
            "5.826962471008301\n",
            "7.568297386169434\n",
            "6.259220123291016\n",
            "7.836301326751709\n",
            "5.51967191696167\n",
            "8.06580638885498\n",
            "8.115079879760742\n",
            "6.110753536224365\n",
            "7.828156471252441\n",
            "4.914388656616211\n",
            "6.634951591491699\n",
            "6.7348833084106445\n",
            "7.506199836730957\n",
            "8.620580673217773\n",
            "8.378204345703125\n",
            "7.233137607574463\n",
            "6.255825996398926\n",
            "7.633962154388428\n",
            "5.35991907119751\n",
            "7.8460516929626465\n",
            "8.737909317016602\n",
            "7.664286136627197\n",
            "6.793432712554932\n",
            "6.025157451629639\n",
            "5.760237693786621\n",
            "7.225234031677246\n",
            "5.078427791595459\n",
            "7.184470176696777\n",
            "6.682015895843506\n",
            "7.0619659423828125\n",
            "8.097982406616211\n",
            "6.281968116760254\n",
            "6.740624904632568\n",
            "6.10968542098999\n",
            "5.457781791687012\n",
            "7.620151519775391\n",
            "7.042298316955566\n",
            "8.756980895996094\n",
            "6.0932841300964355\n",
            "5.475628852844238\n",
            "8.2276611328125\n",
            "7.616279602050781\n",
            "7.304981231689453\n",
            "7.783754825592041\n",
            "8.34870719909668\n",
            "6.684655666351318\n",
            "9.213786125183105\n",
            "7.982029914855957\n",
            "5.933992862701416\n",
            "7.842493534088135\n",
            "6.856741905212402\n",
            "5.638731956481934\n",
            "6.9639387130737305\n",
            "5.407660007476807\n",
            "8.322561264038086\n",
            "7.415487766265869\n",
            "6.742575168609619\n",
            "7.129387855529785\n",
            "7.577298641204834\n",
            "8.887097358703613\n",
            "6.756052494049072\n",
            "7.015036106109619\n",
            "7.701086521148682\n",
            "6.734546661376953\n",
            "6.693562984466553\n",
            "5.849207401275635\n",
            "6.428000450134277\n",
            "7.264639377593994\n",
            "5.853043556213379\n",
            "6.817279815673828\n",
            "6.875080108642578\n",
            "6.975384712219238\n",
            "5.662631034851074\n",
            "7.494614601135254\n",
            "7.037784576416016\n",
            "6.545546054840088\n",
            "7.130350589752197\n",
            "8.019186019897461\n",
            "8.69914436340332\n",
            "6.20998477935791\n",
            "8.819084167480469\n",
            "5.184907913208008\n",
            "7.455268859863281\n",
            "9.136075973510742\n",
            "6.5675859451293945\n",
            "7.922161102294922\n",
            "7.029877662658691\n",
            "8.394195556640625\n",
            "6.930095672607422\n",
            "6.509644985198975\n",
            "6.03140115737915\n",
            "7.680957794189453\n",
            "8.129680633544922\n",
            "6.687457084655762\n",
            "7.0182204246521\n",
            "7.529215335845947\n",
            "7.769461154937744\n",
            "6.226754665374756\n",
            "7.867795467376709\n",
            "7.509020805358887\n",
            "6.939509391784668\n",
            "6.752108097076416\n",
            "8.370034217834473\n",
            "7.554771423339844\n",
            "7.358517646789551\n",
            "7.067972660064697\n",
            "5.876621246337891\n",
            "7.225330352783203\n",
            "6.126602649688721\n",
            "6.8669538497924805\n",
            "7.888189792633057\n",
            "6.7114105224609375\n",
            "6.689080715179443\n",
            "6.712169647216797\n",
            "6.057309150695801\n",
            "6.9900221824646\n",
            "7.0872344970703125\n",
            "7.2414374351501465\n",
            "8.575074195861816\n",
            "7.7207746505737305\n",
            "7.4783616065979\n",
            "7.328431129455566\n",
            "6.976199150085449\n",
            "7.274208068847656\n",
            "6.811604976654053\n",
            "5.370578289031982\n",
            "7.052585601806641\n",
            "8.298809051513672\n",
            "5.6104736328125\n",
            "6.043394565582275\n",
            "7.636065483093262\n",
            "5.612077713012695\n",
            "8.325822830200195\n",
            "6.642033576965332\n",
            "6.207209587097168\n",
            "6.6178436279296875\n",
            "5.705959320068359\n",
            "7.8227338790893555\n",
            "7.610141754150391\n",
            "6.473316192626953\n",
            "7.070195198059082\n",
            "9.454951286315918\n",
            "8.550325393676758\n",
            "7.222801208496094\n",
            "7.17550802230835\n",
            "5.804442405700684\n",
            "8.79541015625\n",
            "7.775254726409912\n",
            "5.995423316955566\n",
            "6.749798774719238\n",
            "7.000693321228027\n",
            "7.804776668548584\n",
            "8.045495986938477\n",
            "6.612556457519531\n",
            "7.977252960205078\n",
            "7.8943190574646\n",
            "6.429501533508301\n",
            "6.20127534866333\n",
            "8.42017936706543\n",
            "8.528054237365723\n",
            "4.934304714202881\n",
            "7.01153039932251\n",
            "5.038364410400391\n",
            "7.349574089050293\n",
            "7.207430839538574\n",
            "6.194390296936035\n",
            "6.646514892578125\n",
            "7.462055206298828\n",
            "6.640743255615234\n",
            "8.44774341583252\n",
            "7.415329933166504\n",
            "6.618278503417969\n",
            "5.657817840576172\n",
            "6.831912994384766\n",
            "6.540955543518066\n",
            "7.407662868499756\n",
            "8.272890090942383\n",
            "7.850285530090332\n",
            "6.147520542144775\n",
            "5.844593048095703\n",
            "5.3576178550720215\n",
            "5.989146709442139\n",
            "8.035961151123047\n",
            "6.700434684753418\n",
            "7.035243988037109\n",
            "9.051183700561523\n",
            "6.749304294586182\n",
            "8.751141548156738\n",
            "5.8025970458984375\n",
            "7.2534942626953125\n",
            "6.013387203216553\n",
            "6.339475154876709\n",
            "6.894201755523682\n",
            "5.722751617431641\n",
            "7.311729431152344\n",
            "4.5750837326049805\n",
            "5.491466522216797\n",
            "6.862408638000488\n",
            "6.039078235626221\n",
            "10.208231925964355\n",
            "6.458808898925781\n",
            "5.142148971557617\n",
            "7.951345920562744\n",
            "5.262964248657227\n",
            "6.885190486907959\n",
            "6.834828853607178\n",
            "7.817010402679443\n",
            "5.607462406158447\n",
            "7.284882545471191\n",
            "6.362444877624512\n",
            "5.739489555358887\n",
            "7.281735897064209\n",
            "6.0891571044921875\n",
            "8.61229133605957\n",
            "7.499312400817871\n",
            "7.239625453948975\n",
            "5.496347427368164\n",
            "7.221858978271484\n",
            "6.176080226898193\n",
            "7.980149745941162\n",
            "6.4897918701171875\n",
            "7.174464225769043\n",
            "7.182257175445557\n",
            "6.994647979736328\n",
            "7.015793800354004\n",
            "5.3247151374816895\n",
            "5.952977180480957\n",
            "7.71735143661499\n",
            "5.4658331871032715\n",
            "9.537047386169434\n",
            "7.419130802154541\n",
            "6.9678192138671875\n",
            "7.441458225250244\n",
            "6.947485446929932\n",
            "4.44573974609375\n",
            "8.350083351135254\n",
            "8.583006858825684\n",
            "8.330381393432617\n",
            "7.429220676422119\n",
            "5.542187690734863\n",
            "6.394863128662109\n",
            "6.270453453063965\n",
            "6.374454975128174\n",
            "7.6213226318359375\n",
            "6.563799858093262\n",
            "6.357989311218262\n",
            "5.239253997802734\n",
            "6.960390567779541\n",
            "4.955965995788574\n",
            "6.916924953460693\n",
            "7.169227600097656\n",
            "5.722611427307129\n",
            "5.999571323394775\n",
            "8.005993843078613\n",
            "6.363986968994141\n",
            "8.063281059265137\n",
            "5.066590785980225\n",
            "7.916935920715332\n",
            "6.152876853942871\n",
            "7.058631896972656\n",
            "6.687614440917969\n",
            "6.029628753662109\n",
            "6.16152286529541\n",
            "7.675515174865723\n",
            "5.619837284088135\n",
            "5.78255033493042\n",
            "6.318171501159668\n",
            "7.003379821777344\n",
            "4.910662651062012\n",
            "7.018097877502441\n",
            "5.287793159484863\n",
            "7.003125190734863\n",
            "7.01212215423584\n",
            "5.653801441192627\n",
            "8.209512710571289\n",
            "6.854836940765381\n",
            "7.273581027984619\n",
            "6.292276859283447\n",
            "7.291441440582275\n",
            "7.952940940856934\n",
            "7.314643859863281\n",
            "4.919731616973877\n",
            "7.010588645935059\n",
            "6.558518886566162\n",
            "7.058670997619629\n",
            "6.981583595275879\n",
            "6.794969081878662\n",
            "7.549102783203125\n",
            "6.885261535644531\n",
            "6.069258689880371\n",
            "8.566116333007812\n",
            "9.160157203674316\n",
            "6.524104118347168\n",
            "6.957965850830078\n",
            "8.788427352905273\n",
            "7.135754585266113\n",
            "7.1048126220703125\n",
            "6.316281318664551\n",
            "7.485804080963135\n",
            "4.137090682983398\n",
            "5.094732284545898\n",
            "6.735228538513184\n",
            "8.415241241455078\n",
            "5.966705322265625\n",
            "10.791966438293457\n",
            "6.830056667327881\n",
            "5.675449371337891\n",
            "6.33174467086792\n",
            "6.014020919799805\n",
            "5.974642753601074\n",
            "7.484896183013916\n",
            "7.651888370513916\n",
            "5.796480655670166\n",
            "8.006292343139648\n",
            "5.566147327423096\n",
            "5.235504150390625\n",
            "5.017395496368408\n",
            "8.164045333862305\n",
            "5.39174222946167\n",
            "7.912055015563965\n",
            "9.246793746948242\n",
            "7.288140773773193\n",
            "6.780470371246338\n",
            "6.088057041168213\n",
            "5.799991607666016\n",
            "7.0261335372924805\n",
            "8.142732620239258\n",
            "5.771668434143066\n",
            "7.082589149475098\n",
            "6.40695858001709\n",
            "4.453436851501465\n",
            "5.987278461456299\n",
            "7.4301252365112305\n",
            "8.474547386169434\n",
            "8.329477310180664\n",
            "7.153292179107666\n",
            "5.244086265563965\n",
            "5.239016532897949\n",
            "6.884339809417725\n",
            "6.584791660308838\n",
            "6.714186191558838\n",
            "7.42734432220459\n",
            "8.513760566711426\n",
            "5.929547309875488\n",
            "6.751951694488525\n",
            "7.035797119140625\n",
            "8.384500503540039\n",
            "6.10195255279541\n",
            "7.771630764007568\n",
            "6.132053375244141\n",
            "7.148421287536621\n",
            "7.900516510009766\n",
            "7.956027030944824\n",
            "5.030531883239746\n",
            "6.6932549476623535\n",
            "5.566347122192383\n",
            "7.402775764465332\n",
            "8.28571891784668\n",
            "9.939614295959473\n",
            "6.071631908416748\n",
            "7.214790344238281\n",
            "5.937977313995361\n",
            "6.723147392272949\n",
            "8.095783233642578\n",
            "8.174280166625977\n",
            "4.77996826171875\n",
            "8.465688705444336\n",
            "7.087423801422119\n",
            "5.550567626953125\n",
            "4.418927192687988\n",
            "7.0644025802612305\n",
            "7.554625511169434\n",
            "5.2173051834106445\n",
            "6.6680731773376465\n",
            "9.080872535705566\n",
            "6.9622979164123535\n",
            "5.939627170562744\n",
            "6.5817742347717285\n",
            "6.811680793762207\n",
            "7.763667106628418\n",
            "6.856640815734863\n",
            "5.8246660232543945\n",
            "6.507039546966553\n",
            "7.917564392089844\n",
            "7.455458164215088\n",
            "6.265700340270996\n",
            "6.316038608551025\n",
            "7.233804225921631\n",
            "7.387004852294922\n",
            "5.509007930755615\n",
            "6.142611503601074\n",
            "6.133872985839844\n",
            "6.488858699798584\n",
            "5.898686408996582\n",
            "6.924793243408203\n",
            "5.943967819213867\n",
            "6.882638454437256\n",
            "6.487697601318359\n",
            "7.432408809661865\n",
            "8.35124683380127\n",
            "5.613282680511475\n",
            "7.440908908843994\n",
            "6.620628356933594\n",
            "5.384428977966309\n",
            "6.339385509490967\n",
            "5.85037088394165\n",
            "6.059592247009277\n",
            "5.660974979400635\n",
            "7.993743896484375\n",
            "4.663903713226318\n",
            "7.8465399742126465\n",
            "5.35574197769165\n",
            "5.236626625061035\n",
            "9.102875709533691\n",
            "7.250063896179199\n",
            "7.178293704986572\n",
            "6.050526142120361\n",
            "5.856907367706299\n",
            "7.195404052734375\n",
            "7.335235595703125\n",
            "5.120810508728027\n",
            "7.097567081451416\n",
            "6.791694641113281\n",
            "7.448164463043213\n",
            "8.57472038269043\n",
            "9.490072250366211\n",
            "5.377469539642334\n",
            "7.373415946960449\n",
            "6.023216724395752\n",
            "6.788320064544678\n",
            "6.735998630523682\n",
            "9.076423645019531\n",
            "8.729536056518555\n",
            "8.707235336303711\n",
            "5.75905179977417\n",
            "6.006049156188965\n",
            "8.23245620727539\n",
            "8.396251678466797\n",
            "6.219078063964844\n",
            "5.745589733123779\n",
            "9.673959732055664\n",
            "6.844817161560059\n",
            "6.349686622619629\n",
            "6.849610328674316\n",
            "5.647400856018066\n",
            "5.490994453430176\n",
            "6.3113179206848145\n",
            "6.948647975921631\n",
            "6.6806817054748535\n",
            "7.310925483703613\n",
            "8.197059631347656\n",
            "5.345883369445801\n",
            "5.594937324523926\n",
            "7.389919281005859\n",
            "6.141870498657227\n",
            "6.523133277893066\n",
            "5.69692850112915\n",
            "6.51747989654541\n",
            "7.384307861328125\n",
            "6.446331024169922\n",
            "6.729090213775635\n",
            "5.208296775817871\n",
            "7.140761375427246\n",
            "8.561517715454102\n",
            "6.391240119934082\n",
            "6.687982082366943\n",
            "7.6311235427856445\n",
            "5.808526515960693\n",
            "5.052593231201172\n",
            "8.666401863098145\n",
            "8.302345275878906\n",
            "7.091055870056152\n",
            "6.069005012512207\n",
            "5.771430015563965\n",
            "10.284111976623535\n",
            "6.679095268249512\n",
            "8.25782585144043\n",
            "9.112963676452637\n",
            "7.556397914886475\n",
            "7.291689872741699\n",
            "6.268466472625732\n",
            "7.387338161468506\n",
            "7.079577445983887\n",
            "7.5754570960998535\n",
            "7.0961737632751465\n",
            "6.694363594055176\n",
            "5.850189208984375\n",
            "8.027514457702637\n",
            "5.782109260559082\n",
            "7.711700439453125\n",
            "9.347623825073242\n",
            "7.2688140869140625\n",
            "7.434364318847656\n",
            "5.589634418487549\n",
            "4.39016580581665\n",
            "5.607148170471191\n",
            "7.28900146484375\n",
            "6.652159690856934\n",
            "3.9669806957244873\n",
            "7.025801658630371\n",
            "4.953592300415039\n",
            "5.542445659637451\n",
            "5.026876926422119\n",
            "7.6933770179748535\n",
            "6.00924015045166\n",
            "4.334839820861816\n",
            "5.484024524688721\n",
            "5.943687438964844\n",
            "6.558595180511475\n",
            "7.020447731018066\n",
            "7.201817512512207\n",
            "8.318867683410645\n",
            "6.699077606201172\n",
            "6.342007637023926\n",
            "6.0764617919921875\n",
            "4.909937858581543\n",
            "6.016850471496582\n",
            "7.1291351318359375\n",
            "5.441594123840332\n",
            "8.97934341430664\n",
            "8.376355171203613\n",
            "4.933095455169678\n",
            "7.027853488922119\n",
            "8.269250869750977\n",
            "6.368290424346924\n",
            "6.050012111663818\n",
            "7.224291801452637\n",
            "8.480563163757324\n",
            "6.095093727111816\n",
            "7.06329870223999\n",
            "7.711489200592041\n",
            "5.548844814300537\n",
            "8.506308555603027\n",
            "5.645404815673828\n",
            "6.461849212646484\n",
            "8.193056106567383\n",
            "6.358719825744629\n",
            "7.221063137054443\n",
            "5.3444318771362305\n",
            "7.645559787750244\n",
            "7.59237003326416\n",
            "8.81224536895752\n",
            "7.000586032867432\n",
            "7.020485877990723\n",
            "7.244175910949707\n",
            "7.349478244781494\n",
            "7.679975986480713\n",
            "8.47166633605957\n",
            "5.936002254486084\n",
            "8.45584774017334\n",
            "5.654499530792236\n",
            "5.353119850158691\n",
            "8.363211631774902\n",
            "7.481564521789551\n",
            "6.3961567878723145\n",
            "7.078485012054443\n",
            "8.19946575164795\n",
            "9.98050308227539\n",
            "7.948420524597168\n",
            "6.2315545082092285\n",
            "7.091397285461426\n",
            "3.937819719314575\n",
            "5.791694164276123\n",
            "7.610057830810547\n",
            "6.981961727142334\n",
            "8.152674674987793\n",
            "7.043990135192871\n",
            "5.8634514808654785\n",
            "5.967329025268555\n",
            "7.217036247253418\n",
            "8.178507804870605\n",
            "8.064837455749512\n",
            "10.091658592224121\n",
            "5.569526672363281\n",
            "6.376688480377197\n",
            "6.911518096923828\n",
            "7.004948616027832\n",
            "7.074715614318848\n",
            "7.470663547515869\n",
            "6.257203102111816\n",
            "7.257559299468994\n",
            "5.862153053283691\n",
            "6.183526515960693\n",
            "7.333547115325928\n",
            "9.14754867553711\n",
            "6.650744438171387\n",
            "6.097652435302734\n",
            "6.298511505126953\n",
            "8.040431022644043\n",
            "6.730837821960449\n",
            "7.888487815856934\n",
            "6.634878635406494\n",
            "6.839047908782959\n",
            "7.095641136169434\n",
            "7.038250923156738\n",
            "4.659316062927246\n",
            "4.962562084197998\n",
            "6.292000770568848\n",
            "6.052909851074219\n",
            "5.859317779541016\n",
            "7.227097988128662\n",
            "6.240082740783691\n",
            "6.027677059173584\n",
            "5.838454246520996\n",
            "7.257837772369385\n",
            "7.773370265960693\n",
            "6.7945051193237305\n",
            "7.332540988922119\n",
            "7.9102983474731445\n",
            "8.032674789428711\n",
            "8.614343643188477\n",
            "5.291868209838867\n",
            "7.2357378005981445\n",
            "7.124636173248291\n",
            "6.802069664001465\n",
            "9.444000244140625\n",
            "6.656410217285156\n",
            "6.733684539794922\n",
            "7.07424783706665\n",
            "6.6077375411987305\n",
            "6.362636566162109\n",
            "7.555336952209473\n",
            "5.826129913330078\n",
            "6.469380855560303\n",
            "6.851637363433838\n",
            "6.926446437835693\n",
            "6.171876907348633\n",
            "6.608773708343506\n",
            "6.346747875213623\n",
            "7.151456356048584\n",
            "8.994544982910156\n",
            "6.126029014587402\n",
            "6.266831398010254\n",
            "5.910974025726318\n",
            "7.871976375579834\n",
            "6.269814968109131\n",
            "5.302972316741943\n",
            "7.011702537536621\n",
            "6.639951229095459\n",
            "8.64788818359375\n",
            "7.433470249176025\n",
            "5.7430644035339355\n",
            "8.182348251342773\n",
            "6.2554521560668945\n",
            "5.994178771972656\n",
            "6.166781902313232\n",
            "6.747686862945557\n",
            "6.018801689147949\n",
            "6.77944278717041\n",
            "7.119224548339844\n",
            "6.516037940979004\n",
            "7.287518501281738\n",
            "6.5340118408203125\n",
            "7.102999210357666\n",
            "5.397255897521973\n",
            "6.86053466796875\n",
            "6.423536777496338\n",
            "7.115859031677246\n",
            "7.175451755523682\n",
            "5.050045490264893\n",
            "5.815093040466309\n",
            "5.938961029052734\n",
            "4.651124000549316\n",
            "6.909581184387207\n",
            "8.377912521362305\n",
            "7.776446342468262\n",
            "5.7890448570251465\n",
            "9.248698234558105\n",
            "6.222321510314941\n",
            "5.473042964935303\n",
            "6.6252312660217285\n",
            "6.210068702697754\n",
            "6.20987606048584\n",
            "8.723191261291504\n",
            "5.955597877502441\n",
            "8.60980224609375\n",
            "6.771989345550537\n",
            "6.338964462280273\n",
            "7.4606032371521\n",
            "7.371464729309082\n",
            "6.492535591125488\n",
            "8.410457611083984\n",
            "6.7804694175720215\n",
            "5.735899925231934\n",
            "8.357318878173828\n",
            "7.823494911193848\n",
            "7.294425964355469\n",
            "7.771967887878418\n",
            "7.041294097900391\n",
            "7.2065935134887695\n",
            "8.509325981140137\n",
            "6.747472286224365\n",
            "7.664158821105957\n",
            "6.0441670417785645\n",
            "6.773825645446777\n",
            "6.648543357849121\n",
            "7.474611759185791\n",
            "7.388035774230957\n",
            "5.411172389984131\n",
            "5.445027828216553\n",
            "6.252350807189941\n",
            "7.1933746337890625\n",
            "7.698205471038818\n",
            "4.898032188415527\n",
            "5.346808433532715\n",
            "6.445183753967285\n",
            "7.009349822998047\n",
            "5.306969165802002\n",
            "8.098883628845215\n",
            "9.57024097442627\n",
            "6.069701194763184\n",
            "6.467345237731934\n",
            "7.228723049163818\n",
            "6.262127876281738\n",
            "8.153862953186035\n",
            "8.883092880249023\n",
            "6.93546199798584\n",
            "7.1624298095703125\n",
            "8.774800300598145\n",
            "8.420580863952637\n",
            "6.063510894775391\n",
            "8.399063110351562\n",
            "7.908451080322266\n",
            "6.547934055328369\n",
            "9.031756401062012\n",
            "4.982530117034912\n",
            "10.69035530090332\n",
            "6.793336391448975\n",
            "6.505504608154297\n",
            "7.525886535644531\n",
            "5.539572238922119\n",
            "7.457997798919678\n",
            "6.135544300079346\n",
            "5.9343767166137695\n",
            "4.626811981201172\n",
            "7.4386773109436035\n",
            "6.764189720153809\n",
            "5.407233238220215\n",
            "5.123509883880615\n",
            "8.646002769470215\n",
            "5.504702568054199\n",
            "7.961268424987793\n",
            "7.935664176940918\n",
            "6.54272985458374\n",
            "7.549508094787598\n",
            "8.534759521484375\n",
            "6.19736385345459\n",
            "7.928786277770996\n",
            "5.0668110847473145\n",
            "6.056365966796875\n",
            "5.541545867919922\n",
            "6.093883991241455\n",
            "7.304887294769287\n",
            "6.206604480743408\n",
            "5.278641700744629\n",
            "8.498631477355957\n",
            "7.7267327308654785\n",
            "8.439408302307129\n",
            "8.493942260742188\n",
            "7.746474266052246\n",
            "7.3657965660095215\n",
            "7.763742923736572\n",
            "7.91033935546875\n",
            "5.038761615753174\n",
            "6.5588884353637695\n",
            "6.534501075744629\n",
            "5.956049919128418\n",
            "7.044793605804443\n",
            "6.145946025848389\n",
            "4.428597450256348\n",
            "6.353230953216553\n",
            "7.404833793640137\n",
            "6.147279739379883\n",
            "6.066134452819824\n",
            "8.282567024230957\n",
            "7.663975715637207\n",
            "7.263661861419678\n",
            "7.372256278991699\n",
            "6.40960693359375\n",
            "6.046008110046387\n",
            "7.980712890625\n",
            "7.503619194030762\n",
            "5.874266624450684\n",
            "7.420716285705566\n",
            "7.044187068939209\n",
            "7.123371124267578\n",
            "5.522297382354736\n",
            "5.6747870445251465\n",
            "4.915521144866943\n",
            "6.921624660491943\n",
            "6.691470146179199\n",
            "4.873830795288086\n",
            "7.291566371917725\n",
            "5.364815711975098\n",
            "6.051115989685059\n",
            "7.725930690765381\n",
            "6.533740997314453\n",
            "6.656004905700684\n",
            "7.38013219833374\n",
            "5.894419193267822\n",
            "6.765103816986084\n",
            "6.500278472900391\n",
            "7.112491607666016\n",
            "5.59702205657959\n",
            "6.804431915283203\n",
            "6.994894504547119\n",
            "5.901007652282715\n",
            "6.034745693206787\n",
            "8.78017520904541\n",
            "5.819077491760254\n",
            "7.921443939208984\n",
            "7.9013671875\n",
            "5.189316749572754\n",
            "6.585735321044922\n",
            "7.94248104095459\n",
            "8.8392333984375\n",
            "8.708222389221191\n",
            "7.8575615882873535\n",
            "6.737253665924072\n",
            "6.00154972076416\n",
            "7.274819374084473\n",
            "7.385963439941406\n",
            "8.292638778686523\n",
            "4.975500106811523\n",
            "8.871185302734375\n",
            "6.28563928604126\n",
            "8.035268783569336\n",
            "6.445943355560303\n",
            "6.145727157592773\n",
            "4.691767692565918\n",
            "5.84157657623291\n",
            "7.124101161956787\n",
            "5.431032180786133\n",
            "9.303866386413574\n",
            "7.9397759437561035\n",
            "6.913364410400391\n",
            "6.606459140777588\n",
            "6.830342769622803\n",
            "7.0769829750061035\n",
            "6.044095039367676\n",
            "4.361775875091553\n",
            "7.982801914215088\n",
            "6.965661525726318\n",
            "6.687929630279541\n",
            "7.906970024108887\n",
            "6.221692085266113\n",
            "6.260132312774658\n",
            "8.042452812194824\n",
            "5.326843738555908\n",
            "5.566803932189941\n",
            "6.07302188873291\n",
            "6.466618537902832\n",
            "7.159549713134766\n",
            "7.0773186683654785\n",
            "6.784802436828613\n",
            "6.066951751708984\n",
            "5.929736137390137\n",
            "5.817933082580566\n",
            "5.938348770141602\n",
            "6.549218654632568\n",
            "6.4849090576171875\n",
            "5.243344306945801\n",
            "7.381531715393066\n",
            "8.457268714904785\n",
            "7.8948235511779785\n",
            "5.792370319366455\n",
            "4.6310529708862305\n",
            "6.5754876136779785\n",
            "7.2826642990112305\n",
            "7.665884971618652\n",
            "6.896306037902832\n",
            "7.217545986175537\n",
            "7.517164707183838\n",
            "6.955342769622803\n",
            "5.688587188720703\n",
            "6.476454734802246\n",
            "6.741580009460449\n",
            "6.363152027130127\n",
            "6.378721237182617\n",
            "7.01143741607666\n",
            "5.938511848449707\n",
            "6.500308036804199\n",
            "5.437282562255859\n",
            "6.47383975982666\n",
            "6.280369281768799\n",
            "7.6747283935546875\n",
            "6.976853847503662\n",
            "6.772916316986084\n",
            "7.164555549621582\n",
            "5.828627109527588\n",
            "7.198172092437744\n",
            "6.280570983886719\n",
            "8.969925880432129\n",
            "7.0631866455078125\n",
            "8.28504753112793\n",
            "6.9706573486328125\n",
            "7.815709590911865\n",
            "6.995858669281006\n",
            "7.413034915924072\n",
            "7.381608486175537\n",
            "6.326014041900635\n",
            "7.88832950592041\n",
            "7.007607460021973\n",
            "8.324047088623047\n",
            "6.004965305328369\n",
            "8.733348846435547\n",
            "5.603051662445068\n",
            "8.760869979858398\n",
            "7.267832279205322\n",
            "6.671844482421875\n",
            "7.166808128356934\n",
            "7.462821006774902\n",
            "5.099998474121094\n",
            "6.758790016174316\n",
            "6.703573703765869\n",
            "7.161220550537109\n",
            "7.368875026702881\n",
            "6.7739715576171875\n",
            "7.417382717132568\n",
            "6.917409420013428\n",
            "7.311923980712891\n",
            "7.5188093185424805\n",
            "7.113454341888428\n",
            "7.929543972015381\n",
            "7.803370475769043\n",
            "8.41272258758545\n",
            "9.05321216583252\n",
            "4.645528316497803\n",
            "7.588461399078369\n",
            "6.605139255523682\n",
            "7.621598243713379\n",
            "5.612214088439941\n",
            "6.2075395584106445\n",
            "7.245855808258057\n",
            "6.8031744956970215\n",
            "6.597872257232666\n",
            "6.184985160827637\n",
            "5.594417572021484\n",
            "6.500125885009766\n",
            "6.755757808685303\n",
            "7.484210968017578\n",
            "7.0406341552734375\n",
            "6.233768463134766\n",
            "6.156155586242676\n",
            "6.977292060852051\n",
            "6.586789131164551\n",
            "5.117869853973389\n",
            "6.591544151306152\n",
            "6.088850498199463\n",
            "7.854458808898926\n",
            "8.471593856811523\n",
            "8.355685234069824\n",
            "7.457037448883057\n",
            "6.750432014465332\n",
            "5.546782493591309\n",
            "6.8600172996521\n",
            "6.394532680511475\n",
            "6.415340423583984\n",
            "7.520501136779785\n",
            "5.928642272949219\n",
            "7.601159572601318\n",
            "6.785656929016113\n",
            "8.90150260925293\n",
            "7.220592498779297\n",
            "5.669232368469238\n",
            "6.3259992599487305\n",
            "7.088648319244385\n",
            "7.414375305175781\n",
            "6.074317455291748\n",
            "7.414301872253418\n",
            "7.613373756408691\n",
            "7.896378993988037\n",
            "5.6064324378967285\n",
            "5.0192551612854\n",
            "5.5699567794799805\n",
            "7.564697265625\n",
            "7.077643394470215\n",
            "7.048724174499512\n",
            "5.411101818084717\n",
            "7.0893988609313965\n",
            "7.270528316497803\n",
            "4.751689910888672\n",
            "7.816071510314941\n",
            "5.736886501312256\n",
            "6.636854648590088\n",
            "6.712764739990234\n",
            "7.381766319274902\n",
            "6.8518476486206055\n",
            "8.555971145629883\n",
            "6.687413692474365\n",
            "6.588931083679199\n",
            "7.306987762451172\n",
            "7.774294376373291\n",
            "7.961282253265381\n",
            "6.575554847717285\n",
            "7.757714748382568\n",
            "8.136575698852539\n",
            "8.083885192871094\n",
            "6.657736778259277\n",
            "6.114356994628906\n",
            "5.187632083892822\n",
            "8.032488822937012\n",
            "7.35137414932251\n",
            "8.380668640136719\n",
            "6.461714267730713\n",
            "4.731430530548096\n",
            "6.4686784744262695\n",
            "7.515966892242432\n",
            "6.531307220458984\n",
            "8.736276626586914\n",
            "6.295642852783203\n",
            "6.791800022125244\n",
            "6.715793609619141\n",
            "6.6174211502075195\n",
            "5.77242374420166\n",
            "5.594897747039795\n",
            "6.322528839111328\n",
            "7.632045745849609\n",
            "8.260701179504395\n",
            "5.435370445251465\n",
            "8.542266845703125\n",
            "5.995811939239502\n",
            "6.771459102630615\n",
            "6.446966648101807\n",
            "6.754049777984619\n",
            "5.771563529968262\n",
            "8.272929191589355\n",
            "8.115617752075195\n",
            "6.076396465301514\n",
            "9.07528018951416\n",
            "6.080124855041504\n",
            "7.296534061431885\n",
            "7.147858619689941\n",
            "9.352355003356934\n",
            "6.678064823150635\n",
            "6.502350807189941\n",
            "7.029810428619385\n",
            "7.695952415466309\n",
            "7.633964538574219\n",
            "7.102674961090088\n",
            "8.089265823364258\n",
            "6.264893531799316\n",
            "8.443819999694824\n",
            "5.898582458496094\n",
            "8.247801780700684\n",
            "6.49988317489624\n",
            "6.18233585357666\n",
            "5.88637638092041\n",
            "6.02541446685791\n",
            "5.833578109741211\n",
            "6.522580146789551\n",
            "4.109490394592285\n",
            "7.737884521484375\n",
            "6.438584804534912\n",
            "6.280987739562988\n",
            "6.321818828582764\n",
            "6.430678367614746\n",
            "6.970406532287598\n",
            "8.528219223022461\n",
            "6.365387916564941\n",
            "7.477799415588379\n",
            "5.181342601776123\n",
            "7.023919582366943\n",
            "7.782568454742432\n",
            "6.776823997497559\n",
            "6.135458946228027\n",
            "6.87322473526001\n",
            "6.205806732177734\n",
            "5.64010763168335\n",
            "5.5616583824157715\n",
            "7.4680495262146\n",
            "5.211292266845703\n",
            "4.844956398010254\n",
            "8.125006675720215\n",
            "8.959155082702637\n",
            "8.065958023071289\n",
            "7.515007972717285\n",
            "7.118566989898682\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-2d6e19bbeb2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# data is tokens, target is tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#data = data.reshape(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m## cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[10]' is invalid for input of size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a258LOYOi5k2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}